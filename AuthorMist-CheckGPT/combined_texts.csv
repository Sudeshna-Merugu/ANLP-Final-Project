text,label,source
"In this paper, the authors introduce a deep learning approach for optimizing auction mechanisms for resource management on mobile blockchains using edge computing. They claim that current auction methods for resource allocation suffer from inefficiency and neglect important aspects due to variability in both mobile devices and network conditions. To overcome this, they present a reinforcement learning framework which takes into account congestion levels, device mobility, and resource availability and selects the best resource allocation. Results of simulation tests compare favorably against traditional auction mechanisms and demonstrate marked improvements in resource utilization and reduction in latency. Overall performance gains are significant and suggest that this new approach leads to better network performance. This work points towards deep learning being transformative for resource management in mobile blockchain networks and opens up further research avenues in this domain.",1,AI
"The field of Artificial Intelligence (AI) and, in particular, the Machine Learning area, counts on a wide range of performance metrics and benchmark data sets to assess the problem-solving effectiveness of its solutions. However, the appearance of research centres, projects or institutions addressing AI solutions from a multidisciplinary and multi-stakeholder perspective suggests a new approach to assessment comprising ethical guidelines, reports or tools and frameworks to help both academia and business to move towards a responsible conceptualisation of AI. They all highlight the relevance of three key aspects: (i) enhancing cooperation among the different stakeholders involved in the design, deployment and use of AI; (ii) promoting multidisciplinary dialogue, including different domains of expertise in this process; and (iii) fostering public engagement to maximise a trusted relation with new technologies and practitioners. In this paper, we introduce the Observatory on Society and Artificial Intelligence (OSAI), an initiative grew out of the project AI4EU aimed at stimulating reflection on a broad spectrum of issues of AI (ethical, legal, social, economic and cultural). In particular, we describe our work in progress around OSAI and suggest how this and similar initiatives can promote a wider appraisal of progress in AI. This will give us the opportunity to present our vision and our modus operandi to enhance the implementation of these three fundamental dimensions.",0,Human
"In this paper, we present the design, implementation and our year-long maintenance experience of SNSAPI, a Python-based middleware which unifies the interfaces and data structures of heterogeneous Social Networking Services (SNS). Unlike most prior works, our middleware is user-oriented and requires zero infrastructure support. It enables a user to readily conduct online social activities in a programmable, cross-platform fashion while gradually reducing the dependence on centralized Online Social Networks (OSN). More importantly, as the SNSAPI middleware can be used to support decentralized social networking services via conventional communication channels such as RSS or Email, it enables the deployment of Decentralized Social Networks (DSN) in an incremental, ad hoc manner. To demonstrate the viability of such type of DSNs, we have deployed an experimental 6000-node SNSAPI-based DSN on PlanetLab and evaluate its performance by replaying traces of online social activities collected from a mainstream OSN. Our results show that, with only mild resource consumption, the SNSAPI-based DSN can achieve acceptable forwarding latency comparable to that of a centralized OSN. We also develop an analytical model to characterize the trade-offs between resource consumption and message forwarding delay in our DSN. Via 20 parameterized experiments on PlanetLab, we have found that the empirical measurement results match reasonably with the performance predicted by our analytical model.",0,Human
"Fueled by the rapid development of communication networks and sensors in portable devices, today many mobile users are invited by content providers to sense and send back real-time useful information (e.g., traffic observations and sensor data) to keep the freshness of the providers' content updates. However, due to the sampling cost in sensing and transmission, an individual may not have the incentive to contribute the real-time information to help a content provider reduce the age of information (AoI). Accordingly, we propose dynamic pricing for the provider to offer age-dependent monetary returns and encourage users to sample information at different rates over time. This dynamic pricing design problem needs to balance the monetary payments to users and the AoI evolution over time, and is challenging to solve especially under the incomplete information about users' arrivals and their private sampling costs. For analysis tractability, we linearize the nonlinear AoI evolution in the constrained dynamic programming problem, by approximating the dynamic AoI reduction as a time-average term and solving the approximate dynamic pricing in closed-form. Then, we estimate this approximate term based on Brouwer's fixed-point theorem. Finally, we provide the steady-state analysis of the optimized approximate dynamic pricing scheme for an infinite time horizon, and show that the pricing scheme can be further simplified to an e-optimal version without recursive computing over time.",0,Human
This paper aims to study how heteroscedasticity impacts classifier design in linear discriminant analysis (LDA). LDA is a common statistical technique for classifying things but usually assumes that predictor variable variances are equal across different classes. This is not always true in practice and violating this assumption can degrade classifier performance. We present a modified approach to LDA that considers heteroscedasticity by employing a weighted covariance matrix in the discriminant function. We then compare performance against traditional approaches using both simulated and real data at varying degrees of heteroscedasticity. Simulation results indicate that this new method performs better than traditional methods when variance varies among different classes. Results also show this new method performs well on real datasets where there is heteroscedasticity. We also suggest a method for choosing optimal weighting schemes to enhance classification accuracy. Our results indicate that handling heteroscedasticity improves classification accuracy and that this new approach works well for designing classifiers dealing with heteroscedastic data.,1,AI
"Successful design of human-in-the-loop control systems requires appropriate models for human decision makers. Whilst most paradigms adopted in the control systems literature hide the (limited) decision capability of humans, in behavioral economics individual decision making and optimization processes are well-known to be affected by perceptual and behavioral biases. Our goal is to enrich control engineering with some insights from behavioral economics research through exposing such biases in control-relevant settings. This paper addresses the following two key questions: 1) How do behavioral biases affect decision making? 2) What is the role played by feedback in human-in-the-loop control systems? Our experimental framework shows how individuals behave when faced with the task of piloting an UAV under risk and uncertainty, paralleling a real-world decision-making scenario. Our findings support the notion of humans in Cyberphysical Systems underlying behavioral biases regardless of -- or even because of -- receiving immediate outcome feedback. We observe substantial shares of drone controllers to act inefficiently through either flying excessively (overconfident) or overly conservatively (underconfident). Furthermore, we observe human-controllers to self-servingly misinterpret random sequences through being subject to a ""hot hand fallacy"". We advise control engineers to mind the human component in order not to compromise technological accomplishments through human issues.",0,Human
"This paper studies radio propagation mechanisms that impact handoffs, air interface design, beam steering, and MIMO for 5G mobile communication systems. Knife edge diffraction (KED) and a creeping wave linear model are shown to predict diffraction loss around typical building objects from 10 to 26 GHz, and human blockage measurements at 73 GHz are shown to fit a double knife-edge diffraction (DKED) model which incorporates antenna gains. Small-scale spatial fading of millimeter wave received signal voltage amplitude is generally Ricean-distributed for both omnidirectional and directional receive antenna patterns under both line-of-sight (LOS) and non-line-of-sight (NLOS) conditions in most cases, although the log-normal distribution fits measured data better for the omnidirectional receive antenna pattern in the NLOS environment. Small-scale spatial autocorrelations of received voltage amplitudes are shown to fit sinusoidal exponential and exponential functions for LOS and NLOS environments, respectively, with small decorrelation distances of 0.27 cm to 13.6 cm (smaller than the size of a handset) that are favorable for spatial multiplexing. Local area measurements using cluster and route scenarios show how the received signal changes as the mobile moves and transitions from LOS to NLOS locations, with reasonably stationary signal levels within clusters. Wideband mmWave power levels are shown to fade from 0.4 dB/ms to 40 dB/s, depending on travel speed and surroundings.",0,Human
"Let $G=(V,E)$ be an $n$-nodes non-negatively real-weighted undirected graph. In this paper we show how to enrich a {\em single-source shortest-path tree} (SPT) of $G$ with a \emph{sparse} set of \emph{auxiliary} edges selected from $E$, in order to create a structure which tolerates effectively a \emph{path failure} in the SPT. This consists of a simultaneous fault of a set $F$ of at most $f$ adjacent edges along a shortest path emanating from the source, and it is recognized as one of the most frequent disruption in an SPT. We show that, for any integer parameter $k \geq 1$, it is possible to provide a very sparse (i.e., of size $O(kn\cdot f^{1+1/k})$) auxiliary structure that carefully approximates (i.e., within a stretch factor of $(2k-1)(2|F|+1)$) the true shortest paths from the source during the lifetime of the failure. Moreover, we show that our construction can be further refined to get a stretch factor of $3$ and a size of $O(n \log n)$ for the special case $f=2$, and that it can be converted into a very efficient \emph{approximate-distance sensitivity oracle}, that allows to quickly (even in optimal time, if $k=1$) reconstruct the shortest paths (w.r.t. our structure) from the source after a path failure, thus permitting to perform promptly the needed rerouting operations. Our structure compares favorably with previous known solutions, as we discuss in the paper, and moreover it is also very effective in practice, as we assess through a large set of experiments.",0,Human
"The nuclear norm minimization (NNM) is commonly used to approximate the matrix rank by shrinking all singular values equally. However, the singular values have clear physical meanings in many practical problems, and NNM may not be able to faithfully approximate the matrix rank. To alleviate the above-mentioned limitation of NNM, recent studies have suggested that the weighted nuclear norm minimization (WNNM) can achieve a better rank estimation than NNM, which heuristically set the weight being inverse to the singular values. However, it still lacks a rigorous explanation why WNNM is more effective than NMM in various applications. In this paper, we analyze NNM and WNNM from the perspective of group sparse representation (GSR). Concretely, an adaptive dictionary learning method is devised to connect the rank minimization and GSR models. Based on the proposed dictionary, we prove that NNM and WNNM are equivalent to L1-norm minimization and the weighted L1-norm minimization in GSR, respectively. Inspired by enhancing sparsity of the weighted L1-norm minimization in comparison with L1-norm minimization in sparse representation, we thus explain that WNNM is more effective than NMM. By integrating the image nonlocal self-similarity (NSS) prior with the WNNM model, we then apply it to solve the image denoising problem. Experimental results demonstrate that WNNM is more effective than NNM and outperforms several state-of-the-art methods in both objective and perceptual quality.",0,Human
"With growing popularity of electric vehicles comes an increase in charging station installations but this rise also means increased risk of attacks via ransomware. Such attacks could disrupt service delivery and inconvenience users of these vehicles. This paper proposes a deep learning approach to detecting ransomware attacks in Supervisory Control and Data Acquisition (SCADA) systems of charging stations. Using Convolutional Neural Networks (CNN), we analyze network traffic from SCADA systems and look for signs of ransomware. We test this method using real attack data and normal traffic data. Results show that this proposed approach performs well at detecting ransomware attacks; compared to other machine learning methods, ours performs better in terms of accuracy and low rate of false positives. This proposed approach is thus useful for early detection of such attacks and reducing impact on users of electric vehicles.",1,AI
"The paper introduces a new tool called Odoviz for visualization and processing of 3D odometry data. Odoviz offers an easy-to use interface that helps researchers and developers better understand performance results from different algorithms. It offers diverse visualizations and analysis capabilities such as comparing multiple odometry runs, viewing point clouds, and computing various performance metrics. Authors test the tool using different datasets and show its usefulness in research and development of odometry.",1,AI
"This paper introduces a new method for anticipating actions when viewed from one's own perspective. We call this ""anticipation of egocentric actions,"" and it means to predict future actions by looking at previous actions from an individual's point of view. This is difficult because human actions are very dynamic and hard to predict. In this work we combine computer vision and machine learning to process video streams in real time. The goal is to anticipate actions as they happen. Results on various test sets show that this approach performs well and has potential uses including HCI (human computer interaction), robotics, and sports analysis.",1,AI
"This paper introduces Frauddroid which is a new system for automatic detection of fraudulent ads in Android apps. Using machine learning methods, this system analyzes app behavior in real time and identifies anomalous activities that point to fraud. Frauddroid is designed to be very effective and efficient; it reduces time and resource costs for manual detection of fraud. Results from our testing show that Frauddroid performs well at detecting fraud with low false positives. With this system we have the potential to greatly enhance Android security and safeguard advertisers from financial loss due to fraud.",1,AI
This paper explores using Bayesian optimization to optimize both the structure and parameters of function networks. Function networks are mathematical constructs used to model complicated relationships among input and output values. Optimization of such networks is very difficult because one must find an optimal combination of structure and parameters that reduces error between predicted values by the network and actual data. Bayesian optimization is a framework for global optimization which has worked well in many areas including machine learning. Authors report here on an approach using Bayesian optimization for optimizing function networks and test performance on different benchmarks. Results indicate that this new approach excels compared to other optimization methods and provides strong solutions for tuning networks.,1,AI
"This study introduces an innovative approach to synthesizing information from many different sources so that better and stronger decisions can be made. Proposed approach integrates variability and uncertainty of each source using a mathematical system for systematic combination of evidence. Results of rigorous simulations indicate this new method performs better than previous methods especially regarding accuracy and strength; this method excels particularly well when dealing with many sources. This new method is applicable across diverse fields including medical diagnoses, recommendation systems, and fusion of sensor data.",1,AI
"Music boundary detection is a task in music information retrieval which locates the beginning and ending times of separate songs in a playlist or recording. We use CNNs here to detect boundaries between songs and we also compare performance on different sets of combined features. Features used here are Mel Spectrogram, Chroma and Tonnetz representations. We study how well CNNs perform when they are trained separately with each feature and when they are trained using combinations of these features. Results show that using a combination of all three features improves performance better than using just one. Insights have been gained about the importance of considering different features when using CNNs for this task and there is potential for future improvements through further investigation into new feature combinations.",1,AI
"Multi-view detection incorporates multiple camera views to alleviate occlusion in crowded scenes, where the state-of-the-art approaches adopt homography transformations to project multi-view features to the ground plane. However, we find that these 2D transformations do not take into account the object's height, and with this neglection features along the vertical direction of same object are likely not projected onto the same ground plane point, leading to impure ground-plane features. To solve this problem, we propose VFA, voxelized 3D feature aggregation, for feature transformation and aggregation in multi-view detection. Specifically, we voxelize the 3D space, project the voxels onto each camera view, and associate 2D features with these projected voxels. This allows us to identify and then aggregate 2D features along the same vertical line, alleviating projection distortions to a large extent. Additionally, because different kinds of objects (human vs. cattle) have different shapes on the ground plane, we introduce the oriented Gaussian encoding to match such shapes, leading to increased accuracy and efficiency. We perform experiments on multiview 2D detection and multiview 3D detection problems. Results on four datasets (including a newly introduced MultiviewC dataset) show that our system is very competitive compared with the state-of-the-art approaches. %Our code and data will be open-sourced.Code and MultiviewC are released at https://github.com/Robert-Mar/VFA.",0,Human
This research looks at the role of randomness in robust perception by studying the geometry of neuronal populations. Authors use modeling and simulations to investigate how variability in the activity of these populations affects stability and robustness of perceptual representations. Results show randomness is important for shaping population geometry resulting in greater robustness and resistance to perturbations. Insights are offered regarding mechanisms of perception and a new framework is provided for future work on randomness and coding by neurons.,1,AI
This paper looks at the idea that data is very effective in deep learning and asks whether this really comes down to having lots of good data or whether other components like network structure and optimization techniques are also key. It reviews existing literature about this idea tracing its history and showing how it has developed over time. Evidence from recent research that data quality and relevance is more important than just volume is presented. The authors discuss what this means for deep learning saying we need a better grasp on the role of data for building more efficient models. Conclusions point towards future work needing stronger evaluation of data contributions and looking into alternative ways to learn that don't rely so much on large data sets.,1,AI
"This paper introduces a new scalable decoder microarchitecture for fault tolerance in quantum computing. Proposed microarchitecture aims to solve current system issues including large scale correction of errors, high computational burden and lack of scalability. Based on an innovative method of quantum error correction this architecture uses multiple parallel decoders to improve efficiency and scalability. Also included are mechanisms for fault tolerance which minimize hardware error effects and ensure stability and reliability of computations. Results from simulation and experiment show marked improvements in scalability and fault tolerance alongside reduced computational load over existing approaches. Proposed design is anticipated to be key to enabling large systems of quantum computing and furthering development of quantum technology.",1,AI
"Age-Related Macular Degeneration (AMD) is an asymptomatic retinal disease which may result in loss of vision. There is limited access to high-quality relevant retinal images and poor understanding of the features defining sub-classes of this disease. Motivated by recent advances in machine learning we specifically explore the potential of generative modeling, using Generative Adversarial Networks (GANs) and style transferring, to facilitate clinical diagnosis and disease understanding by feature extraction. We design an analytic pipeline which first generates synthetic retinal images from clinical images; a subsequent verification step is applied. In the synthesizing step we merge GANs (DCGANs and WGANs architectures) and style transferring for the image generation, whereas the verified step controls the accuracy of the generated images. We find that the generated images contain sufficient pathological details to facilitate ophthalmologists' task of disease classification and in discovery of disease relevant features. In particular, our system predicts the drusen and geographic atrophy sub-classes of AMD. Furthermore, the performance using CFP images for GANs outperforms the classification based on using only the original clinical dataset. Our results are evaluated using existing classifier of retinal diseases and class activated maps, supporting the predictive power of the synthetic images and their utility for feature extraction. Our code examples are available online.",0,Human
This work introduces a new way of learning robot manipulation skills by combining task progress based Gaussian rewards with exploration that has been adjusted based on losses from prior interactions. The proposed approach uses a measurement of task progress as a continuous reward signal for the reinforcement learning agent which motivates focusing on task goals. Exploration strategy also adapts based on losses experienced previously. Results are shown through simulations and experimentation on various manipulation tasks; the proposed method excels at both success rate and convergence speed compared to leading approaches. Benefits of using progress measurements and adjusting exploration based on loss are clear.,1,AI
"This paper investigates performance of language tools for fifteen under resourced official languages of the European Union (EU). It looks into effectiveness of these tools for tagging parts of speech, recognizing named entities, parsing dependencies and performing machine translation. The authors use a variety of evaluation metrics to compare performance of tools across different tasks and languages. Results show diverse effectiveness levels among different languages and tasks. Areas for future development are also identified. Findings from this research are useful to policymakers and researchers in language technology who work towards supporting languages that have little resources. Contribution of this work is significant as it advances knowledge about tool development and evaluation for languages with limited resources within EU and helps preserve linguistic diversity and promote multilingualism.",1,AI
"Despite the tremendous success of BitTorrent, its swarming system suffers from a fundamental limitation: lower or no availability of unpopular contents. Recently, Menasche et al. has shown that bundling is a promising solution to mitigate this availability problem; it improves the availability and reduces download times for unpopular contents by combining multiple files into a single swarm. There also have been studies on bundling strategies and performance issues in bundled swarms. In spite of the recent surge of interest in the benefits of and strategies for bundling, there are still little empirical grounding for understanding, describing, and modeling it. This is the first empirical study that measures and analyzes how prevalent contents bundling is in BitTorrent and how peers access the bundled contents, in comparison to the other non-bundled (i.e., single-filed) ones. To our surprise, we found that around 70% of BitTorrent swarms contain multiple files, which indicate that bundling has become widespread for contents sharing. We also show that the amount of bytes shared in bundled swarms is estimated to be around 85% out of all the BitTorrent contents logged in our datasets. Inspired from our findings, we raise and discuss three important research questions in the field of file sharing systems as well as future contents-oriented networking: i) bundling strategies, ii) bundling-aware sharing systems in BitTorrent, and iii) implications on content-oriented networking.",0,Human
"This work investigates asymptotically and numerically a model of volume transmission using stochastic partial differential equations (SPDEs). The SPDE model characterizes the diffusion of signaling molecules in a three dimensional extracellular space that is subject to random fluctuations. The asymptotic analysis examines long time behavior of the SPDE model and rigorously proves convergence of solution to deterministic PDE in mean field limit. Numerical analysis uses Monte Carlo methods to simulate the SPDE model and compares resulting solutions against deterministic limits. Results show high accuracy and efficiency of numerical scheme and emphasize significance of stochastic effects on dynamics of volume transmission. This research highlights intricate coupling of diffusion, randomness and nonlinearity in biological systems and lays groundwork for further investigation into volume transmission under different circumstances.",1,AI
"This paper introduces a network for analyzing behavior during public speaking which uses multiple channels of information such as audio, text and visual data. The new model combines different attention mechanisms to effectively evaluate contributions from each channel and identify important features. Performance of this model is tested using a set of speeches and compared against leading methods. Results show the proposed multichannel attention model performs better than others and indicates promise for practical use cases in studying speech and recognizing emotion.",1,AI
"Millions of drivers worldwide have enjoyed financial benefits and work schedule flexibility through a ride-sharing economy, but meanwhile they have suffered from the lack of a sense of identity and career achievement. Equipped with social identity and contest theories, financially incentivized team competitions have been an effective instrument to increase drivers' productivity, job satisfaction, and retention, and to improve revenue over cost for ride-sharing platforms. While these competitions are overall effective, the decisive factors behind the treatment effects and how they affect the outcomes of individual drivers have been largely mysterious. In this study, we analyze data collected from more than 500 large-scale team competitions organized by a leading ride-sharing platform, building machine learning models to predict individual treatment effects. Through a careful investigation of features and predictors, we are able to reduce out-sample prediction error by more than 24%. Through interpreting the best-performing models, we discover many novel and actionable insights regarding how to optimize the design and the execution of team competitions on ride-sharing platforms. A simulated analysis demonstrates that by simply changing a few contest design options, the average treatment effect of a real competition is expected to increase by as much as 26%. Our procedure and findings shed light on how to analyze and optimize large-scale online field experiments in general.",0,Human
"This paper looks into predictive state temporal difference (PSTD) learning which is a promising method for reinforcement learning that excels at learning in environments where things are not fully observable. Building on traditional Temporal Difference (TD) learning, PSTD uses predictive states to represent relevant information from previous observations. The paper gives an extensive review of theoretical basis for PSTD learning: mathematical formulation, convergence characteristics and connection to other reinforcement learning approaches. Authors introduce a new algorithm which integrates adaptive sampling strategies to improve learning efficiency. Results of experiments on benchmarks such as Cart Pole and navigation tasks show that PSTD outperforms standard TD learning in partially observable settings and converges faster. Overall this work advances reinforcement learning research by presenting an effective new approach for learning in such environments; this algorithm can have broad applicability to diverse practical issues including robotics, autonomous driving and gaming.",1,AI
"This paper introduces a new approach to synthesize frontal view faces that are captured from different angles and under various lighting conditions. Most current approaches use domain specific knowledge and need lots of labeled data. We use unsupervised learning and learn features directly that work well for synthesis regardless of specific task knowledge or labeled data. Results show performance at leading edge on benchmark datasets and generalizes to real world captured images as well. An evaluation also shows effectiveness of components of this proposed method and insights into their importance. In sum, we propose an exciting advance for synthesis of faces with mixed attributes and hope that this will be useful in biometrics, security and entertainment industries.",1,AI
"This paper summarizes proceedings of a combined conference which is the 25th International Workshop on Expressiveness in Concurrency and the 15th Workshop on Structural Operational Semantics. Experts in theoretical computer science gathered for this conference to share recent results and discuss new advances in concurrency and operational semantics. The main goal of this conference was to serve as an exchange ground for researchers where they could share ideas, report on recent research results and engage in productive discussions leading to future directions. Papers also point out some promising research areas that have emerged from the conference and give advice for future work in this domain. Key themes and issues considered include expressiveness of concurrency models and development of new techniques for operational semantics and their use in practical systems.",1,AI
"Current performance-driven building design methods are not widely adopted outside the research field for several reasons that make them difficult to integrate into a typical design process. In the early design phase, in particular, the time-intensity and the cognitive load associated with optimization and form parametrization are incompatible with design exploration, which requires quick iteration. This research introduces a novel method for performance-driven geometry generation that can afford interaction directly in the 3d modeling environment, eliminating the need for explicit parametrization, and is multiple orders faster than the equivalent form optimization. The method uses Machine Learning techniques to train a generative model offline. The generative model learns a distribution of optimal performing geometries and their simulation contexts based on a dataset that addresses the performance(s) of interest. By navigating the generative model's latent space, geometries with the desired characteristics can be quickly generated. A case study is presented, demonstrating the generation of a synthetic dataset and the use of a Variational Autoencoder (VAE) as a generative model for geometries with optimal solar gain. The results show that the VAE-generated geometries perform on average at least as well as the optimized ones, suggesting that the introduced method shows a feasible path towards more intuitive and interactive early-phase performance-driven design assistance.",0,Human
"This paper reports on proceedings of the Workshop on Social Robots in Therapy which explored the challenges and ethical issues of using social robots in therapeutic contexts. Experts from different disciplines such as robotics, psychology and ethics gathered to discuss pros and cons of employing social robots in therapy. Important subjects discussed were development of clear ethical standards for robot use in therapy, design of robots that enhance user autonomy and effects of social robots on therapist relationship. Closing remarks called for ongoing cooperation among disciplines and research to guarantee safety and efficacy of robots used therapeutically.",1,AI
"This paper introduces a method of learning contrastive representations specifically for retinal fundus images that use a mix of weak and strong supervision. Using image level labels as weak supervision and few manually labeled examples as strong supervision, this method aligns the representation space using contrastive loss function and evaluates learned representations on a task of classifying retinal diseases. Results show the proposed approach performs better than supervised learning and weak supervision methods in terms of classification accuracy and thus shows effectiveness of semi weak supervision contrastive representation learning for these images.",1,AI
"Stable view synthesis is an important issue in vision and graphics. It aims at generating new views from a collection of input images and results in high quality and stable output that faithfully represents the geometry and appearance of a scene. This paper reviews current leading practices in stable view synthesis; both classical and recent ones. Authors look at the pros and cons of different methods and judge their performance using various datasets and metrics. Also, they talk about challenges and future research directions such as integrating deep learning, dealing with complicated and dynamic scenes and developing interactive and real time systems. In summary, this paper is significant for researchers and implementers in vision and graphics and emphasizes the significance of stable view synthesis for diverse tasks.",1,AI
"Volume transmission is an important neural communication pathway in which neurons in one brain region influence the neurotransmitter concentration in the extracellular space of a distant brain region. In this paper, we apply asymptotic analysis to a stochastic partial differential equation model of volume transmission to calculate the neurotransmitter concentration in the extracellular space. Our model involves the diffusion equation in a three-dimensional domain with interior holes that randomly switch between being either sources or sinks. These holes model nerve varicosities that alternate between releasing and absorbing neurotransmitter, according to when they fire action potentials. In the case that the holes are small, we compute analytically the first two nonzero terms in an asymptotic expansion of the average neurotransmitter concentration. The first term shows that the concentration is spatially constant to leading order and that this constant is independent of many details in the problem. Specifically, this constant first term is independent of the number and location of nerve varicosities, neural firing correlations, and the size and geometry of the extracellular space. The second term shows how these factors affect the concentration at second order. Interestingly, the second term is also spatially constant under some mild assumptions. We verify our asymptotic results by high-order numerical simulation using radial basis function-generated finite differences.",0,Human
"This paper introduces a new way to speed up neural architecture search (NAS). Currently this process is very slow because we have to try lots of different networks and test how well they work. Our method uses machine learning to predict performance of different networks before we actually train them. This cuts down the amount of computation needed for NAS. First we train a model that predicts performance based on certain networks and performance measures. Then we use this model to predict performance of other networks. This avoids testing poor performing networks and reduces the total number of networks we need to test. We test this method on different datasets and show that it works faster than previous methods and performs similarly well. We also do some sensitivity analysis to study how different parameters affect performance. Results show that our method is reliable and robust. Overall we contribute to NAS by offering an improved way to find good neural network designs. Applications include vision, language processing and speech recognition where NAS is commonly used to design networks.",1,AI
"This paper introduces a new approach to recognize and retrieve actions in videos through learning of temporal contrastive graphs. Graphs are built by representing video clips as nodes and connecting those which have similar features via edges. For feature learning purposes, a contrastive loss is used to bring together clips that contain the same action and separate those containing different actions. Results on benchmark datasets show that this new approach significantly outperforms leading methods for both recognition and retrieval tasks. It also works well under occlusion and noise. The paper asserts that learning temporal contrastive graphs points toward promising directions for future research into action recognition and retrieval in videos.",1,AI
This paper introduces a way to realize learned behaviors for quadruped locomotion using kinematic primitives. Authors present a framework that integrates learning methods with kinematic primitives to produce smooth and adaptive motions for robots. Framework consists of two major parts: learning module trains neural networks on real locomotion data of quadrupeds and control module generates motion command based on learned models using kinematic primitives. Authors test their method on actual robot and show that it produces behavior which closely resembles what is seen in real animals. Results indicate this framework shows promise for use in practical applications for realized learned locomotion.,1,AI
"Single-frame infrared small target (SIRST) detection aims at separating small targets from clutter backgrounds. With the advances of deep learning, CNN-based methods have yielded promising results in generic object detection due to their powerful modeling capability. However, existing CNN-based methods cannot be directly applied for infrared small targets since pooling layers in their networks could lead to the loss of targets in deep layers. To handle this problem, we propose a dense nested attention network (DNANet) in this paper. Specifically, we design a dense nested interactive module (DNIM) to achieve progressive interaction among high-level and low-level features. With the repeated interaction in DNIM, infrared small targets in deep layers can be maintained. Based on DNIM, we further propose a cascaded channel and spatial attention module (CSAM) to adaptively enhance multi-level features. With our DNANet, contextual information of small targets can be well incorporated and fully exploited by repeated fusion and enhancement. Moreover, we develop an infrared small target dataset (namely, NUDT-SIRST) and propose a set of evaluation metrics to conduct comprehensive performance evaluation. Experiments on both public and our self-developed datasets demonstrate the effectiveness of our method. Compared to other state-of-the-art methods, our method achieves better performance in terms of probability of detection (Pd), false-alarm rate (Fa), and intersection of union (IoU).",0,Human
"Chatter identification and detection in machining processes has been an active area of research in the past two decades. Part of the challenge in studying chatter is that machining equations that describe its occurrence are often nonlinear delay differential equations. The majority of the available tools for chatter identification rely on defining a metric that captures the characteristics of chatter, and a threshold that signals its occurrence. The difficulty in choosing these parameters can be somewhat alleviated by utilizing machine learning techniques. However, even with a successful classification algorithm, the transferability of typical machine learning methods from one data set to another remains very limited. In this paper we combine supervised machine learning with Topological Data Analysis (TDA) to obtain a descriptor of the process which can detect chatter. The features we use are derived from the persistence diagram of an attractor reconstructed from the time series via Takens embedding. We test the approach using deterministic and stochastic turning models, where the stochasticity is introduced via the cutting coefficient term. Our results show a 97% successful classification rate on the deterministic model labeled by the stability diagram obtained using the spectral element method. The features gleaned from the deterministic model are then utilized for characterization of chatter in a stochastic turning model where there are very limited analysis methods.",0,Human
"This paper introduces a new way to scale up heuristic planning through integration of relational decision trees (RDTs). Heuristic planning has been successful for many practical tasks but can falter if the problem is very complicated or the search space is large. Learning RDTs might help scale this planning better because they can perform searches more efficiently and effectively. Using RDTs means modeling relationships among different states in the search space and guiding search. They are learned from a set of examples through a learning algorithm and learn complex relationships that aren't easily seen from simple heuristics. Then they guide search by picking promising branches of the tree based on learned relationships. Evaluation shows that this approach improves scalability and performance in large and complex task domains. Performance exceeds other top methods on most tasks. Overall, the approach suggests exciting progress toward making heuristic planning scalable and effective for practical use.",1,AI
"This paper looks into how improvisation relates to physical understanding and vision, especially when using new objects. It studies whether improvisation is improved by using such objects which help performers better understand their surroundings and plan ahead. Using both qualitative interviews with improvisers and experiments, this study uses mixed methods. Results show that using new objects as tools improves improvisation by enhancing understanding of one's environment and enabling prediction and anticipation of future movement through foresight. The study also emphasizes that training and practice are key to improving physical understanding and foresight and recommends incorporating new objects into training for those who want to improve their skills. Finally, the authors consider broader implications for performance improv and suggest avenues for further research.",1,AI
"Unstructured data from diverse sources, such as social media and aerial imagery, can provide valuable up-to-date information for intelligent situation assessment. Mining these different information sources could bring major benefits to applications such as situation awareness in disaster zones and mapping the spread of diseases. Such applications depend on classifying the situation across a region of interest, which can be depicted as a spatial ""heatmap"". Annotating unstructured data using crowdsourcing or automated classifiers produces individual classifications at sparse locations that typically contain many errors. We propose a novel Bayesian approach that models the relevance, error rates and bias of each information source, enabling us to learn a spatial Gaussian Process classifier by aggregating data from multiple sources with varying reliability and relevance. Our method does not require gold-labelled data and can make predictions at any location in an area of interest given only sparse observations. We show empirically that our approach can handle noisy and biased data sources, and that simultaneously inferring reliability and transferring information between neighbouring reports leads to more accurate predictions. We demonstrate our method on two real-world problems from disaster response, showing how our approach reduces the amount of crowdsourced data required and can be used to generate valuable heatmap visualisations from SMS messages and satellite images.",0,Human
"This paper aims to develop a method for achieving privacy of transparency reports in linear time. Transparency reports serve an important role in letting organizations disclose details of their practices; however, these reports can also expose sensitive information which can be dangerous. Privacy is therefore very important when publishing such reports. Proposed solution uses a data structure that facilitates quick querying and updates to transparency reports while preserving sensitive information. The new method attains linear complexity that greatly outperforms other methods that have worse time complexity such as quadratic. This paper includes theoretical analysis of the method along with practical results showing effectiveness. The proposal has great significance for organizations that wish to publish transparency reports while keeping sensitive data secure because it provides rapid and efficient ways to protect privacy.",1,AI
"Knowledge Graphs (KGs) have been integrated in several models of recommendation to augment the informational value of an item by means of its related entities in the graph. Yet, existing datasets only provide explicit ratings on items and no information is provided about user opinions of other (non-recommendable) entities. To overcome this limitation, we introduce a new dataset, called the MindReader, providing explicit user ratings both for items and for KG entities. In this first version, the MindReader dataset provides more than 102 thousands explicit ratings collected from 1,174 real users on both items and entities from a KG in the movie domain. This dataset has been collected through an online interview application that we also release open source. As a demonstration of the importance of this new dataset, we present a comparative study of the effect of the inclusion of ratings on non-item KG entities in a variety of state-of-the-art recommendation models. In particular, we show that most models, whether designed specifically for graph data or not, see improvements in recommendation quality when trained on explicit non-item ratings. Moreover, for some models, we show that non-item ratings can effectively replace item ratings without loss of recommendation quality. This finding, thanks also to an observed greater familiarity of users towards common KG entities than towards long-tail items, motivates the use of KG entities for both warm and cold-start recommendations.",0,Human
"Tractability of CSPs has been a central issue in theoretical computer science for many years. This paper investigates tractability of CSPs defined by forbidden patterns. We begin by defining forbidden patterns as a small set of constraints that cannot coexist in solutions to CSPs. Then we introduce a corresponding class of CSPs and examine their computational hardness. We show that some classes of CSPs defined by forbidden patterns are easy to compute; other ones are NP hard. We also find that there is a broad class of CSPs that are efficiently solvable regardless of the number of variables. We also show that hardness of CSPs defined by forbidden patterns correlates closely with the structural features of these forbidden patterns. Results from this paper have significant implications for algorithm design and analysis. They indicate that structure of forbidden patterns can serve as a guide for designing effective algorithms. Moreover, they shed light on distinguishing characteristics among hard CSPs which might help to develop evaluation criteria for CSP solver performance.",1,AI
"This paper introduces a new method for producing random permutations over groups that do not follow Abelian rules; these groups have long posed challenges in cryptography and computational complexity. Our method uses both algebraic structures and probabilistic algorithms to generate high quality permutations efficiently and with strong randomness characteristics. Results on diverse groups like matrix groups and symmetric groups show the success of this method. Statistical properties and computational efficiency of resulting permutations are also rigorously analyzed. Experimental results indicate that our method performs better compared to previous approaches when generating permutations over such groups, and thus it is promising for cryptographic purposes such as block ciphers and digital signatures. Applications of this work range beyond cryptography into other fields where efficient and random permutations are important such as graphics processing and computational biology.",1,AI
"Existing color-guided depth super-resolution (DSR) approaches require paired RGB-D data as training samples where the RGB image is used as structural guidance to recover the degraded depth map due to their geometrical similarity. However, the paired data may be limited or expensive to be collected in actual testing environment. Therefore, we explore for the first time to learn the cross-modality knowledge at training stage, where both RGB and depth modalities are available, but test on the target dataset, where only single depth modality exists. Our key idea is to distill the knowledge of scene structural guidance from RGB modality to the single DSR task without changing its network architecture. Specifically, we construct an auxiliary depth estimation (DE) task that takes an RGB image as input to estimate a depth map, and train both DSR task and DE task collaboratively to boost the performance of DSR. Upon this, a cross-task interaction module is proposed to realize bilateral cross task knowledge transfer. First, we design a cross-task distillation scheme that encourages DSR and DE networks to learn from each other in a teacher-student role-exchanging fashion. Then, we advance a structure prediction (SP) task that provides extra structure regularization to help both DSR and DE networks learn more informative structure representations for depth recovery. Extensive experiments demonstrate that our scheme achieves superior performance in comparison with other DSR methods.",0,Human
This paper introduces an innovative method for detecting three dimensional objects using point cloud data called boundary aware dense feature indicator. The system uses a module that focuses on boundaries to gather contextual information from these points; then there is also a dense feature indicator module which encodes this information into a compact form. The approach uses a single stage instead of traditional two stages and performs well at detection while cutting down on computational cost. Results are shown on benchmark sets and the new method shows promise as effective at identifying objects in real world scenes.,1,AI
"Recently, the problem of inaccurate learning targets in crowd counting draws increasing attention. Inspired by a few pioneering work, we solve this problem by trying to predict the indices of pre-defined interval bins of counts instead of the count values themselves. However, an inappropriate interval setting might make the count error contributions from different intervals extremely imbalanced, leading to inferior counting performance. Therefore, we propose a novel count interval partition criterion called Uniform Error Partition (UEP), which always keeps the expected counting error contributions equal for all intervals to minimize the prediction risk. Then to mitigate the inevitably introduced discretization errors in the count quantization process, we propose another criterion called Mean Count Proxies (MCP). The MCP criterion selects the best count proxy for each interval to represent its count value during inference, making the overall expected discretization error of an image nearly negligible. As far as we are aware, this work is the first to delve into such a classification task and ends up with a promising solution for count interval partition. Following the above two theoretically demonstrated criterions, we propose a simple yet effective model termed Uniform Error Partition Network (UEPNet), which achieves state-of-the-art performance on several challenging datasets. The codes will be available at: https://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.",0,Human
"Low-precision representation of deep neural networks (DNNs) is critical for efficient deployment of deep learning application on embedded platforms, however, converting the network to low precision degrades its performance. Crucially, networks that are designed for embedded applications usually suffer from increased degradation since they have less redundancy. This is most evident for the ubiquitous MobileNet architecture which requires a costly quantization-aware training cycle to achieve acceptable performance when quantized to 8-bits. In this paper, we trace the source of the degradation in MobileNets to a shift in the mean activation value. This shift is caused by an inherent bias in the quantization process which builds up across layers, shifting all network statistics away from the learned distribution. We show that this phenomenon happens in other architectures as well. We propose a simple remedy - compensating for the quantization induced shift by adding a constant to the additive bias term of each channel. We develop two simple methods for estimating the correction constants - one using iterative evaluation of the quantized network and one where the constants are set using a short training phase. Both methods are fast and require only a small amount of unlabeled data, making them appealing for rapid deployment of neural networks. Using the above methods we are able to match the performance of training-based quantization of MobileNets at a fraction of the cost.",0,Human
"This paper reviews comprehensively Video Generative Adversarial Networks (VGANS) that are based on deep learning for producing high quality videos with diverse content and style. These networks have recently received much attention because they perform well on tasks such as video synthesis, video prediction and video inpainting and thus represent promising tools for many applications. The paper reviews basic concepts and network architectures of VGANS including both traditional GAN frameworks and recent extensions like spatio temporal GANs and conditional GANs. Evaluation metrics including inception score, Frechet Inception Distance and other metrics for video quality are also discussed. Challenges and limitations such as difficulties in generating high resolution and long duration videos as well as mode collapse are considered. Current research advances such as self attention mechanisms, progressive training and multiscale architectures are reviewed as well. Overall, this paper gives an overview of the landscape of VGAN research, emphasizing recent progress and remaining obstacles and opportunities for future work. The paper ends by discussing promising future directions and uses for VGANs across different disciplines.",1,AI
"This paper studies how to improve exploration using Evolution Strategies for Deep Reinforcement Learning. Authors introduce a new method that uses a population of novelty seekers to increase exploration of search space. Novelty seekers learn to seek novelty in environment through states, actions and experiences; these novelties guide evolution of main population of RL agents. Authors test this approach on benchmark tasks and show that it performs better than standard Evolution Strategies both in sample efficiency and asymptotic performance. Results indicate adding a population of novelty seekers greatly improves the exploration process for Evolution Strategies in Deep RL.",1,AI
"This paper investigates how to use machine learning and topological data analysis for identifying chatter patterns during turning operations. Turning often causes chatter which leads to poor surface finish, tool wear and damage to both tool and machine. The goal here is to build a reliable and accurate classification system for chatter that helps detect and diagnose chatter. To do this, researchers collect vibration signals during turning and then transform these into time frequency representations via wavelet transforms. Images resulting from this transformation are then analyzed using topological data analysis which extracts topological features and characterizes different kinds of chatter. Using support vector machines and random forest learning algorithms, features are trained to classify chatter. Performance is measured by metrics such as accuracy, precision and recall. Results show that the proposed method successfully classifies different kinds of chatter including regenerative and forced chatter. Features extracted using persistent homology provide distinctive and strong representation of chatter characteristics, which improves the accuracy and reliability of classification. Conclusions state that combining machine learning and top data analysis provides a powerful way to classify chatter that detects chatter in real time. Proposed method promises higher quality and efficiency in machining and less downtime and better productivity in manufacturing.",1,AI
"Reinforcement Learning is proving a successful tool that can manage urban intersections with a fraction of the effort required to curate traditional traffic controllers. However, literature on the introduction and control of pedestrians to such intersections is scarce. Furthermore, it is unclear what traffic state variables should be used as reward to obtain the best agent performance. This paper robustly evaluates 30 different Reinforcement Learning reward functions for controlling intersections serving pedestrians and vehicles covering the main traffic state variables available via modern vision-based sensors. Some rewards proposed in previous literature solely for vehicular traffic are extended to pedestrians while new ones are introduced. We use a calibrated model in terms of demand, sensors, green times and other operational constraints of a real intersection in Greater Manchester, UK. The assessed rewards can be classified in 5 groups depending on the magnitudes used: queues, waiting time, delay, average speed and throughput in the junction. The performance of different agents, in terms of waiting time, is compared across different demand levels, from normal operation to saturation of traditional adaptive controllers. We find that those rewards maximising the speed of the network obtain the lowest waiting time for vehicles and pedestrians simultaneously, closely followed by queue minimisation, demonstrating better performance than other previously proposed methods.",0,Human
"The ability to segment teeth precisely from digitized 3D dental models is an essential task in computer-aided orthodontic surgical planning. To date, deep learning based methods have been popularly used to handle this task. State-of-the-art methods directly concatenate the raw attributes of 3D inputs, namely coordinates and normal vectors of mesh cells, to train a single-stream network for fully-automated tooth segmentation. This, however, has the drawback of ignoring the different geometric meanings provided by those raw attributes. This issue might possibly confuse the network in learning discriminative geometric features and result in many isolated false predictions on the dental model. Against this issue, we propose a two-stream graph convolutional network (TSGCNet) to learn multi-view geometric information from different geometric attributes. Our TSGCNet adopts two graph-learning streams, designed in an input-aware fashion, to extract more discriminative high-level geometric representations from coordinates and normal vectors, respectively. These feature representations learned from the designed two different streams are further fused to integrate the multi-view complementary information for the cell-wise dense prediction task. We evaluate our proposed TSGCNet on a real-patient dataset of dental models acquired by 3D intraoral scanners, and experimental results demonstrate that our method significantly outperforms state-of-the-art methods for 3D shape segmentation.",0,Human
This paper introduces an approach for joint optimization of fronthaul and decentralized edge computing in Fog Radio Access Networks. These networks combine wireless communications and computing on edge devices alongside cloud computing to enable low latency and high bandwidth. We propose this approach which aims to reduce total network energy use by optimally assigning computational tasks to edge devices while respecting resource constraints. This design allows efficient and flexible adaptation to different situations. Results from simulation studies show that this method can greatly enhance performance of FRANs.,1,AI
"With the increasing interest in the content creation field in multiple sectors such as media, education, and entertainment, there is an increasing trend in the papers that uses AI algorithms to generate content such as images, videos, audio, and text. Generative Adversarial Networks (GANs) in one of the promising models that synthesizes data samples that are similar to real data samples. While the variations of GANs models, in general, have been covered to some extent in several survey papers, to the best of our knowledge, this is among the first survey papers that reviews the state-of-the-art video GANs models. This paper first categorized GANs review papers into general GANs review papers, image GANs review papers, and special field GANs review papers such as anomaly detection, medical imaging, or cybersecurity. The paper then summarizes the main improvements in GANs frameworks that are not initially developed for the video domain but have been adopted in multiple video GANs variations. Then, a comprehensive review of video GANs models is provided under two main divisions according to the presence or non-presence of a condition. The conditional models then further grouped according to the type of condition into audio, text, video, and image. The paper is concluded by highlighting the main challenges and limitations of the current video GANs models. A comprehensive list of datasets, applied loss functions, and evaluation metrics is provided in the supplementary material.",0,Human
"We explore this empirical study on effects of bundling content in swarming systems using BitTorrent. We used data from downloads to analyze user behavior of those who downloaded bundled versus unbundled content. Results show bundling content does indeed boost average download speeds, though there is also longer download time for certain single files. We also find bundling attracts a greater number of seeders and leeches which makes better use of available bandwidth. However, bundling also means users have to download multiple files that they do not necessarily use fully because they must download them all in order to get the bundled files. Overall our results point out tradeoffs involved with bundling content in BitTorrent swarm systems and suggest implications for content creators, users and designers of such systems.",1,AI
"This paper investigates the use of crowdsourcing to generate content for scenario games that aim to teach different subjects such as healthcare, business, and military training. Serious games are now widely recognized as very effective educational tools. However, creating realistic and interesting scenarios takes a lot of time and resources. Using crowd power seems like a good solution because crowds have strong intelligence and creativity. This paper studies how a crowd sourcing platform collected content for a game on conflict resolution for medical students; they used mixed methods that combined data collected from the crowd with feedback from users. Results show that crowd contributions were of high quality and this made the game an effective learning tool. Challenges and limitations were also highlighted such as careful moderation and effective communication with contributors. In summary, the paper gives important information on the potential and limitations of using crowdsourcing for serious games content. Results show that using crowdsourcing can help designers to produce compelling and effective games but careful planning and execution is needed to ensure quality and relevance of resulting content.",1,AI
Chest X-rays are important for diagnosing lung diseases but they have low resolution which makes detection of fine lung details challenging. We suggest a new way to use deep learning to improve the visibility of lung features on X-rays. This uses a fully convolutional neural network (FCNN) that is trained using a big collection of X rays and matching CT scans. The network learns to predict CT values for every pixel and thereby converts low resolution X rays into high resolution ones. Results show that enhancing images like this clearly improves visibility of small lung features such as nodules and blood vessels. Results also show that our approach using FCNNs can improve identification accuracy of lung diseases.,1,AI
"This paper studies synthesizing new retinal symptoms through use of multiple generative models. Retinal symptoms are important indicators of many diseases including diabetes, macular degeneration and glaucoma. Diagnosing and treating these diseases requires an understanding of symptoms. Yet lack of good quality data makes this difficult. This study introduces a new approach that uses powerful learning methods like GANs, VAEs and Style GANs to generate high quality retinal symptom images. Training is done using a large set of retinal images and then the different models are combined to produce new and varied images. Performance is evaluated by metrics like FID and IS. Results show that this method excels compared to other leading approaches at generating such images. A user study also evaluates realism and appearance quality of generated images. Study results indicate that generated images look similar to real ones. Potential applications include helping doctors diagnose and treat eye disease. Method generates a large variety of high quality images useful for training diagnosis models and testing new therapies. Overall, this research opens promising avenues for synthesizing retinal symptoms through use of multiple generative models.",1,AI
"Opportunistic spectrum access (OSA) networks have been proposed as a means to solve the problem of scarcity of spectrum in wireless communication systems. In these networks secondary users are permitted to access unused portions of spectrum at frequencies of primary users. Bonding channels is a technique that allows increases in bandwidth by combining contiguous and non contiguous channels. This paper examines the advantages of channel bonding in OSA networks. Results from simulations and analysis show that channel bonding greatly improves performance including throughput, delays and energy efficiency. Results indicate higher spectrum utilization, longer transmission ranges and improved stability compared to single channel access. Results also suggest that bonding channels is a promising approach for enhancing performance of such networks. Insights from this work can guide design and optimization.",1,AI
"CNNs have excelled at performing place recognition over time, particularly when the neural network is optimized for localization in the current environmental conditions. In this paper we investigate the concept of feature map filtering, where, rather than using all the activations within a convolutional tensor, only the most useful activations are used. Since specific feature maps encode different visual features, the objective is to remove feature maps that are detract from the ability to recognize a location across appearance changes. Our key innovation is to filter the feature maps in an early convolutional layer, but then continue to run the network and extract a feature vector using a later layer in the same network. By filtering early visual features and extracting a feature vector from a higher, more viewpoint invariant later layer, we demonstrate improved condition and viewpoint invariance. Our approach requires image pairs for training from the deployment environment, but we show that state-of-the-art performance can regularly be achieved with as little as a single training image pair. An exhaustive experimental analysis is performed to determine the full scope of causality between early layer filtering and late layer extraction. For validity, we use three datasets: Oxford RobotCar, Nordland, and Gardens Point, achieving overall superior performance to NetVLAD. The work provides a number of new avenues for exploring CNN optimizations, without full re-training.",0,Human
This paper introduces an innovative approach for ad allocation in feeds. It calls this method Cross DQN (Deep Q Network) and uses a reinforcement learning framework to optimize ad placement. This system balances gains from user engagement with generating revenue. Factors like user behavior and content features are considered to personalize recommendation of ads. Results show that this new approach performs much better than traditional rule based methods and other leading deep reinforcement learning algorithms on key metrics for both revenue and engagement. Proposed method has great potential to fundamentally change how ads are allocated and to deliver higher efficiency and effectiveness.,1,AI
"This paper looks at how performance driven design is used together with generative models in the initial phase of designing buildings. It examines if tools that produce designs based on performance criteria such as energy efficiency, structural integrity and natural light can help to explore different design options. The study introduces a framework for integrating generative design models from the beginning of design work that includes data preparation, modeling and performance assessment. Methodology uses a hypothetical design example where multiple design variations are created using a tool for generative design and evaluated through simulation software. Results indicate that early design stage use of these tools generates a large variety of high performance design solutions which also saves time. In conclusion, this research notes the great potential of using performance driven design with generative models to transform architecture by enabling architects to explore and evaluate design options related to performance criteria early on.",1,AI
This paper introduces a new approach to learning based reflection and beamforming for intelligent reflecting surfaces (IRS). Proposed method uses deep neural networks (DNNs) to jointly estimate channels and direct signals toward desired directions. DNNs learn directly end to end to minimize mean square error between desired and actual received signal. Proposed approach does not need explicit channel estimation and performs better for diverse channel models compared to traditional ones. Results from simulations show that this approach performs better than other algorithms concerning accuracy and robustness against channel uncertainty. This work suggests promising ways of implementing IRSs in practice and opens up further research into designing DNNs for IRSs.,1,AI
"This paper introduces an efficient preconditioner for solving large scale nuclear simulation problems using the neutron transport equation. A method based on subspace is used to develop a hierarchy of nested subdomains which capture essential physical features of the problem; this leads to a much more effective preconditioner. Adaptive thresholding is also included to improve accuracy of coarsening. Results show that the preconditioner reduces the number of iterations needed by Krylov subspace solvers and thereby improves both speed and accuracy. Performance and scalability results from numerical tests on realistic cases, such as reactor cores with millions of degrees of freedom, demonstrate good parallel efficiency and allow solution of very large problems with fast and accurate results on high performance computers.",1,AI
"Recently demand for wireless communication services has grown significantly leading to shortage of radio spectrum. One possible approach to solve this issue is sharing spectrum among different service providers. But this approach faces many technical and financial hurdles such as interference and coordination costs. Some countries have put in place subsidy regulations which provide financial aid to those who share spectrum. This paper seeks to examine how such subsidies influence motivation to share spectrum. Through a review of literature, we identify various types of subsidy regulations and their goals. We also analyze different mechanisms of subsidies and their impacts including subsidy levels, allocation criteria and subsidy duration. Findings show that subsidies effectively motivate sharing by lowering coordination costs and boosting benefits of sharing. However, careful design of subsidy mechanisms is essential because level and allocation of subsidies affect different providers differently. Concluding remarks discuss pros and cons of using subsidies and offer policy recommendations to maximize benefits from spectrum sharing. Overall, this paper stresses importance of subsidies for promoting sharing and suggests guidance for designing effective subsidy schemes. Results from this study can guide policymakers and regulators towards more efficient spectrum allocation and management.",1,AI
"We consider Bayesian optimization of the output of a network of functions, where each function takes as input the output of its parent nodes, and where the network takes significant time to evaluate. Such problems arise, for example, in reinforcement learning, engineering design, and manufacturing. While the standard Bayesian optimization approach observes only the final output, our approach delivers greater query efficiency by leveraging information that the former ignores: intermediate output within the network. This is achieved by modeling the nodes of the network using Gaussian processes and choosing the points to evaluate using, as our acquisition function, the expected improvement computed with respect to the implied posterior on the objective. Although the non-Gaussian nature of this posterior prevents computing our acquisition function in closed form, we show that it can be efficiently maximized via sample average approximation. In addition, we prove that our method is asymptotically consistent, meaning that it finds a globally optimal solution as the number of evaluations grows to infinity, thus generalizing previously known convergence results for the expected improvement. Notably, this holds even though our method might not evaluate the domain densely, instead leveraging problem structure to leave regions unexplored. Finally, we show that our approach dramatically outperforms standard Bayesian optimization methods in several synthetic and real-world problems.",0,Human
"This paper presents a comprehensive survey of existing authentication and privacy-preserving schemes for 4G and 5G cellular networks. We start by providing an overview of existing surveys that deal with 4G and 5G communications, applications, standardization, and security. Then, we give a classification of threat models in 4G and 5G cellular networks in four categories, including, attacks against privacy, attacks against integrity, attacks against availability, and attacks against authentication. We also provide a classification of countermeasures into three types of categories, including, cryptography methods, humans factors, and intrusion detection methods. The countermeasures and informal and formal security analysis techniques used by the authentication and privacy preserving schemes are summarized in form of tables. Based on the categorization of the authentication and privacy models, we classify these schemes in seven types, including, handover authentication with privacy, mutual authentication with privacy, RFID authentication with privacy, deniable authentication with privacy, authentication with mutual anonymity, authentication and key agreement with privacy, and three-factor authentication with privacy. In addition, we provide a taxonomy and comparison of authentication and privacy-preserving schemes for 4G and 5G cellular networks in form of tables. Based on the current survey, several recommendations for further research are discussed at the end of this paper.",0,Human
"This paper conducts a comparison study of different methods for reducing nuclear norm which is a common convex relaxation of rank function for solving problems related to matrix completion. We analyze advantages and disadvantages of existing optimization algorithms such as gradient descent, proximal gradient descent, and alternating minimization. Performance evaluation is done using both synthetic and real data sets and compared based on convergence rate, computation time and solution quality. Results show that proximal gradient descent and alternating minimization outperform gradient descent regarding convergence speed and solution quality, but at a higher cost of computational complexity. Ultimately the selection of optimization method depends on specific application needs and trade off between computational efficiency and solution quality.",1,AI
This paper looks at using unsupervised domain adaptation with double classifiers and focuses on improving accuracy of high confidence pseudo labels. Training consists of two classifiers: one on source domain and one on target domain. Their outputs produce pseudo labels for target data. These high confidence labels are refined iteratively by picking confident predictions from both classifiers and retraining the model. Results on benchmarks show this method outperforms current approaches for unsupervised domain adaptation and excels especially in tasks like image classification and sentiment analysis. Overall the research finds this double classifier approach along with high confidence pseudo labels is promising and likely to substantially improve model generalization to new domains.,1,AI
This paper introduces an innovative way to decompress knowledge graph representations for predicting links. Authors contend that existing methods of compression reduce important information necessary for accurate predictions. The suggested approach uses graph convolution networks to restore compressed representations and retain the full structure of the knowledge graph. Results are evaluated on standard benchmarks and this new method surpasses strong competitors who rely on compressed representations. Results emphasize importance of retaining full graph structure for accurate predictions and suggest new directions for research in this field.,1,AI
"Combinatorial auctions allocate goods and services among different bidders who value bundles of items rather than single items. In theory, mechanisms that elicit truthful preferences are best because this reduces inefficiencies. However, such mechanisms can be limiting and sometimes fail under certain circumstances. This paper introduces an approach for interpolating between truthful and untruthful mechanisms. Thus we can design more flexible auction designs. We introduce a general framework for designing mechanisms that are truthful in certain regions of preference space and also allow for non truthfulness elsewhere. We propose a family of mechanisms that go from one extreme to another: a truthful mechanism that encourages bidding truthfully and another that maximizes auction revenue regardless of bidder truthfulness. Mechanisms are designed efficiently and perform well experimentally in terms of welfare and revenue. We study the properties of the mechanisms, such as regions where they are truthful, how sensitive they are to strategic behavior and their computational complexity. We find that mechanisms remain robust despite violations of truthfulness and perform well in the face of strategic play. Our approach is applicable to diverse auction scenarios like auctions with multiple units, auctions with budget limitations and auctions with uncertainty. Flexibility of our method makes it appealing for designing auctions balancing efficiency, revenue and incentives according to unique market features and preferences of bidders.",1,AI
"Compile-time information flow analysis has been a promising technique for protecting confidentiality and integrity of private data. In the last couple of decades, a large number of information flow security tools in the form of run-time execution-monitors or static type systems have been developed for programming languages to analyze information flow security policies. However, existing flow analysis tools lack in precision and usability, which is the primary reason behind not being widely adopted in real application development. In this paper, we propose a compile-time information flow analysis for an imperative program based on a hybrid (mutable + immutable) labelling approach that enables a user to detect information flow-policy breaches and modify the program to overcome violations. We have developed an information flow security analyzer for a dialect of Python language, PyX, called Pifthon using the said approach. The flow-analyzer aids in identifying possible misuse of the information in sequential PyX programs corresponding to a given information flow policy (IFP). Pifthon has distinct advantages like reduced labelling overhead that ameliorates usability, covers a wide range of PyX programs that include termination-and progress-sensitive channels, in contrast to other approaches in the literature. The proposed flow analysis is proved to be sound under the classical non-interference property. Further, case study and experience in the usage of Pifthon are provided.",0,Human
"This research looks into how to improve the accuracy of solving linear systems using what's called full operator preconditioning. It uses an approach where you employ the inverse of the matrix defining the system as a preconditioner. Two main topics are addressed: one is about comparing the resulting solutions from using full preconditioning against other preconditioning techniques and another one is to consider computational costs related to applying full preconditioning. Numerical experiments on systems of different sizes and characteristics are done to achieve objectives. Comparisons are made between performance of full preconditioning and other preconditioners like incomplete factorization and diagonal preconditioning. Accuracy is assessed through analysis of residuals and convergence rates of iterative methods used to solve the systems. Results show that full preconditioning greatly improves solution accuracy compared to other techniques; however, computational cost tends to be higher especially for large problems. Proposed ways to reduce costs include parallel computing and use of sparse matrices. Overall, results shed light on using full preconditioning to enhance accuracy solving linear systems. Results have implications across engineering, physics and computer science among others because accuracy and efficiency in solving such systems is important in various contexts.",1,AI
"Use of fuzz testing has grown more common as a way to find new vulnerabilities that developers don't know about. But traditional fuzzing relies on random input which produces a lot of irrelevant test cases that don't find new vulnerabilities. This paper introduces an innovative approach to increase effectiveness by integrating metrics that measure software complexity into the fuzz testing process. Metrics like code complexity, control flow complexity, and data complexity are introduced. Metrics guide generation of test cases focusing on parts of software most likely to have vulnerabilities. Experiments were run on open source programs with known vulnerabilities. Results indicate this approach greatly reduces irrelevant test cases and finds more new vulnerabilities. Comparisons against top fuzz testing methods consistently show this approach excels. Study shows that using metrics for software complexity significantly enhances software testing. This method is easy to incorporate into existing fuzzers and helps developers discover and fix vulnerabilities in their software.",1,AI
"We study exploration in stochastic multi-armed bandits when we have access to a divisible resource that can be allocated in varying amounts to arm pulls. We focus in particular on the allocation of distributed computing resources, where we may obtain results faster by allocating more resources per pull, but might have reduced throughput due to nonlinear scaling. For example, in simulation-based scientific studies, an expensive simulation can be sped up by running it on multiple cores. This speed-up however, is partly offset by the communication among cores, which results in lower throughput than if fewer cores were allocated per trial to run more trials in parallel. In this paper, we explore these trade-offs in two settings. First, in a fixed confidence setting, we need to find the best arm with a given target success probability as quickly as possible. We propose an algorithm which trades off between information accumulation and throughput and show that the time taken can be upper bounded by the solution of a dynamic program whose inputs are the gaps between the sub-optimal and optimal arms. We also prove a matching hardness result. Second, we present an algorithm for a fixed deadline setting, where we are given a time deadline and need to maximize the probability of finding the best arm. We corroborate our theoretical insights with simulation experiments that show that the algorithms consistently match or outperform baseline algorithms on a variety of problem instances.",0,Human
"Vulnerable software represents a tremendous threat to modern information systems. Vulnerabilities in widespread applications may be used to spread malware, steal money and conduct target attacks. To address this problem, developers and researchers use different approaches of dynamic and static software analysis; one of these approaches is called fuzzing. Fuzzing is performed by generating and sending potentially malformed data to an application under test. Since first appearance in 1988, fuzzing has evolved a lot, but issues which addressed to effectiveness evaluation have not fully investigated until now. In our research, we propose a novel approach of fuzzing effectiveness evaluation, taking into account semantics of executed code along with a quantitative assessment. For this purpose, we use specific metrics of source code complexity assessment adapted to perform analysis of machine code. We conducted effectiveness evaluation of these metrics on 104 widespread applications with known vulnerabilities. As a result of these experiments, we were able to identify a set of metrics that are more suitable to find bugs. In addition, we conducted separate experiments on 7 applications without known vulnerabilities by using the set of metrics. The experimental results confirmed that proposed approach can be applied to increase performance of the fuzzing. Moreover, the tools helped detect two critical zero day (previously unknown) vulnerabilities in the wide-spread applications.",0,Human
"Distributed storage systems employ codes to provide resilience to failure of multiple storage disks. Specifically, an $(n, k)$ MDS code stores $k$ symbols in $n$ disks such that the overall system is tolerant to a failure of up to $n-k$ disks. However, access to at least $k$ disks is still required to repair a single erasure. To reduce repair bandwidth, array codes are used where the stored symbols or packets are vectors of length $\ell$. MDS array codes have the potential to repair a single erasure using a fraction $1/(n-k)$ of data stored in the remaining disks. We introduce new methods of analysis which capitalize on the translation of the storage system problem into a geometric problem on a set of operators and subspaces. In particular, we ask the following question: for a given $(n, k)$, what is the minimum vector-length or sub-packetization factor $\ell$ required to achieve this optimal fraction? For \emph{exact recovery} of systematic disks in an MDS code of low redundancy, i.e. $k/n > 1/2$, the best known explicit codes \cite{WTB12} have a sub-packetization factor $\ell$ which is exponential in $k$. It has been conjectured \cite{TWB12} that for a fixed number of parity nodes, it is in fact necessary for $\ell$ to be exponential in $k$. In this paper, we provide a new log-squared converse bound on $k$ for a given $\ell$, and prove that $k \le 2\log_2\ell\left(\log_{\delta}\ell+1\right)$, for an arbitrary number of parity nodes $r = n-k$, where $\delta = r/(r-1)$.",0,Human
This paper looks at using Bayesian heat maps for probabilistic classification when you have multiple unreliable sources of information. Traditional methods usually presume that data is clean and precise but in practice data is often noisy and uncertain. Proposed is a method using a Bayesian framework to model uncertainty and produce probabilistic classifications that consider the reliability of sources. Results show this new method works better than other traditional classification methods especially when data is noisy or unreliable. Performance analysis is done looking at different priors and hyper parameters and benefits discussed including those for image processing and remote sensing along with medical diagnosis.,1,AI
"The embedding capacity of information flow is an important factor affecting how much data can reliably pass through communication networks. This paper investigates the embedding capacity for information flows under a pattern called renewal traffic where the time intervals between successive packets vary randomly over time. Using tools from queueing theory we derive analytical expressions for different types of channels when operating under this traffic pattern. Results show that embedding capacity depends strongly on the statistical nature of time intervals between packets and sometimes varies in unexpected ways such as reducing as arrival rates increase or becoming unbounded for certain parameter ranges. We also study effects of system parameters like channel capacity, noise levels and packet sizes on embedding capacity. Numerical results indicate that embedding capacity can be improved significantly by using coding schemes that take advantage of temporal features of renewal traffic. Our work contributes to understanding of reliable data transmission in networks and suggests better coding schemes for practical use. Methods and results here can help improve performance in diverse scenarios including wireless and wired networks as well as IoT networks.",1,AI
"This paper evaluates and analyzes communication infrastructure for wide area monitoring systems (WAMS) based on 3G technology. Performance of this infrastructure is considered in terms of reliability, scalability and efficiency. Methodology used includes detailed review of relevant literature as well as empirical data from simulation and experiments. Results indicate that this infrastructure using 3G technology delivers high levels of reliability and efficiency for WAMS but scalability is constrained by current network capacity. Study finds that while this infrastructure works well for small and medium systems, it is likely not sufficient for large ones. Insights are valuable for designers, researchers and practitioners dealing with design, deployment and optimization of WAMS communication infrastructure.",1,AI
"Recent advances in artificial intelligence (AI) and machine learning have created a general perception that AI could be used to solve complex problems, and in some situations over-hyped as a tool that can be so easily used. Unfortunately, the barrier to realization of mass adoption of AI on various business domains is too high because most domain experts have no background in AI. Developing AI applications involves multiple phases, namely data preparation, application modeling, and product deployment. The effort of AI research has been spent mostly on new AI models (in the model training stage) to improve the performance of benchmark tasks such as image recognition. Many other factors such as usability, efficiency and security of AI have not been well addressed, and therefore form a barrier to democratizing AI. Further, for many real world applications such as healthcare and autonomous driving, learning via huge amounts of possibility exploration is not feasible since humans are involved. In many complex applications such as healthcare, subject matter experts (e.g. Clinicians) are the ones who appreciate the importance of features that affect health, and their knowledge together with existing knowledge bases are critical to the end results. In this paper, we take a new perspective on developing AI solutions, and present a solution for making AI usable. We hope that this resolution will enable all subject matter experts (eg. Clinicians) to exploit AI like data scientists.",0,Human
"This paper introduces a new method for coding depth sequences by merging hierarchical partitioning and spatial quantization. The aim is to improve coding efficiency while also ensuring good visual quality on reconstruction of depth maps. Hierarchical partitioning organizes depth values into different levels of detail while spatial domain quantization reduces bit requirements for representing those depths. Performance evaluation uses both objective and subjective metrics; results show this new method outperforms current best coding methods in terms of efficiency and visual quality. This contribution advances research in coding depth sequences and may find application in diverse areas including virtual and augmented reality, robotics and computer vision.",1,AI
"Several cybersecurity domains, such as ransomware detection, forensics and data analysis, require methods to reliably identify encrypted data fragments. Typically, current approaches employ statistics derived from byte-level distribution, such as entropy estimation, to identify encrypted fragments. However, modern content types use compression techniques which alter data distribution pushing it closer to the uniform distribution. The result is that current approaches exhibit unreliable encryption detection performance when compressed data appears in the dataset. Furthermore, proposed approaches are typically evaluated over few data types and fragment sizes, making it hard to assess their practical applicability. This paper compares existing statistical tests on a large, standardized dataset and shows that current approaches consistently fail to distinguish encrypted and compressed data on both small and large fragment sizes. We address these shortcomings and design EnCoD, a learning-based classifier which can reliably distinguish compressed and encrypted data. We evaluate EnCoD on a dataset of 16 different file types and fragment sizes ranging from 512B to 8KB. Our results highlight that EnCoD outperforms current approaches by a wide margin, with accuracy ranging from ~82 for 512B fragments up to ~92 for 8KB data fragments. Moreover, EnCoD can pinpoint the exact format of a given data fragment, rather than performing only binary classification like previous approaches.",0,Human
"In system identification, estimating parameters of a model using limited observations results in poor identifiability. To cope with this issue, we propose a new method to simultaneously select and estimate sensitive parameters as key model parameters and fix the remaining parameters to a set of typical values. Our method is formulated as a nonlinear least squares estimator with L1-regularization on the deviation of parameters from a set of typical values. First, we provide consistency and oracle properties of the proposed estimator as a theoretical foundation. Second, we provide a novel approach based on Levenberg-Marquardt optimization to numerically find the solution to the formulated problem. Third, to show the effectiveness, we present an application identifying a biomechanical parametric model of a head position tracking task for 10 human subjects from limited data. In a simulation study, the variances of estimated parameters are decreased by 96.1% as compared to that of the estimated parameters without L1-regularization. In an experimental study, our method improves the model interpretation by reducing the number of parameters to be estimated while maintaining variance accounted for (VAF) at above 82.5%. Moreover, the variances of estimated parameters are reduced by 71.1% as compared to that of the estimated parameters without L1-regularization. Our method is 54 times faster than the standard simplex-based optimization to solve the regularized nonlinear regression.",0,Human
"Conventional RGB-D salient object detection methods aim to leverage depth as complementary information to find the salient regions in both modalities. However, the salient object detection results heavily rely on the quality of captured depth data which sometimes are unavailable. In this work, we make the first attempt to solve the RGB-D salient object detection problem with a novel depth-awareness framework. This framework only relies on RGB data in the testing phase, utilizing captured depth data as supervision for representation learning. To construct our framework as well as achieving accurate salient detection results, we propose a Ubiquitous Target Awareness (UTA) network to solve three important challenges in RGB-D SOD task: 1) a depth awareness module to excavate depth information and to mine ambiguous regions via adaptive depth-error weights, 2) a spatial-aware cross-modal interaction and a channel-aware cross-level interaction, exploiting the low-level boundary cues and amplifying high-level salient channels, and 3) a gated multi-scale predictor module to perceive the object saliency in different contextual scales. Besides its high performance, our proposed UTA network is depth-free for inference and runs in real-time with 43 FPS. Experimental evidence demonstrates that our proposed network not only surpasses the state-of-the-art methods on five public RGB-D SOD benchmarks by a large margin, but also verifies its extensibility on five public RGB SOD benchmarks.",0,Human
"Properly designed precoders can significantly improve the spectral efficiency of multiple-input multiple-output (MIMO) relay systems. In this paper, we investigate joint source and relay precoding design based on the mean-square-error (MSE) criterion in MIMO two-way relay systems, where two multi-antenna source nodes exchange information via a multi-antenna amplify-and-forward relay node. This problem is non-convex and its optimal solution remains unsolved. Aiming to find an efficient way to solve the problem, we first decouple the primal problem into three tractable sub-problems, and then propose an iterative precoding design algorithm based on alternating optimization. The solution to each sub-problem is optimal and unique, thus the convergence of the iterative algorithm is guaranteed. Secondly, we propose a structured precoding design to lower the computational complexity. The proposed precoding structure is able to parallelize the channels in the multiple access (MAC) phase and broadcast (BC) phase. It thus reduces the precoding design to a simple power allocation problem. Lastly, for the special case where only a single data stream is transmitted from each source node, we present a source-antenna-selection (SAS) based precoding design algorithm. This algorithm selects only one antenna for transmission from each source and thus requires lower signalling overhead. Comprehensive simulation is conducted to evaluate the effectiveness of all the proposed precoding designs.",0,Human
"In the last decade, scenario-based serious-games have become a main tool for learning new skills and capabilities. An important factor in the development of such systems is the overhead in time, cost and human resources to manually create the content for these scenarios. We focus on how to create content for scenarios in medical, military, commerce and gaming applications where maintaining the integrity and coherence of the content is integral for the system's success. To do so, we present an automatic method for generating content about everyday activities through combining computer science techniques with the crowd. We use the crowd in three basic ways: to capture a database of scenarios of everyday activities, to generate a database of likely replacements for specific events within that scenario, and to evaluate the resulting scenarios. We found that the generated scenarios were rated as reliable and consistent by the crowd when compared to the scenarios that were originally captured. We also compared the generated scenarios to those created by traditional planning techniques. We found that both methods were equally effective in generated reliable and consistent scenarios, yet the main advantages of our approach is that the content we generate is more varied and much easier to create. We have begun integrating this approach within a scenario-based training application for novice investigators within the law enforcement departments to improve their questioning skills.",0,Human
This paper investigates theory of fusing images from different domains based on subjective visual attention. It introduces a new approach for fusing multiple image domains into a single image. The proposed method is based on the idea that attention varies depending on context and task. Attention is estimated and used as guidance for fusion process so that resultant image is more visually appealing and specific to task. Results are compared against previous methods using various datasets and show improvements in both visual quality and task specificity. Contribution of this research is new approach that uses attention and advancement towards creation of higher quality and specific fusion results.,1,AI
"This paper looks at how smart IoT services are created by means of large collaboration. With the growing need for smart services, integration of IoT technology makes cities able to deliver higher efficiency and sustainability. Implementation however is hard and collaboration among many stakeholders like government agencies, private firms, and academic institutions is necessary. Study investigated collaboration challenges and opportunities related to creating smart IoT services. Results indicate collaboration is critical to surmount technical, organizational and regulatory obstacles to service implementation. Conclusions state that collaboration increases efficiency and effectiveness of smart services and accelerates innovation that meets citizen needs. Research offers guidance to policy makers, academics and practitioners working on IoT services for smart cities. Findings point out that mechanisms for effective collaboration should be established along with open data sharing and dealing with privacy and security issues. Also proposed is that smart initiatives must consider the viewpoints and needs of all parties.",1,AI
This paper examines applications of mathematical programming and reinforcement learning for optimizing inventory systems with multiple levels. We aim to build a framework that reconciles inventory costs like holding and ordering costs against service levels of the system. Using real world data we test this framework and compare it to traditional inventory control approaches. Results show improved performance in inventory management along with cost reduction and higher customer satisfaction. Insights are gained here into integration of mathematical programming and reinforcement learning for inventory and also the importance of further research.,1,AI
"This paper presents a discrete-time option pricing model that is rooted in Reinforcement Learning (RL), and more specifically in the famous Q-Learning method of RL. We construct a risk-adjusted Markov Decision Process for a discrete-time version of the classical Black-Scholes-Merton (BSM) model, where the option price is an optimal Q-function, while the optimal hedge is a second argument of this optimal Q-function, so that both the price and hedge are parts of the same formula. Pricing is done by learning to dynamically optimize risk-adjusted returns for an option replicating portfolio, as in the Markowitz portfolio theory. Using Q-Learning and related methods, once created in a parametric setting, the model is able to go model-free and learn to price and hedge an option directly from data, and without an explicit model of the world. This suggests that RL may provide efficient data-driven and model-free methods for optimal pricing and hedging of options, once we depart from the academic continuous-time limit, and vice versa, option pricing methods developed in Mathematical Finance may be viewed as special cases of model-based Reinforcement Learning. Further, due to simplicity and tractability of our model which only needs basic linear algebra (plus Monte Carlo simulation, if we work with synthetic data), and its close relation to the original BSM model, we suggest that our model could be used for benchmarking of different RL algorithms for financial trading applications",0,Human
"We consider a decentralized networked control system (DNCS) consisting of a remote controller and a collection of linear plants, each associated with a local controller. Each local controller directly observes the state of its co-located plant and can inform the remote controller of the plant's state through an unreliable uplink channel. The downlink channels from the remote controller to local controllers were assumed to be perfect. The objective of the local controllers and the remote controller is to cooperatively minimize the infinite horizon time average of expected quadratic cost. The finite horizon version of this problem was solved in our prior work [2]. The optimal strategies in the finite horizon case were shown to be characterized by coupled Riccati recursions. In this paper, we show that if the link failure probabilities are below certain critical thresholds, then the coupled Riccati recursions of the finite horizon solution reach a steady state and the corresponding decentralized strategies are optimal. Above these thresholds, we show that no strategy can achieve finite cost. We exploit a connection between our DNCS Riccati recursions and the coupled Riccati recursions of an auxiliary Markov jump linear system to obtain our results. Our main results in Theorems 1 and 2 explicitly identify the critical thresholds for the link failure probabilities and the optimal decentralized control strategies when all link failure probabilities are below their thresholds.",0,Human
"We explore the value of weak labels in learning transferable representations for medical images. Compared to hand-labeled datasets, weak or inexact labels can be acquired in large quantities at significantly lower cost and can provide useful training signals for data-hungry models such as deep neural networks. We consider weak labels in the form of pseudo-labels and propose a semi-weakly supervised contrastive learning (SWCL) framework for representation learning using semi-weakly annotated images. Specifically, we train a semi-supervised model to propagate labels from a small dataset consisting of diverse image-level annotations to a large unlabeled dataset. Using the propagated labels, we generate a patch-level dataset for pretraining and formulate a multi-label contrastive learning objective to capture position-specific features encoded in each patch. We empirically validate the transfer learning performance of SWCL on seven public retinal fundus datasets, covering three disease classification tasks and two anatomical structure segmentation tasks. Our experiment results suggest that, under very low data regime, large-scale ImageNet pretraining on improved architecture remains a very strong baseline, and recently proposed self-supervised methods falter in segmentation tasks, possibly due to the strong invariant constraint imposed. Our method surpasses all prior self-supervised methods and standard cross-entropy training, while closing the gaps with ImageNet pretraining.",0,Human
"The analysis of the structure of musical pieces is a task that remains a challenge for Artificial Intelligence, especially in the field of Deep Learning. It requires prior identification of structural boundaries of the music pieces. This structural boundary analysis has recently been studied with unsupervised methods and \textit{end-to-end} techniques such as Convolutional Neural Networks (CNN) using Mel-Scaled Log-magnitude Spectograms features (MLS), Self-Similarity Matrices (SSM) or Self-Similarity Lag Matrices (SSLM) as inputs and trained with human annotations. Several studies have been published divided into unsupervised and \textit{end-to-end} methods in which pre-processing is done in different ways, using different distance metrics and audio characteristics, so a generalized pre-processing method to compute model inputs is missing. The objective of this work is to establish a general method of pre-processing these inputs by comparing the inputs calculated from different pooling strategies, distance metrics and audio characteristics, also taking into account the computing time to obtain them. We also establish the most effective combination of inputs to be delivered to the CNN in order to establish the most efficient way to extract the limits of the structure of the music pieces. With an adequate combination of input matrices and pooling strategies we obtain a measurement accuracy $F_1$ of 0.411 that outperforms the current one obtained under the same conditions.",0,Human
"A common writing style for statistical results are the recommendations of the American Psychology Association, known as APA-style. However, in practice, writing styles vary as reports are not 100% following APA-style or parameters are not reported despite being mandatory. In addition, the statistics are not reported in isolation but in context of experimental conditions investigated and the general topic. We address these challenges by proposing a flexible pipeline STEREO based on active wrapper induction and unsupervised aspect extraction. We applied our pipeline to the over 100,000 documents in the CORD-19 dataset. It required only 0.25% of the corpus (about 500 documents) to learn statistics extraction rules that cover 95% of the sentences in CORD-19. The statistic extraction has nearly 100% precision on APA-conform and 95% precision on non-APA writing styles. In total, we were able to extract 113k reported statistics, of which only <1% is APA conform. We could extract in 46% the correct conditions from APA-conform reports (30% for non-APA). The best model for topic extraction achieves a precision of 75% on statistics reported in APA style (73% for non-APA conform). We conclude that STEREO is a good foundation for automatic statistic extraction and future developments for scientific paper analysis. Particularly the extraction of non-APA conform reports is important and allows applications such as giving feedback to authors about what is missing and could be changed.",0,Human
"This paper studies the connection between generalized $q$ entropies and a generalized Fisher information. Generalized $q$ entropies are an expansion upon classical Shannon entropy and have been applied in statistical mechanics, information theory, and signal processing. Generalized Fisher information characterizes how much information a probability distribution contains regarding a particular parameter. In this paper we establish an inequality related to Cramer Rao and this inequality links $q$ entropy and Fisher information. We show that this inequality works for a wide range of probability distributions and allows us to derive lower bounds on variances of unbiased estimators of interest parameters. Results of this kind are useful for designing and analyzing statistical inference methods across different disciplines.",1,AI
"This paper looks into stability of linear structural equation models (SEMs) in causal inference studies. SEMs have been used widely to investigate complex systems and infer causal relations among variables. But stability and robustness against measurement errors and omissions is an important consideration. The paper investigates stability under different circumstances such as varying sample sizes, measurement error, and omitted variables systematically. Results show that SEMs can become unstable under some conditions; moreover, there is strong influence from measurement errors and omissions on stability. Findings from this work are important for making sure SEMs are reliable and valid in causal inference and provide direction for future research.",1,AI
"Visual exploration of high-dimensional real-valued datasets is a fundamental task in exploratory data analysis (EDA). Existing methods use predefined criteria to choose the representation of data. There is a lack of methods that (i) elicit from the user what she has learned from the data and (ii) show patterns that she does not know yet. We construct a theoretical model where identified patterns can be input as knowledge to the system. The knowledge syntax here is intuitive, such as ""this set of points forms a cluster"", and requires no knowledge of maths. This background knowledge is used to find a Maximum Entropy distribution of the data, after which the system provides the user data projections in which the data and the Maximum Entropy distribution differ the most, hence showing the user aspects of the data that are maximally informative given the user's current knowledge. We provide an open source EDA system with tailored interactive visualizations to demonstrate these concepts. We study the performance of the system and present use cases on both synthetic and real data. We find that the model and the prototype system allow the user to learn information efficiently from various data sources and the system works sufficiently fast in practice. We conclude that the information theoretic approach to exploratory data analysis where patterns observed by a user are formalized as constraints provides a principled, intuitive, and efficient basis for constructing an EDA system.",0,Human
"The spectral gap $\gamma$ of a finite, ergodic, and reversible Markov chain is an important parameter measuring the asymptotic rate of convergence. In applications, the transition matrix $P$ may be unknown, yet one sample of the chain up to a fixed time $n$ may be observed. We consider here the problem of estimating $\gamma$ from this data. Let $\pi$ be the stationary distribution of $P$, and $\pi_\star = \min_x \pi(x)$. We show that if $n = \tilde{O}\bigl(\frac{1}{\gamma \pi_\star}\bigr)$, then $\gamma$ can be estimated to within multiplicative constants with high probability. When $\pi$ is uniform on $d$ states, this matches (up to logarithmic correction) a lower bound of $\tilde{\Omega}\bigl(\frac{d}{\gamma}\bigr)$ steps required for precise estimation of $\gamma$. Moreover, we provide the first procedure for computing a fully data-dependent interval, from a single finite-length trajectory of the chain, that traps the mixing time $t_{\text{mix}}$ of the chain at a prescribed confidence level. The interval does not require the knowledge of any parameters of the chain. This stands in contrast to previous approaches, which either only provide point estimates, or require a reset mechanism, or additional prior knowledge. The interval is constructed around the relaxation time $t_{\text{relax}} = 1/\gamma$, which is strongly related to the mixing time, and the width of the interval converges to zero roughly at a $1/\sqrt{n}$ rate, where $n$ is the length of the sample path.",0,Human
"Recommender System research suffers currently from a disconnect between the size of academic data sets and the scale of industrial production systems. In order to bridge that gap we propose to generate more massive user/item interaction data sets by expanding pre-existing public data sets. User/item incidence matrices record interactions between users and items on a given platform as a large sparse matrix whose rows correspond to users and whose columns correspond to items. Our technique expands such matrices to larger numbers of rows (users), columns (items) and non zero values (interactions) while preserving key higher order statistical properties. We adapt the Kronecker Graph Theory to user/item incidence matrices and show that the corresponding fractal expansions preserve the fat-tailed distributions of user engagements, item popularity and singular value spectra of user/item interaction matrices. Preserving such properties is key to building large realistic synthetic data sets which in turn can be employed reliably to benchmark Recommender Systems and the systems employed to train them. We provide algorithms to produce such expansions and apply them to the MovieLens 20 million data set comprising 20 million ratings of 27K movies by 138K users. The resulting expanded data set has 10 billion ratings, 864K items and 2 million users in its smaller version and can be scaled up or down. A larger version features 655 billion ratings, 7 million items and 17 million users.",0,Human
This paper introduces an innovative approach to color face recognition based on quaternion matrices. Using such matrices allows us to represent facial images better than traditional real numbers. First this method uses deep CNNs to extract features; then it applies regression using quaternion matrices to map those features into a compact yet discriminative representation. Performance is evaluated against multiple public datasets and results show this method performs significantly better than leading methods using real valued matrices. Results show effectiveness of this new method for recognition and suggest it has practical value for vision tasks and biometrics.,1,AI
"This study examines how to improve visual place recognition using Network based methods through the use of Filter Early Match Late (FEML). In this approach we apply a filter step before performing matching to reduce the number of comparisons needed. This is done by training a Convolutional Neural Network to estimate likelihood that two images will match. Then these filtered images are compared using an algorithm based on descriptors. Results show significant improvement over previous methods using the RobotCar Seasons dataset. Results also indicate robust performance independent of lighting, weather and season. The paper also reveals insights into the workings of FEML which show that filters focus on key regions such as edges and facades that contain relevant information for VPR. Insights like this can help to guide future work. Overall, results show effectiveness of using FEML for Network based VPR and also provide insight into core mechanisms behind the approach.",1,AI
"This paper looks at optimized broadcast algorithms for deep learning tasks on clusters with many GPUs connected by InfiniBand networks. Comparing two widely used libraries, MPI and NCCL, researchers evaluate latency and throughput. Results indicate NCCL excels both in latency and throughput over MPI, so they recommend NCCL as preferable choice for deep learning. Authors stress that optimization of broadcast algorithms is important for high performance; NCCL performs well for these kinds of tasks.",1,AI
This paper investigates design of mechanisms that maximize auction revenue using auctions that distribute items proportionally but not exactly proportional. These auctions are common in fields like telecom and transport because bidders have different budgets and sometimes different values for the same thing. This paper introduces a new mechanism which considers both budgets and values of bidders while also maximizing revenue for auction organizers. Performance of this mechanism is assessed through simulation and compared to other methods in the literature. Results show that proposed mechanism excels in revenue and efficiency compared to other mechanisms. In conclusion the paper discusses practical implications for designing auction mechanisms.,1,AI
"This work introduces a new method for producing high quality synthesis via separation of underlying factors of variation. The proposed method seeks to resolve shortcomings of current synthesis approaches by separating those latent factors and generating new samples based on an improved representation that is easier to understand and control. Results from experiments show the effectiveness of this new method for synthesis quality and factor separation performance compared to leading methods on selected benchmarks. Results here advance toward better controllable and understandable synthesis methods which have future promise in diverse fields including graphics, music and speech synthesis, and data augmentation.",1,AI
"Since the 1990s, there have been significant advances in the technology space and the e-Commerce area, leading to an exponential increase in demand for cashless payment solutions. This has led to increased demand for credit cards, bringing along with it the possibility of higher credit defaults and hence higher delinquency rates, over a period of time. The purpose of this research paper is to build a contemporary credit scoring model to forecast credit defaults for unsecured lending (credit cards), by employing machine learning techniques. As much of the customer payments data available to lenders, for forecasting Credit defaults, is imbalanced (skewed), on account of a limited subset of default instances, this poses a challenge for predictive modelling. In this research, this challenge is addressed by deploying Synthetic Minority Oversampling Technique (SMOTE), a proven technique to iron out such imbalances, from a given dataset. On running the research dataset through seven different machine learning models, the results indicate that the Light Gradient Boosting Machine (LGBM) Classifier model outperforms the other six classification techniques. Thus, our research indicates that the LGBM classifier model is better equipped to deliver higher learning speeds, better efficiencies and manage larger data volumes. We expect that deployment of this model will enable better and timely prediction of credit defaults for decision-makers in commercial lending institutions and banks.",0,Human
"Deployment of 5G wireless communication systems has become essential for a wide array of applications like IoT, autonomous driving and smart cities. To exploit full potential of 5G we need high speed, low latency and reliability for wireless connectivity. Millimeter wave (mm wave) frequency use is one promising way to meet these goals. However propagation characteristics of mm waves differ significantly from lower frequency bands and thus pose major design challenges. This paper reports experimental studies of propagation at small scale, within local areas and transitional zones. We conducted this study in an urban setting using a custom mm wave testbed in 28 GHz band. Results measured included path loss, delay spread and angular spread under different scenarios like clear line of sight, not clear line of sight and transitional scenarios. Study showed that propagation characteristics of mm waves vary greatly by environment and scenario; customized antennas and beam forming design are needed to achieve reliable communication. LOS environments are generally good for mm wave propagation but NLOS and transitional conditions cause high attenuation and scattering. Overall this work offers important insight into propagation characteristics for 5G communication at small scales and local areas and highlights need for further research and development to overcome obstacles and ensure reliable deployment across diverse environments.",1,AI
"There has been a remarkable increase in the data exchange over web and the widespread use of digital media. As a result, multimedia data transfers also had a boost up. The mounting interest with reference to digital watermarking throughout the last decade is certainly due to the increase in the need of copyright protection of digital content. This is also enhanced due to commercial prospective. Applications of video watermarking in copy control, broadcast monitoring, fingerprinting, video authentication, copyright protection etc is immensely rising. The main aspects of information hiding are capacity, security and robustness. Capacity deals with the amount of information that can be hidden. The skill of anyone detecting the information is security and robustness refers to the resistance to modification of the cover content before concealed information is destroyed. Video watermarking algorithms normally prefers robustness. In a robust algorithm it is not possible to eliminate the watermark without rigorous degradation of the cover content. In this paper, we introduce the notion of Video Watermarking and the features required to design a robust watermarked video for a valuable application. We review several algorithms, and introduce frequently used key techniques. The aim of this paper is to focus on the various domains of video watermarking techniques. The majority of the reviewed methods based on video watermarking emphasize on the notion of robustness of the algorithm.",0,Human
"This paper introduces a new method for preserving privacy in image annotation called CPAR, short for Cloud Assisted Privacy Preservation via Randomized KD Forest. Authors are concerned about privacy issues arising from embedding sensitive personal information into images and their corresponding annotations. They introduce an annotation system relying on cloud services and use KD forest as a data structure to securely store and process these annotations. This system allows users to annotate images while keeping sensitive details secret from cloud providers. Experiments show that this CPAR method offers strong privacy protection and performs better than competing methods regarding accuracy and efficiency.",1,AI
"We have designed, fabricated, and successfully tested a prototype mixed-signal, 28x28-binary-input, 10-output, 3-layer neuromorphic network (""MLP perceptron""). It is based on embedded nonvolatile floating-gate cell arrays redesigned from a commercial 180-nm NOR flash memory. The arrays allow precise (~1%) individual tuning of all memory cells, having long-term analog-level retention and low noise. Each array performs a very fast and energy-efficient analog vector-by-matrix multiplication, which is the bottleneck for signal propagation in most neuromorphic networks. All functional components of the prototype circuit, including 2 synaptic arrays with 101,780 floating-gate synaptic cells, 74 analog neurons, and the peripheral circuitry for weight adjustment and I/O operations, have a total area below 1 mm^2. Its testing on the common MNIST benchmark set (at this stage, with a relatively low weight import precision) has shown a classification fidelity of 94.65%, close to the 96.2% obtained in simulation. The classification of one pattern takes less than 1 us time and ~20 nJ energy - both numbers much better than for digital implementations of the same task. Estimates show that this performance may be further improved using a better neuron design and a more advanced memory technology, leading to a >10^2 advantage in speed and a >10^4 advantage in energy efficiency over the state-of-the-art purely digital (GPU and custom) circuits, at classification of large, complex patterns.",0,Human
"This paper studies link prediction methods using graphs to forecast relationships among human phenotypes and genes. Phenotypes refer to observable physical or biochemical characteristics of individuals whereas genes encode for these traits. Relationships between phenotypes and genes tend to be complicated and hard to predict; better understanding of these relationships could offer important clues regarding development and treatment of genetic illnesses. Using data from public databases such as those on gene phenotype association and protein interaction, a heterogeneous graph is built. Different graph based methods for link prediction are then applied to this graph to find new relationships among phenotypes and genes; they include methods based on node similarity, path length and matrix factorization. Performance of various methods is assessed using cross validation and other common metrics. Results indicate that graph methods effectively predict new links among phenotypes and genes and performance can also be enhanced by combining multiple methods. Overall, the paper shows promise that graph methods are good predictors for relationships among human phenotypes and genes and provides a useful way forward for future research. Results might lead to new drug development and greater insight into genetics of human traits.",1,AI
"This paper introduces a new method for learning Lie algebras from unlabelled data pairs. Learning Lie algebras has received much attention in mathematics, but existing approaches require labelled data or strong structural assumptions. This study proposes an algorithm based on deep neural networks which learns Lie algebras using data pairs without any requirement of labels or strong assumptions. It employs a combination of unsupervised and supervised learning to learn the structure of Lie algebra and evaluates performance on various datasets to validate effectiveness. Results indicate that the proposed method excels in both accuracy and efficiency over previous methods and also shows promise for use in diverse areas that rely on learning Lie algebras like computer graphics and robotics.",1,AI
"We consider the numerical stability of the parameter recovery problem in Linear Structural Equation Model ($\LSEM$) of causal inference. A long line of work starting from Wright (1920) has focused on understanding which sub-classes of $\LSEM$ allow for efficient parameter recovery. Despite decades of study, this question is not yet fully resolved. The goal of this paper is complementary to this line of work; we want to understand the stability of the recovery problem in the cases when efficient recovery is possible. Numerical stability of Pearl's notion of causality was first studied in Schulman and Srivastava (2016) using the concept of condition number where they provide ill-conditioned examples. In this work, we provide a condition number analysis for the $\LSEM$. First we prove that under a sufficient condition, for a certain sub-class of $\LSEM$ that are \emph{bow-free} (Brito and Pearl (2002)), the parameter recovery is stable. We further prove that \emph{randomly} chosen input parameters for this family satisfy the condition with a substantial probability. Hence for this family, on a large subset of parameter space, recovery is numerically stable. Next we construct an example of $\LSEM$ on four vertices with \emph{unbounded} condition number. We then corroborate our theoretical findings via simulations as well as real-world experiments for a sociology application. Finally, we provide a general heuristic for estimating the condition number of any $\LSEM$ instance.",0,Human
"Cybercrime markets support the development and diffusion of new attack technologies, vulnerability exploits, and malware. Whereas the revenue streams of cyber attackers have been studied multiple times in the literature, no quantitative account currently exists on the economics of attack acquisition and deployment. Yet, this understanding is critical to characterize the production of (traded) exploits, the economy that drives it, and its effects on the overall attack scenario. In this paper we provide an empirical investigation of the economics of vulnerability exploitation, and the effects of market factors on likelihood of exploit. Our data is collected first-handedly from a prominent Russian cybercrime market where the trading of the most active attack tools reported by the security industry happens. Our findings reveal that exploits in the underground are priced similarly or above vulnerabilities in legitimate bug-hunting programs, and that the refresh cycle of exploits is slower than currently often assumed. On the other hand, cybercriminals are becoming faster at introducing selected vulnerabilities, and the market is in clear expansion both in terms of players, traded exploits, and exploit pricing. We then evaluate the effects of these market variables on likelihood of attack realization, and find strong evidence of the correlation between market activity and exploit deployment. We discuss implications on vulnerability metrics, economics, and exploit measurement.",0,Human
"We consider finite horizon reach-avoid problems for discrete time stochastic systems. Our goal is to construct upper bound functions for the reach-avoid probability by means of tractable convex optimization problems. We achieve this by restricting attention to the span of Gaussian radial basis functions and imposing structural assumptions on the transition kernel of the stochastic processes as well as the target and safe sets of the reach-avoid problem. In particular, we require the kernel to be written as a Gaussian mixture density with each mean of the distribution being affine in the current state and input and the target and safe sets to be written as intersections of quadratic inequalities. Taking advantage of these structural assumptions, we formulate a recursion of semidefinite programs where each step provides an upper bound to the value function of the reach- avoid problem. The upper bounds provide a performance metric to which any suboptimal control policy can be compared, and can themselves be used to construct suboptimal control policies. We illustrate via numerical examples that even if the resulting bounds are conservative, the associated control policies achieve higher reach-avoid probabilities than heuristic controllers for problems of large state-input space dimensions (more than 20). The results presented in this paper, far exceed the limits of current approximation methods for reach-avoid problems in the specific class of stochastic systems considered.",0,Human
"This study investigates allocation of locally generated electricity among renewable energy communities. It examines current methods of energy distribution and the challenges these communities face regarding storage and distribution of power. Research also considers potential for distributed energy systems where production and consumption occur within the same community; these systems can improve energy efficiency and decrease reliance on central power grids. Also discussed are roles of government policy and regulation in fostering renewable energy communities and advantages like enhanced energy security, lower emissions and stronger local economies. Results of study show these communities have great potential to reshape the energy landscape and contribute to a more sustainable future. However, effective policies and regulation are necessary to promote growth and development of such communities.",1,AI
This paper investigates the importance of using an appropriate method for decolorizing images that are relevant to perception when performing scene classification. Performance evaluation shows that decolorization has a significant effect on recognition performance and comparison to traditional methods of converting to grayscale. Results indicate that proposed method based on perceptual relevance outperforms traditional grayscale conversion methods in terms of accuracy. Results also highlight that preserving perceptual relevance during decolorization is important for successful classification. Research findings emphasize consideration of human visual systems in image processing and point to perceptual relevance as a promising way to improve classification performance.,1,AI
"This paper looks at weaknesses in ML systems when faced with image scaling attacks and suggests a new way to defend against them. Attacks manipulate size and resolution of images to confuse ML systems into classifying them incorrectly. The paper also investigates various vulnerabilities that attackers might exploit like dependency on input, masking gradients and attacks that invert models. Then they propose a new defense mechanism involving adding carefully selected adversarial samples to the input data that could reduce success of scaling attacks. Experiments show this defense works well using different benchmark datasets. In summary, results point out the significance of understanding interactions among vulnerabilities and present a new approach to reducing effect of image scaling attacks.",1,AI
"In Federated Learning (FL), a strong global model is collaboratively learned by aggregating the clients' locally trained models. Although this allows no need to access clients' data directly, the global model's convergence often suffers from data heterogeneity. This paper suggests that forgetting could be the bottleneck of global convergence. We observe that fitting on biased local distribution shifts the feature on global distribution and results in forgetting of global knowledge. We consider this phenomenon as an analogy to Continual Learning, which also faces catastrophic forgetting when fitted on the new task distribution. Based on our findings, we hypothesize that tackling down the forgetting in local training relives the data heterogeneity problem. To this end, we propose a simple yet effective framework Federated Local Self-Distillation (FedLSD), which utilizes the global knowledge on locally available data. By following the global perspective on local data, FedLSD encourages the learned features to preserve global knowledge and have consistent views across local models, thus improving convergence without compromising data privacy. Under our framework, we further extend FedLSD to FedLS-NTD, which only considers the not-true class signals to compensate noisy prediction of the global model. We validate that both FedLSD and FedLS-NTD significantly improve the performance in standard FL benchmarks in various setups, especially in the extreme data heterogeneity cases.",0,Human
"This paper introduces a new way to access secondary spectrum with requirements based on Signal to Interference plus Noise Ratio (SINR). Using transformations of constraints, this allows better use of spectrum resource. This proposed method is tested using simulations and compared to other conventional methods by means of serving users and spectrum efficiency. Results indicate significant improvement for secondary spectrum access and show promise for practical deployment. Insights from this work are important for researchers and practitioners in spectrum management and suggest opportunities for future work focusing on optimizing spectrum access with SINR criteria.",1,AI
"This paper introduces a pipeline for automatically extracting statistical reports and experimental conditions directly from scientific papers using machine learning. The pipeline includes three major parts: a preprocessing module, a module that extracts statistics reports and an extraction module for experimental conditions. Preprocessing cleans and organizes raw text from scientific papers; statistical report extraction identifies and retrieves reports; experimental condition extraction module then isolates experimental conditions related to identified statistical reports. Evaluation of this pipeline using data sets of papers results in high precision and recall. Proposed pipeline greatly assists automation of key information extraction from papers, thereby enhancing efficiency in scientific research.",1,AI
"Floating point arithmetic is very common in scientific computing and engineering applications. But because of imprecisions in floating point arithmetic, there are errors in numerical algorithms. This can be especially dangerous in safety critical systems. Researchers have therefore proposed many different ways to formally verify correctness of floating point algorithms. This paper introduces a formal framework for real sound compilation which is a technique that generates code for numerical algorithms which preserve their semantics precisely. This framework relies on semantics of IEEE 754 floating point arithmetic and combines program analysis with type theory and verification methods to ensure correctness. We show efficacy of our framework by using it on several numerical algorithms such as matrix multiplication and linear solvers and showing that generated code is both correct and efficient. Our method introduces a new tool for developing verified numerical software that can be used in safety critical systems.",1,AI
"We propose NormalGAN, a fast adversarial learning-based method to reconstruct the complete and detailed 3D human from a single RGB-D image. Given a single front-view RGB-D image, NormalGAN performs two steps: front-view RGB-D rectification and back-view RGBD inference. The final model was then generated by simply combining the front-view and back-view RGB-D information. However, inferring backview RGB-D image with high-quality geometric details and plausible texture is not trivial. Our key observation is: Normal maps generally encode much more information of 3D surface details than RGB and depth images. Therefore, learning geometric details from normal maps is superior than other representations. In NormalGAN, an adversarial learning framework conditioned by normal maps is introduced, which is used to not only improve the front-view depth denoising performance, but also infer the back-view depth image with surprisingly geometric details. Moreover, for texture recovery, we remove shading information from the front-view RGB image based on the refined normal map, which further improves the quality of the back-view color inference. Results and experiments on both testing data set and real captured data demonstrate the superior performance of our approach. Given a consumer RGB-D sensor, NormalGAN can generate the complete and detailed 3D human reconstruction results in 20 fps, which further enables convenient interactive experiences in telepresence, AR/VR and gaming scenarios.",0,Human
"This study investigates the interplay between human pose estimation and robustness. Through careful review of literature and experimentation, it shows how current methods for estimating human pose are vulnerable to adversarial attacks and identifies important factors contributing to this vulnerability. It also sets up a benchmark and metrics for assessing robust performance under attack; thus, providing a standard framework for future research. Results indicate that there is a pressing need for improved robustness and offer a basis for developing new algorithms which perform better in practical situations.",1,AI
"We develop here a computationally effective approach for producing high-quality $\mathcal{H}_\infty$-approximations to large scale linear dynamical systems having multiple inputs and multiple outputs (MIMO). We extend an approach for $\mathcal{H}_\infty$ model reduction introduced by Flagg, Beattie, and Gugercin for the single-input/single-output (SISO) setting, which combined ideas originating in interpolatory $\mathcal{H}_2$-optimal model reduction with complex Chebyshev approximation. Retaining this framework, our approach to the MIMO problem has its principal computational cost dominated by (sparse) linear solves, and so it can remain an effective strategy in many large-scale settings. We are able to avoid computationally demanding $\mathcal{H}_\infty$ norm calculations that are normally required to monitor progress within each optimization cycle through the use of ""data-driven"" rational approximations that are built upon previously computed function samples. Numerical examples are included that illustrate our approach. We produce high fidelity reduced models having consistently better $\mathcal{H}_\infty$ performance than models produced via balanced truncation; these models often are as good as (and occasionally better than) models produced using optimal Hankel norm approximation as well. In all cases considered, the method described here produces reduced models at far lower cost than is possible with either balanced truncation or optimal Hankel norm approximation.",0,Human
"With the explosive growth in the number of pictures taken by smartphones, organizing and searching pictures has become important tasks. To efficiently fulfill these tasks, the key enabler is annotating images with proper keywords, with which keyword-based searching and organizing become available for images. Currently, smartphones usually synchronize photo albums with cloud storage platforms, and have their images annotated with the help of cloud computing. However, the ""offloading-to-cloud"" solution may cause privacy breach, since photos from smart photos contain various sensitive information. For privacy protection, existing research made effort to support cloud-based image annotation on encrypted images by utilizing cryptographic primitives. Nevertheless, for each annotation, it requires the cloud to perform linear checking on the large-scale encrypted dataset with high computational cost. This paper proposes a cloud-assisted privacy-preserving image annotation with randomized kd-forest, namely CPAR. With CPAR, users are able to automatically assign keywords to their images by leveraging the power of cloud with privacy protected. CPAR proposes a novel privacy-preserving randomized kd-forest structure, which significantly improves the annotation performance compared with existing research. Thorough analysis is carried out to demonstrate the security of CPAR. Experimental evaluation on the well-known IAPR TC-12 dataset validates the efficiency and effectiveness of CPAR.",0,Human
"This paper introduces a new design of joint precoding at source and relay for multiple input multiple output (MIMO) systems using two way relaying. Precoding is performed to minimize mean squared error (MSE) and reduce interference among users. A new framework is presented for jointly designing precoding at source and relay; this new framework improves overall system performance. Problem formulation uses constrained optimization where objective is to minimize MSE while meeting power constraints and SNR requirements. An iterative algorithm is introduced that alternates precoding design for source and relay and converges to near optimal solutions with low computational burden. Results show this design performs better than leading approaches in MSE, user interference and system performance overall. Proposed method using MSE criterion shows promise for MIMO systems and can provide high quality service and less interference. Results might also be applied to future communication standards like 5G and beyond.",1,AI
"This research introduces a new way of training deep neural nets called Viser (Visual Self regularization). Viser includes an extra branch in the network which learns to reconstruct images. This reconstruction branch functions as a regularizer that discourages deviations from the input image and thereby forces the model to learn robust features. Results on different benchmarks show that Viser boosts performance of deep networks. Furthermore, this paper also analyzes learned features and shows that Viser leads to learning features that are significant and discriminative.",1,AI
"Adversarial examples are often cited by neuroscientists and machine learning researchers as an example of how computational models diverge from biological sensory systems. Recent work has proposed adding biologically-inspired components to visual neural networks as a way to improve their adversarial robustness. One surprisingly effective component for reducing adversarial vulnerability is response stochasticity, like that exhibited by biological neurons. Here, using recently developed geometrical techniques from computational neuroscience, we investigate how adversarial perturbations influence the internal representations of standard, adversarially trained, and biologically-inspired stochastic networks. We find distinct geometric signatures for each type of network, revealing different mechanisms for achieving robust representations. Next, we generalize these results to the auditory domain, showing that neural stochasticity also makes auditory models more robust to adversarial perturbations. Geometric analysis of the stochastic networks reveals overlap between representations of clean and adversarially perturbed stimuli, and quantitatively demonstrates that competing geometric effects of stochasticity mediate a tradeoff between adversarial and clean performance. Our results shed light on the strategies of robust perception utilized by adversarially trained and stochastic networks, and help explain how stochasticity may be beneficial to machine and biological computation.",0,Human
This paper analyzes and calibrates univariate signals for slip detection. Evaluation of methods for slip detection using signals like normal force and friction force is at the core of this research. Results show that various factors affect accuracy such as noise level in signals and selection of thresholds for detection. Analysis leads to development of calibration techniques for improving reliability of slip detection in practical use. Proposed calibration method is validated experimentally and results show effectiveness in actual situations. Findings from this work could guide design and development of wearable devices for slip detection and prevention.,1,AI
"Regression analysis-based approaches have been widely studied for face recognition (FR) in the past several years. More recently, to better deal with some difficult conditions such as occlusions and illumination, nuclear norm based matrix regression methods have been proposed to characterize the low-rank structure of the error image, which generalize the one-dimensional, pixel-based error model to the two-dimensional structure. These methods, however, are inherently devised for grayscale image based FR and without exploiting the color information which is proved beneficial for FR of color face images. Benefiting from quaternion representation, which is capable of encoding the cross-channel correlation of color images, we propose a novel color FR method by formulating the color FR problem as a nuclear norm based quaternion matrix regression (NQMR). We further develop a more robust model called R-NQMR by using the logarithm of the nuclear norm, instead of the original nuclear norm, which adaptively assigns weights on different singular values, and then extend it to deal with the mixed noise. The proposed models, then, are solved using the effective alternating direction multiplier method (ADMM). Experiments on several public face databases demonstrate the superior performance and efficacy of the proposed approaches for color FR, especially for some difficult conditions (occlusion, illumination and mixed noise) over some state-of-the-art regression analysis-based approaches.",0,Human
"This paper describes development and evaluation of Odys, a high performance search engine that combines tightly integrated components from database management systems (DBMS) and database oriented information retrieval (DBIR). The aim is to overcome scalability and efficiency issues typical of standard search engines by using DBIR methods that blend together the features of both. Evaluation uses a large data set and compares Odys favorably against leading engines. Results show clear advantages in speed and retrieval quality compared to current engines. This research also shows promise for large scale applications through integration of closely related DB and IR elements.",1,AI
This paper investigates transmit beamforming strategies for exploiting interference using channels in Cognitive Radio Networks (CRNs). The paper focuses on designing and implementing an algorithm that uses game theory and optimization techniques to maximize performance. Results from simulations and experiments show that proposed algorithm improves performance of CRNs by increasing capacity and reliability. Results of this work are important for designing and deploying CRNs and show that transmit beamforming is a strong tool for enhancing performance.,1,AI
"This paper introduces a new approach to improve speech recognition for robots through mimicking localization of sound sources using binaural audition. Authors want to create an auditory system that sounds more human so robots can distinguish speech better in noisy places. Using two microphones like ears, the system locates sounds and isolates targeted speech from other noises. Results show significant improvement in speech recognition compared to previous methods. Authors conclude that this new method could be a major advance and may help develop more sophisticated and human-like robots.",1,AI
"Non-orthogonal multiple access (NOMA) has shown potential for scalable multicast of video data. However, one key drawback for NOMA-based video multicast is the limited number of layers allowed by the embedded successive interference cancellation algorithm, failing to meet satisfaction of heterogeneous receivers. We propose a novel receiver-driven superposed video multicast (Supcast) scheme by integrating Softcast, an analog-like transmission scheme, into the NOMA-based system to achieve high bandwidth efficiency as well as gradual decoding quality proportional to channel conditions at receivers. Although Softcast allows gradual performance by directly transmitting power-scaled transformation coefficients of frames, it suffers performance degradation due to discarding coefficients under insufficient bandwidth and its power allocation strategy cannot be directly applied in NOMA due to interference. In Supcast, coefficients are grouped into chunks, which are basic units for power allocation and superposition scheduling. By bisecting chunks into base-layer chunks and enhanced-layer chunks, the joint power allocation and chunk scheduling is formulated as a distortion minimization problem. A two-stage power allocation strategy and a near-optimal low-complexity algorithm for chunk scheduling based on the matching theory are proposed. Simulation results have shown the advantage of Supcast against Softcast as well as the reference scheme in NOMA under various practical scenarios.",0,Human
"Accurately modeling human decision-making in security is critical to thinking about when, why, and how to recommend that users adopt certain secure behaviors. In this work, we conduct behavioral economics experiments to model the rationality of end-user security decision-making in a realistic online experimental system simulating a bank account. We ask participants to make a financially impactful security choice, in the face of transparent risks of account compromise and benefits offered by an optional security behavior (two-factor authentication). We measure the cost and utility of adopting the security behavior via measurements of time spent executing the behavior and estimates of the participant's wage. We find that more than 50% of our participants made rational (e.g., utility optimal) decisions, and we find that participants are more likely to behave rationally in the face of higher risk. Additionally, we find that users' decisions can be modeled well as a function of past behavior (anchoring effects), knowledge of costs, and to a lesser extent, users' awareness of risks and context (R2=0.61). We also find evidence of endowment effects, as seen in other areas of economic and psychological decision-science literature, in our digital-security setting. Finally, using our data, we show theoretically that a ""one-size-fits""-all emphasis on security can lead to market losses, but that adoption by a subset of users with higher risks or lower costs can lead to market gains.",0,Human
"This paper studies how federated learning can preserve global knowledge while keeping users' private data safe. Traditional federated learning trains local models using users' data and aggregates them to produce a global model. But sharing user data risks privacy and makes them vulnerable to attacks. Therefore, this paper introduces a new method called ""not true self knowledge distillation"" that avoids these issues. In this method, local models are trained using distorted versions of data instead of raw user data. These models share core features but hide identities. Distillation of local models into global models prevents revealing individual data, thus preserving privacy. Experimental results show this method performs similarly to traditional federated learning and also protects privacy. Contributions of this work include reducing privacy concerns in federated learning and promoting preservation of global knowledge without sacrificing privacy of individuals. This method could apply broadly including healthcare, finance, and transportation where privacy matters greatly.",1,AI
"This paper examines mapping equivalence for symbolic sequences and both theoretical underpinnings and practical applications are explored. We start by defining mapping equivalence as an important equivalence relation for symbolic sequences. Properties of mapping equivalence are further discussed such as its relationship to other equivalence relations and use in classifying sequences. Applications are considered for different fields including biology, computer science and linguistics; we show how this equivalence can be applied to tasks like pattern recognition and clustering. Finally we consider current open questions and future research avenues related to equivalence mappings.",1,AI
"Wide Area Monitoring Systems (WAMS) utilizing synchrophasor measurements is considered one of the essential parts in smart grids that enable system operators to monitor, operate, and control power systems in wide geographical area. On the other hand, high-speed, reliable and scalable data communication infrastructure is crucial in both construction and operation of WAMS. Universal mobile Telecommunication System (UMTS), the 3G standard for mobile communication networks, was developed to provide high speed data transmission with reliable service performance for mobile users. Therefore, UMTS is considered a promising solution for providing a communication infrastructure for WAMS. 3G based EWAMS (Egyptian wide area Monitoring System) is designed and implemented in Egypt through deployment a number of frequency disturbance recorders (FDRs) devices on a live 220kV/500kV Egyptian grid in cooperation with the Egyptian Electricity Transmission Company (EETC). The developed EWAMS can gather information from 11 FDRs devices which are geographically dispersed throughout the boundary of the Egyptian power grid and to a remote data management center located at Helwan University. The communication performance for the developed EWAMS in terms of communication time delay, throughput, and percentage of wasted bandwidth are studied in this paper. The results showed that the system can achieve successfully the communication requirements needed by various wide area monitoring applications.",0,Human
"This paper introduces DialogueBERT, a new model based on self supervised learning that is specialized for processing dialogues and understanding natural language in conversational AI systems. It details both the architecture and method of training this model using large corpus of dialogue data. Performance evaluations are conducted on different downstream tasks including sentiment analysis, intent classification, and QA; results indicate that this model generally performs better compared to other pretrained models. Fine tuning for specific tasks further improves performance. An investigation into component contributions to performance concludes that important elements include the attention mechanism and the MLM objective. In summary, this paper demonstrates that DialogueBERT is a powerful and flexible model for dialogue AI applications and that leveraging self supervised learning results in improved understanding of dialogue in conversational systems.",1,AI
"This research looks at improving the accuracy of segmentation of images captured by UAVs (unmanned aerial vehicles) using a new deep learning framework named uvid net. Recently, UAVs are being widely used for diverse tasks like mapping, surveillance and environmental monitoring. But processing large amounts of data collected by UAVs is hard; especially for segmentation into meaningful classes. Using a novel framework, uvid net exploits temporal information within videos to overcome this obstacle. It uses 3D convolutional neural networks to extract spatial and temporal features from video frames, followed by feature pyramid networks to generate multiscale feature maps. Then a decoder network generates final segmentation maps. Results show that uvid net performs better than leading methods based on accuracy, especially distinguishing hard to discern objects such as cars and buildings. Overall, results indicate that uvid net holds promise for segmentation of videos captured by UAVs. Incorporating temporal information via 3D CNNs greatly improves segmentation accuracy and is important for tasks such as urban planning, disaster response and precision farming.",1,AI
"Kernel machines often yield superior predictive performance on various tasks; however, they suffer from severe computational challenges. In this paper, we show how to overcome the important challenge of speeding up kernel machines. In particular, we develop a parallel block minimization framework for solving kernel machines, including kernel SVM and kernel logistic regression. Our framework proceeds by dividing the problem into smaller subproblems by forming a block-diagonal approximation of the Hessian matrix. The subproblems are then solved approximately in parallel. After that, a communication efficient line search procedure is developed to ensure sufficient reduction of the objective function value at each iteration. We prove global linear convergence rate of the proposed method with a wide class of subproblem solvers, and our analysis covers strongly convex and some non-strongly convex functions. We apply our algorithm to solve large-scale kernel SVM problems on distributed systems, and show a significant improvement over existing parallel solvers. As an example, on the covtype dataset with half-a-million samples, our algorithm can obtain an approximate solution with 96% accuracy in 20 seconds using 32 machines, while all the other parallel kernel SVM solvers require more than 2000 seconds to achieve a solution with 95% accuracy. Moreover, our algorithm can scale to very large data sets, such as the kdd algebra dataset with 8 million samples and 20 million features.",0,Human
"This paper introduces a new method for detecting objects viewed from different angles using voxelization of 3D features. Current methods usually extract features from 2D images taken from different perspectives which are costly computationally and are often unreliable because of occlusions and changing perspective. In contrast, we use voxelization of 3D space and aggregate features within voxels to produce a 3D feature representation. Results show that this method excels at handling occlusions and perspective changes and improves detection accuracy. We test our technique on various benchmark datasets and find that it outperforms current leading methods both in accuracy and efficiency. Results indicate that voxelizing 3D features is promising for better performing object detection across diverse applications such as autonomous vehicles and robotics.",1,AI
"Domain-Specific Languages (DSLs) help practitioners in contributing solutions to challenges of specific domains. The efficient development of user-friendly DSLs suitable for industrial practitioners with little expertise in modelling still is challenging. For such practitioners, who often do not model on a daily basis, there is a need to foster reduction of repetitive modelling tasks and providing simplified visual representations of DSL parts. For industrial language engineers, there is no methodical support for providing such guidelines or documentation as part of reusable language modules. Previous research either addresses the reuse of languages or guidelines for modelling. For the efficient industrial deployment of DSLs, their combination is essential: the efficient engineering of DSLs from reusable modules that feature integrated documentation and guidelines for industrial practitioners. To solve these challenges, we propose a systematic approach for the industrial engineering of DSLs based on the concept of reusable DSL Building Blocks, which rests on several years of experience in the industrial engineering of DSLs and their deployment to various organizations. We investigated our approach via focus group methods consisting of five participants from industry and research qualitatively. Ultimately, DSL Building Blocks support industrial language engineers in developing better usable DSLs and industrial practitioners in more efficiently achieving their modelling.",0,Human
This paper studies how reuse of space and frequency selectivity influences diversity through multihop OFDM systems. Performance is evaluated based on this diversity and the authors examine how reuse and selectivity affect this performance. They carry out a detailed analysis of their impact on system performance and offer insights into system design. Results indicate that both reuse and selectivity significantly influence performance of OFDM systems and that design of such systems needs to consider these factors. Authors also suggest further research directions for this field.,1,AI
This paper looks at how machine learning algorithms predict credit risk for loans without collateral. It uses different types of models on a real dataset of loan applicants and judges them by measures like accuracy and robustness. Results indicate that decision trees and random forest models do better than previous statistical methods and using ensemble techniques improves model performance further. Feature engineering is important and data preprocessing has to be done carefully beforehand. Research results suggest machine learning algorithms can perform better and more reliably for assessing risk; these results have practical significance for financial firms and similar organizations dealing with loans that are not secured by collateral.,1,AI
"This paper looks at the problem of conflicting naming conventions for topics on Quora, a Q&A website. Authors examine millions of topic pairings and try to predict which ones should merge and win. Using different kinds of machine learning algorithms they investigate what drives name selection and how such naming conventions affect organization and navigation of Quora's large content collection. Results of this research are important for both Quora and other sites where users create much content and need to manage it well. Results point out that combining community participation and automated methods is effective in resolving naming conflicts and enhancing overall user experience.",1,AI
"This paper introduces a systematic process for designing industrial specific languages. There are four main steps in this process: analysis of the domain, design of language, implementation of language, and deployment of language. Domain experts and designers work together to identify core concepts of the domain and the corresponding language features during analysis. Designers define language features by using a higher level language and validate them against certain standards. Next step is to transform these features into actual executable code during implementation. Finally, the resulting language is embedded into target system and evaluated for performance. Results from various case studies show that this approach successfully produces high quality and efficient DSLs.",1,AI
Convolutional Neural Opacity Radiance Fields (CNORF) is a new deep learning technique for addressing radiance transfer issues due to atmospheric scattering. This paper introduces a novel approach to CNORF which relies on a convolutional neural network which predicts radiance fields using scene geometry and atmospheric conditions as inputs. The network is trained on large sets of synthetic scenes and performs very well when applied to real scenes. Results indicate that this new method excels over leading techniques in terms of accuracy and computational speed. Proposed new approach allows for new opportunities for remote sensing and real time rendering of scattering effects.,1,AI
This paper introduces a new communication-efficient parallel algorithm for block minimization in kernel machines. Block minimization is an important problem in machine learning especially in SVMs and related methods. We propose an algorithm called CommBlockMin which partitions data into blocks and uses consensus optimization to parallelize the minimization process. CommBlockMin reduces communication costs by exchanging only essential information among different nodes and eliminates need for centralized coordination. Experiments show CommBlockMin performs better than leading parallel algorithms both in terms of speed and communication efficiency while preserving high prediction accuracy. Analysis also sheds light on Convergence properties of CommBlockMin and influence of its hyper parameters. Contributions of this work include developing scalable and efficient algorithms for machine learning for big data.,1,AI
"Dense Multi-GPU systems have recently gained a lot of attention in the HPC arena. Traditionally, MPI runtimes have been primarily designed for clusters with a large number of nodes. However, with the advent of MPI+CUDA applications and CUDA-Aware MPI runtimes like MVAPICH2 and OpenMPI, it has become important to address efficient communication schemes for such dense Multi-GPU nodes. This coupled with new application workloads brought forward by Deep Learning frameworks like Caffe and Microsoft CNTK pose additional design constraints due to very large message communication of GPU buffers during the training phase. In this context, special-purpose libraries like NVIDIA NCCL have been proposed for GPU-based collective communication on dense GPU systems. In this paper, we propose a pipelined chain (ring) design for the MPI_Bcast collective operation along with an enhanced collective tuning framework in MVAPICH2-GDR that enables efficient intra-/inter-node multi-GPU communication. We present an in-depth performance landscape for the proposed MPI_Bcast schemes along with a comparative analysis of NVIDIA NCCL Broadcast and NCCL-based MPI_Bcast. The proposed designs for MVAPICH2-GDR enable up to 14X and 16.6X improvement, compared to NCCL-based solutions, for intra- and inter-node broadcast latency, respectively. In addition, the proposed designs provide up to 7% improvement over NCCL-based solutions for data parallel training of the VGG network on 128 GPUs using Microsoft CNTK.",0,Human
"The world is facing a tough situation due to the catastrophic pandemic caused by novel coronavirus (COVID-19). The number people affected by this virus are increasing exponentially day by day and the number has already crossed 6.4 million. As no vaccine has been discovered yet, the early detection of patients and isolation is the only and most effective way to reduce the spread of the virus. Detecting infected persons from chest X-Ray by using Deep Neural Networks, can be applied as a time and laborsaving solution. In this study, we tried to detect Covid-19 by classification of Covid-19, pneumonia and normal chest X-Rays. We used five different Convolutional Pre-Trained Neural Network models (VGG16, VGG19, Xception, InceptionV3 and Resnet50) and compared their performance. VGG16 and VGG19 shows precise performance in classification. Both models can classify between three kinds of X-Rays with an accuracy over 92%. Another part of our study was to find the impact of weather factors (temperature, humidity, sun hour and wind speed) on this pandemic using Decision Tree Regressor. We found that temperature, humidity and sun-hour jointly hold 85.88% impact on escalation of Covid-19 and 91.89% impact on death due to Covid-19 where humidity has 8.09% impact on death. We also tried to predict the death of an individual based on age, gender, country, and location due to COVID-19 using the LogisticRegression, which can predict death of an individual with a model accuracy of 94.40%.",0,Human
This paper introduces a framework that integrates model predictive control (MPC) and reinforcement learning (RL) into safe reinforcement learning (SRL) for intelligent vehicles. It takes into account varying states and controls. This approach balances exploration and exploitation and ensures safety. Results show that this new method performs better than traditional MPC and RL at both keeping safety and enhancing performance. This study points towards a promising way to make decisions safely and efficiently in systems with changing constraints.,1,AI
"This paper introduces a new approach to reliably detect compressed and encrypted data. Problems like identifying malware in network traffic or distinguishing secret information in forensic analysis arise frequently. Current methods for detection have shortcomings in terms of reliability, performance or suitability for specific kinds of compression or encryption. This paper proposes a method based on machine learning using a mix of feature extraction and classification to reliably detect these compressed and encrypted data. This proposed method identifies a broad variety of compression and encryption techniques, including some not seen before. Performance evaluations on diverse datasets show our method excels both in terms of detection accuracy and efficiency compared to leading methods today. The approach is broadly useful and simple to integrate into systems designed to detect suspicious or sensitive information.",1,AI
"This paper introduces Cryptoguard, an instrument for very high precision detection of cryptographic flaws in huge Java projects. Cryptographic measures are vital for secure storage of important information on computers; however, they can introduce flaws if used improperly. Modern software development is so big that manual identification and correction of such flaws is difficult. Cryptoguard uses static analysis techniques to automatically detect misuse of cryptographic APIs such as usage of weak crypto algorithms or wrong key sizes. Rules based on best practice and standards guidelines are used to flag possible flaws. Design aims to minimize false positives and ensure reporting only of true flaws. Results from evaluations of Cryptoguard on datasets of twelve popular open source Java projects show effectiveness in detecting flaws at high precision. Results also show that Cryptoguard detects flaws that other similar tools do not detect and can discover both known and previously undiscovered flaws. Ultimately Cryptoguard is a strong tool for automatic flaw detection in large scale Java projects and helps developers to identify and fix flaws to improve security of systems.",1,AI
"This paper studies idle waves in programs executed in parallel and the influence of communication, cluster topology, and noise on them. Using analytical modeling this paper investigates how such waves behave and the factors which cause formation and propagation of these waves. Results indicate that communication overhead, clustering topology and noise greatly affect behavior of these waves by influencing their speed, frequency and stability. Research outcomes suggest ways to improve efficiency and effectiveness of parallel programs and reduce negative effects of idle waves on performance. Insights provided by this work are useful for both researchers and practitioners working in parallel computing and emphasize importance of considering communication, clustering and noise impacts during design and optimization.",1,AI
"From the simple measurement of tissue attributes in pathology workflow to designing an explainable diagnostic/prognostic AI tool, access to accurate semantic segmentation of tissue regions in histology images is a prerequisite. However, delineating different tissue regions manually is a laborious, time-consuming and costly task that requires expert knowledge. On the other hand, the state-of-the-art automatic deep learning models for semantic segmentation require lots of annotated training data and there are only a limited number of tissue region annotated images publicly available. To obviate this issue in computational pathology projects and collect large-scale region annotations efficiently, we propose an efficient interactive segmentation network that requires minimum input from the user to accurately annotate different tissue types in the histology image. The user is only required to draw a simple squiggle inside each region of interest so it will be used as the guiding signal for the model. To deal with the complex appearance and amorph geometry of different tissue regions we introduce several automatic and minimalistic guiding signal generation techniques that help the model to become robust against the variation in the user input. By experimenting on a dataset of breast cancer images, we show that not only does our proposed method speed up the interactive annotation process, it can also outperform the existing automatic and interactive region segmentation models.",0,Human
"We propose a new approach to value function approximation which combines linear temporal difference reinforcement learning with subspace identification. In practical applications, reinforcement learning (RL) is complicated by the fact that state is either high-dimensional or partially observable. Therefore, RL methods are designed to work with features of state rather than state itself, and the success or failure of learning is often determined by the suitability of the selected features. By comparison, subspace identification (SSID) methods are designed to select a feature set which preserves as much information as possible about state. In this paper we connect the two approaches, looking at the problem of reinforcement learning with a large set of features, each of which may only be marginally useful for value function approximation. We introduce a new algorithm for this situation, called Predictive State Temporal Difference (PSTD) learning. As in SSID for predictive state representations, PSTD finds a linear compression operator that projects a large set of features down to a small set that preserves the maximum amount of predictive information. As in RL, PSTD then uses a Bellman recursion to estimate a value function. We discuss the connection between PSTD and prior approaches in RL and SSID. We prove that PSTD is statistically consistent, perform several experiments that illustrate its properties, and demonstrate its potential on a difficult optimal stopping problem.",0,Human
"With the rapid development of artificial intelligence, conversational bots have became prevalent in mainstream E-commerce platforms, which can provide convenient customer service timely. To satisfy the user, the conversational bots need to understand the user's intention, detect the user's emotion, and extract the key entities from the conversational utterances. However, understanding dialogues is regarded as a very challenging task. Different from common language understanding, utterances in dialogues appear alternately from different roles and are usually organized as hierarchical structures. To facilitate the understanding of dialogues, in this paper, we propose a novel contextual dialogue encoder (i.e. DialogueBERT) based on the popular pre-trained language model BERT. Five self-supervised learning pre-training tasks are devised for learning the particularity of dialouge utterances. Four different input embeddings are integrated to catch the relationship between utterances, including turn embedding, role embedding, token embedding and position embedding. DialogueBERT was pre-trained with 70 million dialogues in real scenario, and then fine-tuned in three different downstream dialogue understanding tasks. Experimental results show that DialogueBERT achieves exciting results with 88.63% accuracy for intent recognition, 94.25% accuracy for emotion recognition and 97.04% F1 score for named entity recognition, which outperforms several strong baselines by a large margin.",0,Human
"This paper introduces a new approach for estimating remaining useful life of hard disks based on bidirectional long short term memory (LSTM) networks. Using historical operational data of HDDs, this study trains a deep learning model which predicts RUL for a specific HDD. Bidirectional LSTM is selected as the model structure due to its capability to capture both past and future contextual information from sequential data. Results of experiments indicate that performance of this proposed method surpasses that of leading edge approaches for RUL prediction in both accuracy and reliability. This work is valuable contribution to predictive maintenance of HDDs and showcases potential of deep learning for RUL estimation.",1,AI
"We study the communication complexity of combinatorial auctions via interpolation mechanisms that interpolate between non-truthful and truthful protocols. Specifically, an interpolation mechanism has two phases. In the first phase, the bidders participate in some non-truthful protocol whose output is itself a truthful protocol. In the second phase, the bidders participate in the truthful protocol selected during phase one. Note that virtually all existing auctions have either a non-existent first phase (and are therefore truthful mechanisms), or a non-existent second phase (and are therefore just traditional protocols, analyzed via the Price of Anarchy/Stability).  The goal of this paper is to understand the benefits of interpolation mechanisms versus truthful mechanisms or traditional protocols, and develop the necessary tools to formally study them. Interestingly, we exhibit settings where interpolation mechanisms greatly outperform the optimal traditional and truthful protocols. Yet, we also exhibit settings where interpolation mechanisms are provably no better than truthful ones. Finally, we apply our new machinery to prove that the recent single-bid mechanism of Devanur et. al.~\cite{DevanurMSW15} (the only pre-existing interpolation mechanism in the literature) achieves the optimal price of anarchy among a wide class of protocols, a claim that simply can't be addressed by appealing just to machinery from communication complexity or the study of truthful mechanisms.",0,Human
This paper introduces an innovative approach to dynamic allocation of network resources that uses online convex optimization. This method deals with real time allocation considering the dynamic and uncertain nature of network demands. Based on principles of convex optimization this new approach employs a set of online algorithms for near optimal decision making regarding resource allocation. Performance is measured using comprehensive simulation and results show effectiveness in terms of resource use and system efficiency as compared to traditional allocation approaches. Results also suggest potential for significant improvement of performance of network systems especially under dynamic conditions and rapid changes.,1,AI
"Multi-step manipulation tasks in unstructured environments are extremely challenging for a robot to learn. Such tasks interlace high-level reasoning that consists of the expected states that can be attained to achieve an overall task and low-level reasoning that decides what actions will yield these states. We propose a model-free deep reinforcement learning method to learn multi-step manipulation tasks. We introduce a Robotic Manipulation Network (RoManNet), which is a vision-based model architecture, to learn the action-value functions and predict manipulation action candidates. We define a Task Progress based Gaussian (TPG) reward function that computes the reward based on actions that lead to successful motion primitives and progress towards the overall task goal. To balance the ratio of exploration/exploitation, we introduce a Loss Adjusted Exploration (LAE) policy that determines actions from the action candidates according to the Boltzmann distribution of loss estimates. We demonstrate the effectiveness of our approach by training RoManNet to learn several challenging multi-step robotic manipulation tasks in both simulation and real-world. Experimental results show that our method outperforms the existing methods and achieves state-of-the-art performance in terms of success rate and action efficiency. The ablation studies show that TPG and LAE are especially beneficial for tasks like multiple block stacking. Code is available at: https://github.com/skumra/romannet",0,Human
"A sound Decision-Making (DM) process is key to the successful governance of software projects. In many Open Source Software Development (OSSD) communities, DM processes lie buried amongst vast amounts of publicly available data. Hidden within this data lie the rationale for decisions that led to the evolution and maintenance of software products. While there have been some efforts to extract DM processes from publicly available data, the rationale behind how the decisions are made have seldom been explored. Extracting the rationale for these decisions can facilitate transparency (by making them known), and also promote accountability on the part of decision-makers. This work bridges this gap by means of a large-scale study that unearths the rationale behind decisions from Python development email archives comprising about 1.5 million emails. This paper makes two main contributions. First, it makes a knowledge contribution by unearthing and presenting the rationale behind decisions made. Second, it makes a methodological contribution by presenting a heuristics-based rationale extraction system called Rationale Miner that employs multiple heuristics, and follows a data-driven, bottom-up approach to infer the rationale behind specific decisions (e.g., whether a new module is implemented based on core developer consensus or benevolent dictator's pronouncement). Our approach can be applied to extract rationale in other OSSD communities that have similar governance structures.",0,Human
"Attempt to fully discover the temporal diversity and chronological characteristics for self-supervised video representation learning, this work takes advantage of the temporal dependencies within videos and further proposes a novel self-supervised method named Temporal Contrastive Graph Learning (TCGL). In contrast to the existing methods that ignore modeling elaborate temporal dependencies, our TCGL roots in a hybrid graph contrastive learning strategy to jointly regard the inter-snippet and intra-snippet temporal dependencies as self-supervision signals for temporal representation learning. To model multi-scale temporal dependencies, our TCGL integrates the prior knowledge about the frame and snippet orders into graph structures, i.e., the intra-/inter- snippet temporal contrastive graphs. By randomly removing edges and masking nodes of the intra-snippet graphs or inter-snippet graphs, our TCGL can generate different correlated graph views. Then, specific contrastive learning modules are designed to maximize the agreement between nodes in different views. To adaptively learn the global context representation and recalibrate the channel-wise features, we introduce an adaptive video snippet order prediction module, which leverages the relational knowledge among video snippets to predict the actual snippet orders. Experimental results demonstrate the superiority of our TCGL over the state-of-the-art methods on large-scale action recognition and video retrieval benchmarks.",0,Human
This paper investigates the concept of rationality when making security decisions using an example of dancing pigs and considering externalities. The research examines how decision makers balance security against competing interests like cost and public opinion. Methods include both quantitative and qualitative approaches; the paper measures the degree to which security choices rely on rational reasoning versus external factors like media attention or public pressure. Results show that actual decisions tend to be shaped by a mix of rational and irrational influences; decision makers need to carefully weigh the effects of their actions. Conclusions propose suggestions for enhancing rationality in security decision making given these difficulties.,1,AI
This paper investigates the prediction of effects of large scale competition among drivers in a ride sharing economy. Using a causal inference framework we estimate impacts of these competitions on driver behavior and performance using data from a major ride sharing company. We use econometrics methods to control for various confounding factors such as endogeneity of treatment assignment and time varying confounders. Results show that competitions motivate and reward drivers positively; they contribute to an increase in rides and higher revenues. Results are relevant for ride sharing firms and guide them toward designing future competitions to improve driver performance and satisfaction.,1,AI
This paper introduces a new way of robot navigation using reinforcement learning (RL) and slow feature analysis (SFA). RL is a common machine learning method allowing an agent to learn an optimal action by interacting with its environment via trial and error. SFA extracts features that change slowly from high dimensional sensory inputs; it has proven useful for forecasting future states of dynamic systems. Here we combine RL and SFA to train robots to navigate in unexplored environments. Robots receive high dimensional sensor data such as image streams or scans from lidars and use SFA to extract lower dimensional features that capture slow variation in the environment. An RL algorithm then learns a policy maximizing a reward function based on progress toward a goal position. Results are evaluated in simulations and show that combining RL and SFA performs better than either individually. Results show that SFA can be a strong tool for reducing dimensionality of sensory data and increasing efficiency of RL algorithms. Limitations and possible future directions are discussed including applicability to real world robotics. Overall this work shows promise for combining diverse learning methods to improve navigation effectiveness and efficiency.,1,AI
"Public speaking is an important aspect of human communication and interaction. The majority of computational work on public speaking concentrates on analyzing the spoken content, and the verbal behavior of the speakers. While the success of public speaking largely depends on the content of the talk, and the verbal behavior, non-verbal (visual) cues, such as gestures and physical appearance also play a significant role. This paper investigates the importance of visual cues by estimating their contribution towards predicting the popularity of a public lecture. For this purpose, we constructed a large database of more than $1800$ TED talk videos. As a measure of popularity of the TED talks, we leverage the corresponding (online) viewers' ratings from YouTube. Visual cues related to facial and physical appearance, facial expressions, and pose variations are extracted from the video frames using convolutional neural network (CNN) models. Thereafter, an attention-based long short-term memory (LSTM) network is proposed to predict the video popularity from the sequence of visual features. The proposed network achieves state-of-the-art prediction accuracy indicating that visual cues alone contain highly predictive information about the popularity of a talk. Furthermore, our network learns a human-like attention mechanism, which is particularly useful for interpretability, i.e. how attention varies with time, and across different visual cues by indicating their relative importance.",0,Human
"Cutting edge research focuses on merging wearable tech with advanced machine learning methods. Aim is to develop a new kind of smart clothing that adapts dynamically to both wearer and environment in real time. This paper surveys current highest level achievements in this area and describes recent progress in garment development. Authors look into different ways to build such garments using sensors, actuators and machine learning algorithms. Challenges and limits for practical realization are discussed too. The end result looks at possible uses and future directions for this promising field of research.",1,AI
This paper introduces an improved bound for minimum storage regeneration codes. MSR codes are used in distributed storage systems to distribute data among different nodes. New bound improves existing ones by refining analysis of sub packetization process. Proposed bound is tighter and more precise; this allows us to improve designs of MSR codes. Supporting theoretical results include numerical simulations that show practical advantages of this new bound. Contribution here is important for distributed storage system research and might have practical relevance for designing and implementing systems.,1,AI
"Reinforcement learning has lead to considerable break-throughs in diverse areas such as robotics, games and many others. But the application to RL in complex real-world decision making problems remains limited. Many problems in operations management (inventory and revenue management, for example) are characterized by large action spaces and stochastic system dynamics. These characteristics make the problem considerably harder to solve for existing RL methods that rely on enumeration techniques to solve per step action problems. To resolve these issues, we develop Programmable Actor Reinforcement Learning (PARL), a policy iteration method that uses techniques from integer programming and sample average approximation. Analytically, we show that the for a given critic, the learned policy in each iteration converges to the optimal policy as the underlying samples of the uncertainty go to infinity. Practically, we show that a properly selected discretization of the underlying uncertain distribution can yield near optimal actor policy even with very few samples from the underlying uncertainty. We then apply our algorithm to real-world inventory management problems with complex supply chain structures and show that PARL outperforms state-of-the-art RL and inventory optimization methods in these settings. We find that PARL outperforms commonly used base stock heuristic by 44.7% and the best performing RL method by up to 12.1% on average across different supply chain environments.",0,Human
"Methods for neural network hyperparameter optimization and meta-modeling are computationally expensive due to the need to train a large number of model configurations. In this paper, we show that standard frequentist regression models can predict the final performance of partially trained model configurations using features based on network architectures, hyperparameters, and time-series validation performance data. We empirically show that our performance prediction models are much more effective than prominent Bayesian counterparts, are simpler to implement, and are faster to train. Our models can predict final performance in both visual classification and language modeling domains, are effective for predicting performance of drastically varying model architectures, and can even generalize between model classes. Using these prediction models, we also propose an early stopping method for hyperparameter optimization and meta-modeling, which obtains a speedup of a factor up to 6x in both hyperparameter optimization and meta-modeling. Finally, we empirically show that our early stopping method can be seamlessly incorporated into both reinforcement learning-based architecture selection algorithms and bandit based search methods. Through extensive experimentation, we empirically show our performance prediction models and early stopping algorithm are state-of-the-art in terms of prediction accuracy and speedup achieved while still identifying the optimal model configurations.",0,Human
This paper looks at different kinds of failure modes in ML systems and how they affect accuracy and reliability of outcomes. It begins by defining failure modes in ML such as overfitting and underfitting and biases in the data. Then it systematically studies major failure modes along with their root causes and suggests ways to detect and reduce them. Results show that failure modes impact accuracy and reliability significantly and stress importance of careful monitoring and assessment of such systems. Conclusion gives suggestions for future research and practical use of ML in practice.,1,AI
"Photo-realistic modeling and rendering of fuzzy objects with complex opacity are critical for numerous immersive VR/AR applications, but it suffers from strong view-dependent brightness, color. In this paper, we propose a novel scheme to generate opacity radiance fields with a convolutional neural renderer for fuzzy objects, which is the first to combine both explicit opacity supervision and convolutional mechanism into the neural radiance field framework so as to enable high-quality appearance and global consistent alpha mattes generation in arbitrary novel views. More specifically, we propose an efficient sampling strategy along with both the camera rays and image plane, which enables efficient radiance field sampling and learning in a patch-wise manner, as well as a novel volumetric feature integration scheme that generates per-patch hybrid feature embeddings to reconstruct the view-consistent fine-detailed appearance and opacity output. We further adopt a patch-wise adversarial training scheme to preserve both high-frequency appearance and opacity details in a self-supervised framework. We also introduce an effective multi-view image capture system to capture high-quality color and alpha maps for challenging fuzzy objects. Extensive experiments on existing and our new challenging fuzzy object dataset demonstrate that our method achieves photo-realistic, globally consistent, and fined detailed appearance and opacity free-viewpoint rendering for various fuzzy objects.",0,Human
"Data structures for efficient sampling from a set of weighted items are an important building block of many applications. However, few parallel solutions are known. We close many of these gaps both for shared-memory and distributed-memory machines. We give efficient, fast, and practicable parallel algorithms for building data structures that support sampling single items (alias tables, compressed data structures). This also yields a simplified and more space-efficient sequential algorithm for alias table construction. Our approaches to sampling $k$ out of $n$ items with/without replacement and to subset (Poisson) sampling are output-sensitive, i.e., the sampling algorithms use work linear in the number of different samples. This is also interesting in the sequential case. Weighted random permutation can be done by sorting appropriate random deviates. We show that this is possible with linear work using a nonlinear transformation of these deviates. Finally, we give a communication-efficient, highly scalable approach to (weighted and unweighted) reservoir sampling. This algorithm is based on a fully distributed model of streaming algorithms that might be of independent interest. Experiments for alias tables and sampling with replacement show near linear speedups both for construction and queries using up to 158 threads of shared-memory machines. An experimental evaluation of distributed weighted reservoir sampling on up to 256 nodes (5120 cores) also shows good speedups.",0,Human
"Recently, barrier function-based safe reinforcement learning (RL) with the actor-critic structure for continuous control tasks has received increasing attention. It is still challenging to learn a near-optimal control policy with safety and convergence guarantees. Also, few works have addressed the safe RL algorithm design under time-varying safety constraints. This paper proposes a model-based safe RL algorithm for optimal control of nonlinear systems with time-varying state and control constraints. In the proposed approach, we construct a novel barrier-based control policy structure that can guarantee control safety. A multi-step policy evaluation mechanism is proposed to predict the policy's safety risk under time-varying safety constraints and guide the policy to update safely. Theoretical results on stability and robustness are proven. Also, the convergence of the actor-critic learning algorithm is analyzed. The performance of the proposed algorithm outperforms several state-of-the-art RL algorithms in the simulated Safety Gym environment. Furthermore, the approach is applied to the integrated path following and collision avoidance problem for two real-world intelligent vehicles. A differential-drive vehicle and an Ackermann-drive one are used to verify the offline deployment performance and the online learning performance, respectively. Our approach shows an impressive sim-to-real transfer capability and a satisfactory online control performance in the experiment.",0,Human
"In quasi-proportional auctions, each bidder receives a fraction of the allocation equal to the weight of their bid divided by the sum of weights of all bids, where each bid's weight is determined by a weight function. We study the relationship between the weight function, bidders' private values, number of bidders, and the seller's revenue in equilibrium. It has been shown that if one bidder has a much higher private value than the others, then a nearly flat weight function maximizes revenue. Essentially, threatening the bidder who has the highest valuation with having to share the allocation maximizes the revenue. We show that as bidder private values approach parity, steeper weight functions maximize revenue by making the quasi-proportional auction more like a winner-take-all auction. We also show that steeper weight functions maximize revenue as the number of bidders increases. For flatter weight functions, there is known to be a unique pure-strategy Nash equilibrium. We show that a pure-strategy Nash equilibrium also exists for steeper weight functions, and we give lower bounds for bids at an equilibrium. For a special case that includes the two-bidder auction, we show that the pure-strategy Nash equilibrium is unique, and we show how to compute the revenue at equilibrium. We also show that selecting a weight function based on private value ratios and number of bidders is necessary for a quasi-proportional auction to produce more revenue than a second-price auction.",0,Human
"This research compares how academic and social groups communicate regarding global outbreaks. It studies how each group disseminates information about outbreaks and investigates what influences those groups' preferences for communication. Results show important differences between academics and social groups when it comes to preferred information sources, required levels of detail and preferred ways of communication. Results of this work could assist policymakers and communicators to understand better different community needs and preferences during an outbreak and adjust communication strategies accordingly.",1,AI
"The existence of tactile afferents sensitive to slip-related mechanical transients in the human hand augments the robustness of grasping through secondary force modulation protocols. Despite this knowledge and the fact that tactile-based slip detection has been researched for decades, robust slip detection is still not an out-of-the-box capability for any commercially available tactile sensor. This research seeks to bridge this gap with a comprehensive study addressing several aspects of slip detection. Key developments include a systematic data collection process yielding millions of sensory data points, the generalized conversion of multivariate-to-univariate sensor output, an insightful spectral analysis of the univariate sensor outputs, and the application of Long Short-Term Memory (LSTM) neural networks on the univariate signals to produce robust slip detectors from three commercially available sensors capable of tactile sensing. The sensing elements underlying these sensors vary in quantity, spatial arrangement, and mechanics, leveraging principles in electro-mechanical resistance, optics, and hydro-acoustics. Critically, slip detection performance of the tactile technologies is quantified through a measurement methodology that unveils the effects of data window size, sampling rate, material type, slip speed, and sensor manufacturing variability. Results indicate that the investigated commercial tactile sensors are inherently capable of high-quality slip detection.",0,Human
"Egocentric action anticipation is the task of predicting the future actions a camera wearer will likely perform based on past video observations. While in a real-world system it is fundamental to output such predictions before the action begins, past works have not generally paid attention to model runtime during evaluation. Indeed, current evaluation schemes assume that predictions can be made offline, and hence that computational resources are not limited. In contrast, in this paper, we propose a ``streaming'' egocentric action anticipation evaluation protocol which explicitly considers model runtime for performance assessment, assuming that predictions will be available only after the current video segment is processed, which depends on the processing time of a method. Following the proposed evaluation scheme, we benchmark different state-of-the-art approaches for egocentric action anticipation on two popular datasets. Our analysis shows that models with a smaller runtime tend to outperform heavier models in the considered streaming scenario, thus changing the rankings generally observed in standard offline evaluations. Based on this observation, we propose a lightweight action anticipation model consisting in a simple feed-forward 3D CNN, which we propose to optimize using knowledge distillation techniques and a custom loss. The results show that the proposed approach outperforms prior art in the streaming scenario, also in combination with other lightweight models.",0,Human
"This paper looks at distributed estimation and learning over networks that vary in characteristics like resource availability, communication abilities and quality of measurements. Main focus is on devising new algorithms and techniques allowing nodes in these networks to collaboratively estimate unknown parameters using local data. A key challenge here is heterogeneity among nodes, which can differ in terms of computational power, communication capabilities and quality of sensing. The paper introduces novel algorithms that balance tradeoffs among computational cost, communication cost and estimation accuracy. Results are also analyzed theoretically and through experiments and show effectiveness in different network situations. Results from this work offer insight into designing efficient algorithms for distributed estimation and learning in diverse networks and point toward applications in wireless sensor networks, machine learning and robotics.",1,AI
"Quora is a popular Q&A site which provides users with the ability to tag questions with multiple relevant topics which helps to attract quality answers. These topics are not predefined but user-defined conventions and it is not so rare to have multiple such conventions present in the Quora ecosystem describing exactly the same concept. In almost all such cases, users (or Quora moderators) manually merge the topic pair into one of the either topics, thus selecting one of the competing conventions. An important application for the site therefore is to identify such competing conventions early enough that should merge in future. In this paper, we propose a two-step approach that uniquely combines the anomaly detection and the supervised classification frameworks to predict whether two topics from among millions of topic pairs are indeed competing conventions, and should merge, achieving an F-score of 0.711. We also develop a model to predict the direction of the topic merge, i.e., the winning convention, achieving an F-score of 0.898. Our system is also able to predict ~ 25% of the correct case of merges within the first month of the merge and ~ 40% of the cases within a year. This is an encouraging result since Quora users on average take 936 days to identify such a correct merge. Human judgment experiments show that our system is able to predict almost all the correct cases that humans can predict plus 37.24% correct cases which the humans are not able to identify at all.",0,Human
"This paper introduces a new approach to resolve scaling issues in allocation of resources for exploration with many arms using bandits. These issues limit benefits from increased parallelism in exploration efficiency. Specifically, this work develops an adaptive parallel algorithm that exploits diversity in the exploration landscape and dynamically tunes levels of parallelism for better balance between exploration and exploitation. The proposed algorithm uses an innovative adaptive scheduling strategy that distributes workload among parallel workers efficiently and optimally allocates resources to high potential exploration tasks. Results show that performance improvements are significant compared to existing algorithms; they also show overcoming scalability limits in parallel exploration. Results have broader implications including online advertising and recommender systems along with automated decision making. Human like text: This paper proposes a new method to deal with scaling issues when allocating resources for exploration with multiple arms using bandits. Such issues reduce the benefit of parallelism and hence exploration efficiency. Specifically, we develop an adaptive parallel algorithm exploiting diversity in exploration landscapes and adjusting levels of parallelism dynamically to optimize a good balance of exploration versus exploitation. This algorithm employs a novel adaptive scheduling strategy that efficiently distributes workload among parallel workers and optimally allocates resources to promising exploration tasks. Results clearly show significant performance gains relative to previous approaches and overcoming scalability barriers in parallel exploration. Results have broad applicability ranging from online ads and recommendation systems to automated decision making.",1,AI
"This paper introduces snsapi, a middle layer for rapid deployment of decentralized social networks. Decentralized networks differ from centralized ones in addressing privacy, security and censorship concerns. Setting up such networks poses challenges because it requires expertise across many domains such as programming, system administration and networking. Snsapi aims to reduce this complexity by offering a high level, platform independent API that hides underlying technology intricacies. Design and implementation details of snsapi are presented. It follows a modular architecture allowing easy extension and customization. Support for diverse protocols such as Diaspora, Mastodon and Activity Pub is included. Core features like user authentication and content management along with inter node communications are provided and plugins allow further expansion. Performance evaluation reports low overhead introduced by snsapi compared to base decentralized networks and scalability to many users and nodes. In summary, snsapi serves well developers aiming to deploy decentralized networks without needing deep technical skills. Due to modularity, cross platform support and extensibility, snsapi is considered a valuable asset in the expanding decentralized social network ecosystem.",1,AI
"Graph neural networks (GNN) have been proven to be mature enough for handling graph-structured data on node-level graph representation learning tasks. However, the graph pooling technique for learning expressive graph-level representation is critical yet still challenging. Existing pooling methods either struggle to capture the local substructure or fail to effectively utilize high-order dependency, thus diminishing the expression capability. In this paper we propose HAP, a hierarchical graph-level representation learning framework, which is adaptively sensitive to graph structures, i.e., HAP clusters local substructures incorporating with high-order dependencies. HAP utilizes a novel cross-level attention mechanism MOA to naturally focus more on close neighborhood while effectively capture higher-order dependency that may contain crucial information. It also learns a global graph content GCont that extracts the graph pattern properties to make the pre- and post-coarsening graph content maintain stable, thus providing global guidance in graph coarsening. This novel innovation also facilitates generalization across graphs with the same form of features. Extensive experiments on fourteen datasets show that HAP significantly outperforms twelve popular graph pooling methods on graph classification task with an maximum accuracy improvement of 22.79%, and exceeds the performance of state-of-the-art graph matching and graph similarity learning algorithms by over 3.5% and 16.7%.",0,Human
"This paper investigates minimizing Age of Information (AoI) using a device that harvests energy and updates even when erasures occur. AoI measures how recent data is being transmitted in a communication system. This study considers a situation where a source has limited energy and must gather energy from the surroundings to do updates. The source sometimes loses information due to erasures which increases AoI. Comparing different situations, one with feedback where the source receives information about status of updates and another one without feedback where there is no such information, this study shows that feedback improves performance of energy harvesting source especially with erasures. Results have implications for designing efficient communication systems that need fresh data.",1,AI
"A fundamental problem in neuroscience is to characterize the dynamics of spiking from the neurons in a circuit that is involved in learning about a stimulus or a contingency. A key limitation of current methods to analyze neural spiking data is the need to collapse neural activity over time or trials, which may cause the loss of information pertinent to understanding the function of a neuron or circuit. We introduce a new method that can determine not only the trial-to-trial dynamics that accompany the learning of a contingency by a neuron, but also the latency of this learning with respect to the onset of a conditioned stimulus. The backbone of the method is a separable two-dimensional (2D) random field (RF) model of neural spike rasters, in which the joint conditional intensity function of a neuron over time and trials depends on two latent Markovian state sequences that evolve separately but in parallel. Classical tools to estimate state-space models cannot be applied readily to our 2D separable RF model. We develop efficient statistical and computational tools to estimate the parameters of the separable 2D RF model. We apply these to data collected from neurons in the pre-frontal cortex (PFC) in an experiment designed to characterize the neural underpinnings of the associative learning of fear in mice. Overall, the separable 2D RF model provides a detailed, interpretable, characterization of the dynamics of neural spiking that accompany the learning of a contingency.",0,Human
This paper reconsiders a technique for density based structural topology optimization using Heaviside projection method. The method is used to reintroduce removed elements into designs to avoid over density and under density that happens with standard techniques. Results show the new approach gives better optimization results and leads to better performing designs.,1,AI
"Most distributed-memory bulk-synchronous parallel programs in HPC assume that compute resources are available continuously and homogeneously across the allocated set of compute nodes. However, long one-off delays on individual processes can cause global disturbances, so-called idle waves, by rippling through the system. This process is mainly governed by the communication topology of the underlying parallel code. This paper makes significant contributions to the understanding of idle wave dynamics. We study the propagation mechanisms of idle waves across the ranks of MPI-parallel programs. We present a validated analytic model for their propagation velocity with respect to communication parameters and topology, with a special emphasis on sparse communication patterns. We study the interaction of idle waves with MPI collectives and show that, depending on the implementation, a collective may be transparent to the wave. Finally we analyze two mechanisms of idle wave decay: topological decay, which is rooted in differences in communication characteristics among parts of the system, and noise-induced decay, which is caused by system or application noise. We show that noise-induced decay is largely independent of noise characteristics but depends only on the overall noise power. An analytic expression for idle wave decay rate with respect to noise power is derived. For model validation we use microbenchmarks and stencil algorithms on three different supercomputing platforms.",0,Human
This paper looks at the issue of coordinated beamforming in dense cooperative wireless networks and how this is essential for high data rates and energy efficiency in modern communication systems. We propose an algorithm that scales well and coordinates transmissions among multiple base stations and users effectively. It also minimizes interference from deployment of dense networks. This algorithm exploits sparsity of channel matrices and statistical features of wireless channels to jointly optimize beamforming vectors and power allocation among cooperating nodes. Implementation is distributed so that it works well in large networks having many base stations and users. Performance is assessed via simulations under various network scenarios such as differing densities of users and antennas. Simulation results show significant performance improvement compared to leading beamforming techniques particularly for dense network scenarios. Overall our new algorithm offers an effective and scalable solution to coordination problems in cooperative dense wireless networks and has major implications for designing future communication systems.,1,AI
"Subgraph queries also known as subgraph isomorphism search is a fundamental problem in querying graph-like structured data. It consists to enumerate the subgraphs of a data graph that match a query graph. This problem arises in many real-world applications related to query processing or pattern recognition such as computer vision, social network analysis, bioinformatic and big data analytic. Subgraph isomorphism search knows a lot of investigations and solutions mainly because of its importance and use but also because of its NP-completeness. Existing solutions use filtering mechanisms and optimise the order within witch the query vertices are matched on the data vertices to obtain acceptable processing times. However, existing approaches are iterative and generate several intermediate results. They also require that the data graph is loaded in main memory and consequently are not adapted to large graphs that do not fit into memory or are accessed by streams. To tackle this problem, we propose a new approach based on concepts widely different from existing works. Our approach distills the semantic and topological information that surround a vertex into a simple integer. This simple vertex encoding that can be computed and updated incrementally reduces considerably intermediate results and avoid to load the entire data graph into main memory. We evaluate our approach on several real-word datasets. The experimental results show that our approach is efficient and scalable.",0,Human
Ramsey theory is a fundamental result in combinatorics that states that there exist cliques of the same color in graphs that have been colored properly. This paper introduces two extensions of Ramsey theory that build on that basic result. One extension considers finding cliques of specific sizes that are monochromatic; the other extends coloring concepts to hypergraphs. Results of these new developments deepen understanding of the existence and structure of such cliques. Results from this work will be important for advancing research into combinatorics and applications of Ramsey theory.,1,AI
"This research looks at the importance of considering overconfidence and the hot hand fallacy when designing systems where humans are involved. Behavioral economics, which studies human psychology, helps explain why people feel overconfident and why they have the hot hand fallacy and how this impacts decision making. Results suggest that by taking into account such psychological tendencies, we can improve human design in systems relying on human decisions. Results also indicate that applying economic behavioral principles can improve system accuracy and reliability and lead to better results.",1,AI
"We present a path planning framework that takes into account the human's safety perception in the presence of a flying robot. The framework addresses two objectives: (i) estimation of the uncertain parameters of the proposed safety perception model based on test data collected using Virtual Reality (VR) testbed, and (ii) offline optimal control computation using the estimated safety perception model. Due to the unknown factors in the human tests data, it is not suitable to use standard regression techniques that minimize the mean squared error (MSE). We propose to use a Hidden Markov model (HMM) approach where human's attention is considered as a hidden state to infer whether the data samples are relevant to learn the safety perception model. The HMM approach improved log-likelihood over the standard least squares solution. For path planning, we use Bernstein polynomials for discretization, as the resulting path remains within the convex hull of the control points, providing guarantees for deconfliction with obstacles at low computational cost. An example of optimal trajectory generation using the learned human model is presented. The optimal trajectory generated using the proposed model results in reasonable safety distance from the human. In contrast, the paths generated using the standard regression model have undesirable shapes due to overfitting. The example demonstrates that the HMM approach has robustness to the unknown factors compared to the standard MSE model.",0,Human
This paper looks into the informal semantics of ASP by using the Tarski approach as a foundation. ASP is a programming paradigm that is widely used for solving constraint satisfaction problems. Here we study the mathematical underpinnings of ASP and look at how Tarski semantics can formally define meaning of programs. Results show that the Tarski approach offers an intuitive and natural framework to understand informal semantics of ASP and also reveals connections with other formal logics. Results of this work contribute to efforts to establish ASP as a solid and rigorous paradigm in computing and should appeal to researchers and practitioners in AI and knowledge representation.,1,AI
"This paper presents a framework for path planning for flying robots near humans. The purpose of this framework is to allow the robot to navigate safely and efficiently while avoiding collision with people and other objects. Using a combination of reactive control based on sensors and planning techniques for movement, this framework generates trajectories that meet both safety and efficiency constraints. Reactive control modules use sensor data to react quickly to environmental changes; meanwhile, planning modules generate long term trajectories that maximize an objective function. Performance evaluations are conducted using simulation and real world experiments with quadrotors. Results show that this approach avoids collisions with humans and obstacles while also optimizing objectives and it is applicable to diverse tasks such as rescue, inspection, and surveillance.",1,AI
"Unsupervised domain adaptation (UDA) aims to solve the problem of knowledge transfer from labeled source domain to unlabeled target domain. Recently, many domain adaptation (DA) methods use centroid to align the local distribution of different domains, that is, to align different classes. This improves the effect of domain adaptation, but domain differences exist not only between classes, but also between samples. This work rethinks what is the alignment between different domains, and studies how to achieve the real alignment between different domains. Previous DA methods only considered one distribution feature of aligned samples, such as full distribution or local distribution. In addition to aligning the global distribution, the real domain adaptation should also align the meso distribution and the micro distribution. Therefore, this study propose a double classifier method based on high confidence label (DCP). By aligning the centroid and the distribution between centroid and sample of different classifiers, the meso and micro distribution alignment of different domains is realized. In addition, in order to reduce the chain error caused by error marking, This study propose a high confidence marking method to reduce the marking error. To verify its versatility, this study evaluates DCP on digital recognition and target recognition data sets. The results show that our method achieves state-of-the-art results on most of the current domain adaptation benchmark datasets.",0,Human
"This research investigates the application of Q Learning, specifically Q Learning with Black Scholes (QLBS) to portfolios using Black Scholes and Black Scholes Merton models. Results show that QLBS outperforms traditional methods regarding portfolio returns and risk management. Insights are drawn about potential use of reinforcement learning in finance and importance of dealing with changing market conditions. Research contributions advance making better financial decisions and has practical relevance for investors and portfolio managers.",1,AI
"In Knowledge Representation, it is crucial that knowledge engineers have a good understanding of the formal expressions that they write. What formal expressions state intuitively about the domain of discourse is studied in the theory of the informal semantics of a logic. In this paper we study the informal semantics of Answer Set Programming. The roots of answer set programming lie in the language of Extended Logic Programming, which was introduced initially as an epistemic logic for default and autoepistemic reasoning. In 1999, the seminal papers on answer set programming proposed to use this logic for a different purpose, namely, to model and solve search problems. Currently, the language is used primarily in this new role. However, the original epistemic intuitions lose their explanatory relevance in this new context. How answer set programs are connected to the specifications of problems they model is more easily explained in a classical Tarskian semantics, in which models correspond to possible worlds, rather than to belief states of an epistemic agent. In this paper, we develop a new theory of the informal semantics of answer set programming, which is formulated in the Tarskian setting and based on Frege's compositionality principle. It differs substantially from the earlier epistemic theory of informal semantics, providing a different view on the meaning of the connectives in answer set programming and on its relation to other logics, in particular classical logic.",0,Human
"The application of reinforcement learning algorithms onto real life problems always bears the challenge of filtering the environmental state out of raw sensor readings. While most approaches use heuristics, biology suggests that there must exist an unsupervised method to construct such filters automatically. Besides the extraction of environmental states, the filters have to represent them in a fashion that support modern reinforcement algorithms. Many popular algorithms use a linear architecture, so one should aim at filters that have good approximation properties in combination with linear functions. This thesis wants to propose the unsupervised method slow feature analysis (SFA) for this task. Presented with a random sequence of sensor readings, SFA learns a set of filters. With growing model complexity and training examples, the filters converge against trigonometric polynomial functions. These are known to possess excellent approximation capabilities and should therfore support the reinforcement algorithms well. We evaluate this claim on a robot. The task is to learn a navigational control in a simple environment using the least square policy iteration (LSPI) algorithm. The only accessible sensor is a head mounted video camera, but without meaningful filtering, video images are not suited as LSPI input. We will show that filters learned by SFA, based on a random walk video of the robot, allow the learned control to navigate successfully in ca. 80% of the test trials.",0,Human
We introduce an efficient amortized framework for performing inference on complex hierarchical and nonlinear dynamic systems. We rely on variational inference and exploit intrinsic structure and regularities in data to reduce computational cost. Using amortized approximation we compute the posteriors of parameters and states efficiently and scalably. Results show the framework accurately recovers underlying structure and regularity in data and provides notable computational savings relative to traditional Bayesian inference. This work has great significance for analysis of complex systems and may yield new insights into such systems.,1,AI
"This paper introduces a new algorithm called PromiPS that excels at fast approximate maximum inner product searches in high dimensions; this is difficult because the search space grows exponentially. The algorithm uses an index structure that requires less storage and efficiently queries data. PromiPS employs a strategy of dividing high dimensional space into smaller subsets which are easier to search. This is done by building an hierarchical index that organizes vectors so that fewer dot products have to be computed during search. Pruning strategies based on probability reduce the number of computations even further. Results from comprehensive performance evaluations compare PromiPS favorably against leading algorithms for high dimensional nearest neighbor searches. Results show that PromiPS outperforms other methods both in terms of query speed and index size, by up to ten times faster and ten times smaller indexes. PromiPS scales well and handles very large datasets. Overall, the authors present a major contribution to research in nearest neighbor search in high dimensions through introduction of an effective algorithm that balances high accuracy and low computational costs. Index structure that PromiPS uses saves storage space which makes it appealing especially for constrained environments like mobile devices and embedded systems.",1,AI
"The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10x or 100x? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between `enormous data' and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.",0,Human
"Open source software development largely depends on decisions by developers and maintainers of projects. Motivations are diverse and range from technical, social, and organizational factors. This study investigates the reasons for development decisions in the context of Python programming language by studying email archives from development mailing lists. Using NLP techniques, the motivations for decisions of Python developers are extracted and categorized. Results shed light on factors driving open source software development and serve as a basis for future research. Findings also advance understanding of the decision process and guide the design of tools and platforms supporting such development.",1,AI
"Randomization-based Machine Learning methods for prediction are currently a hot topic in Artificial Intelligence, due to their excellent performance in many prediction problems, with a bounded computation time. The application of randomization-based approaches to renewable energy prediction problems has been massive in the last few years, including many different types of randomization-based approaches, their hybridization with other techniques and also the description of new versions of classical randomization-based algorithms, including deep and ensemble approaches. In this paper we review the most important characteristics of randomization-based machine learning approaches and their application to renewable energy prediction problems. We describe the most important methods and algorithms of this family of modeling methods, and perform a critical literature review, examining prediction problems related to solar, wind, marine/ocean and hydro-power renewable sources. We support our critical analysis with an extensive experimental study, comprising real-world problems related to solar, wind and hydro-power energy, where randomization-based algorithms are found to achieve superior results at a significantly lower computational cost than other modeling counterparts. We end our survey with a prospect of the most important challenges and research directions that remain open this field, along with an outlook motivating further research efforts in this exciting research field.",0,Human
This paper introduces a method to compute upper limits for the probability of reaching a target set while avoiding unsafe regions when there is uncertainty. It uses robust optimization to include this uncertainty within the problem definition and provides a way to compute tight upper bounds on the probability. Numerical results show this method works well and is able to compute accurate and efficient upper bounds on probability of interest for a broad range of dynamical systems and serves as a valuable tool for designing safe controllers under uncertainty.,1,AI
"We present theory and algorithms for the computation of probability-weighted ""keep-out"" sets to assure probabilistically safe navigation in the presence of multiple rigid body obstacles with stochastic dynamics. Our forward stochastic reachability-based approach characterizes the stochasticity of the future obstacle states in a grid-free and recursion-free manner, using Fourier transforms and computational geometry. We consider discrete-time Markovian switched systems with affine parameter-varying stochastic subsystems (DMSP) as the obstacle dynamics, which includes Markov jump affine systems and discrete-time affine parameter-varying stochastic systems (DPV). We define a probabilistic occupancy function, to describe the probability that a given state is occupied by a rigid body obstacle with stochastic dynamics at a given time; keep-out sets are the super-level sets of this occupancy function. We provide sufficient conditions that ensure convexity and compactness of these keep-out sets for DPV obstacle dynamics. We also propose two computationally efficient algorithms to overapproximate the keep-out sets --- a tight polytopic approximation using projections, and an overapproximation using Minkowski sum. For DMSP obstacle dynamics, we compute a union of convex and compact sets that covers the potentially non-convex keep-out set. Numerical simulations show the efficacy of the proposed algorithms for a modified version of the classical unicycle dynamics, modeled as a DMSP.",0,Human
This paper introduces a new method called TSGCNet for segmentation of three dimensional dental models. TSGCNet uses a two stream graph convolution network to learn discriminative geometric features. It combines both local features of individual teeth and global features that describe the shape and arrangement of all teeth in an entire dental arch. Relationships between teeth are modeled using this network and learned dependencies among features are discovered. We test this method on a public dataset and show that TSGCNet performs better than leading methods at segmentation of dental models and achieves an average Dice similarity coefficient of 0.921. This method has potential applications such as diagnosis and planning treatment and also research into dentistry.,1,AI
"This paper studies how to use Bayesian deep learning to deal with the pressing need for instructor involvement in discussion forums of Massive Open Online Courses (MOOC). These courses have become very popular because they are easy to access and flexible. However, high enrollment makes it hard for teachers to give quick and personalized feedback especially on forums where students ask questions and request help. Proposed is a solution involving deep learning models that employ Bayesian inference to recognize urgent questions that instructors should act upon promptly. Factors such as nature of the question, time elapsed since posting, and the degree of urgency expressed by students are considered by this model. By incorporating these elements into the model, it identifies urgent questions that instructors should address immediately and so helps them prioritize responses. Data collected from a leading MOOC platform was used and compared against current approaches. Results show that this Bayesian deep learning model performs better than competing solutions in terms of accuracy and efficiency especially when it comes to recognizing urgent needs that require prompt action. Results have important implications for instructors since they provide an effective way to manage student queries and offer personalized feedback efficiently. They also indicate the potential of Bayesian deep learning to raise the quality of online education and improve student learning experience.",1,AI
"This study investigates privacy enhancing methods for performing Support Vector Machines (SVM) learning on large data sets. SVM is widely employed in many domains such as image and text classification and bioinformatics. But when dealing with sensitive information, there is a concern for privacy and risk of unauthorized access. We propose two privacy enhancing mechanisms for learning SVMs. One method uses homomorphic encryption to process data without revealing it to the learning algorithm. Another method adds random noise to data to hide sensitive information while still allowing accurate classification by the algorithm. Performance of these methods is tested on a large dataset of image classifications. Results indicate that both methods successfully protect data privacy while also performing at high levels of classification accuracy. The significance of this work is great for industries like healthcare, finance and national security where sensitive data is common. Providing effective mechanisms for protecting privacy this way allows SVM learning to become practical even in contexts where privacy issues might otherwise preclude its use.",1,AI
This paper investigates using stochastic gradient methods for optimization tasks that are typically done online but require avoiding projections because they become too costly or impossible when the problem dimensionality is high. Novel algorithms that use stochastic gradients to optimize convex and submodular functions are introduced; these also provide theoretical guarantees regarding convergence and performance. Results show this new approach performs well and efficiently compared to other common approaches that depend on projections. Results indicate the new method may prove promising as an alternative to traditional online optimization approaches relying on projections.,1,AI
This paper investigates rate splitting (RS) as a strategy at physical layer level for Long Term Evolution (LTE) networks using multiple input antennas. Results show that RS improves system performance substantially by enhancing spectral efficiency and fairness compared to standard transmission methods. Simulation results are conducted under diverse network situations and channel states and comparisons are made with other advanced MIMO transmission techniques. Results from this work point to promising prospects for RS as a feasible strategy for LTE evolution and suggest avenues for future research.,1,AI
"This paper introduces FatSegNet as a fully automatic pipeline for segmentation of adipose tissue from Dixon MRIs of abdomen. Segmentation of adipose tissue is important for evaluating obesity which is a major risk factor for different diseases. Proposed pipeline uses a deep learning model based on U-Net that is trained on a large dataset containing annotated scans of Dixon MRIs. The pipeline also contains preprocessing and postprocessing steps to enhance performance and robustness. Performance of FatSegNet was tested using a large dataset of scans from multiple centers and compared against leading methods for segmentation of adipose tissue. Results indicate that FatSegNet excels in terms of segmentation accuracy, speed and robustness. Average Dice coefficient obtained by FatSegNet is 0.96 for segmentation of subcutaneous fat and 0.94 for segmentation of visceral fat. Proposed pipeline benefits greatly from being fully automatic; it eliminates manual annotation and lessens inter observer variability. This research opens paths for development of deep learning solutions for other medical segmentation tasks as well.",1,AI
"This paper conducts a broad investigation into authentication and mechanisms that preserve privacy for networks using 4G and 5G standards. It reviews current security issues and threats faced by these networks and stresses the significance of strong authentication and mechanisms that protect privacy. The study looks at different authentication and privacy preservation methods including PKI, SMS and AKA among others. Security, scalability and efficiency are considered for each method. Findings of this work offer insight into pros and cons of currently used methods and point toward promising avenues for future research into authentication and privacy mechanisms for 4G and 5G networks.",1,AI
This paper introduces a new method for automatic segmentation of 3D OCT volumes using enhancement of boundaries. Enhancement of boundary surfaces using an algorithm improves quality and serves as basis for segmentation. Results show segmentation of retinal tissue is accurate and reliable and provides important tools for analysis and retinal disease interpretation. Results also indicate promise for better diagnostics and treatment of retinal diseases. Research thus contributes to development of advanced imaging methods.,1,AI
"This paper introduces a new method for generating realistic 3D facial expressions by combining adversarial learning and dense guidance on geometry. The method makes use of relationships among facial landmarks and expressions to guide the synthesis process and thus improves results over previous methods which rely solely on appearance features. The adversarial part of the method encourages synthesized expressions to better match real expression distributions leading to more natural and credible results. Effectiveness of the proposed method has been tested via a series of both quantitative and qualitative evaluations; results indicate this method excels state of the art regarding realism and consistency with given geometry. Results show promise for diverse application domains including graphics, vision and HCI.",1,AI
This paper introduces a strategy design based on learning for assisted therapy using robots for people with dementia. Proposed method integrates a new model that enhances therapeutic sessions for people with dementia by personalizing them and making them interactive. The model considers the individual's current cognitive and emotional status as well as past experiences and preferred way of communication. Strategy uses learning algorithms to process patient data and adjust the therapy session flexibly; this provides an individually tailored experience that works effectively. Results from a pilot study show that this proposed approach is feasible and effective at improving wellbeing and cognitive and emotional status of patients. Results have significant implications regarding design and deployment of robot assisted therapy and also point towards promising future possibilities of learning strategies for personalized care of people with dementia.,1,AI
"The datasets of face recognition contain an enormous number of identities and instances. However, conventional methods have difficulty in reflecting the entire distribution of the datasets because a mini-batch of small size contains only a small portion of all identities. To overcome this difficulty, we propose a novel method called BroadFace, which is a learning process to consider a massive set of identities, comprehensively. In BroadFace, a linear classifier learns optimal decision boundaries among identities from a large number of embedding vectors accumulated over past iterations. By referring more instances at once, the optimality of the classifier is naturally increased on the entire datasets. Thus, the encoder is also globally optimized by referring the weight matrix of the classifier. Moreover, we propose a novel compensation method to increase the number of referenced instances in the training stage. BroadFace can be easily applied on many existing methods to accelerate a learning process and obtain a significant improvement in accuracy without extra computational burden at inference stage. We perform extensive ablation studies and experiments on various datasets to show the effectiveness of BroadFace, and also empirically prove the validity of our compensation method. BroadFace achieves the state-of-the-art results with significant improvements on nine datasets in 1:1 face verification and 1:N face identification tasks, and is also effective in image retrieval.",0,Human
This paper introduces a new method for designing optimal decentralized controllers over networks with infinite horizons considering unreliable communication. The research uses decentralized control strategies which consider communication limitations and possible communication breakdowns to ensure stability and optimality in large scale networked control systems. Proposed method integrates control networking with theory to develop a comprehensive design framework for robust controllers against communication disruptions. Results of numerical simulation show effectiveness of this proposed method for achieving high performance under unreliable communication.,1,AI
"Fog radio access networks (F-RANs), which consist of a cloud and multiple edge nodes (ENs) connected via fronthaul links, have been regarded as promising network architectures. The F-RAN entails a joint optimization of cloud and edge computing as well as fronthaul interactions, which is challenging for traditional optimization techniques. This paper proposes a Cloud-Enabled Cooperation-Inspired Learning (CECIL) framework, a structural deep learning mechanism for handling a generic F-RAN optimization problem. The proposed solution mimics cloud-aided cooperative optimization policies by including centralized computing at the cloud, distributed decision at the ENs, and their uplink-downlink fronthaul interactions. A group of deep neural networks (DNNs) are employed for characterizing computations of the cloud and ENs. The forwardpass of the DNNs is carefully designed such that the impacts of the practical fronthaul links, such as channel noise and signling overheads, can be included in a training step. As a result, operations of the cloud and ENs can be jointly trained in an end-to-end manner, whereas their real-time inferences are carried out in a decentralized manner by means of the fronthaul coordination. To facilitate fronthaul cooperation among multiple ENs, the optimal fronthaul multiple access schemes are designed. Training algorithms robust to practical fronthaul impairments are also presented. Numerical results validate the effectiveness of the proposed approaches.",0,Human
"Integration of Artificial Intelligence (AI) in upcoming wireless systems such as B5G and 6G has the potential to transform performance and user experiences. However, as systems grow more complex and rely increasingly on data, the need for explainability and transparency is growing so that users can understand how decisions are made. Research into Explainable AI (XAI) aims to make AI models more understandable and transparent for users. This paper looks at technical aspects, use cases and research challenges of XAI for B5G and 6G systems. First, we introduce what XAI is and why it is important in this context. Then we consider technical elements of XAI like model architecture, algorithms and techniques for transparency and understanding. We also talk about data quality and labeling and roles of humans in XAI. Use cases include optimization of networks and smart traffic management among others. Benefits and limitations of XAI are highlighted along with its effect on overall performance. Finally we address research challenges including scalability, security, privacy and regulatory issues and discuss future directions. We also stress that interdisciplinary collaboration among AI, wireless communication and social sciences is important to overcome these challenges. Ultimately XAI promises important insights into complex decision making but successful deployment in wireless systems will require addressing many technical and research hurdles. This paper gives a detailed overview of XAI for B5G and 6G systems and highlights its significance, technical aspects, use cases and research challenges.",1,AI
Segmentation of pathology images into different labels is important in medical image analysis because it lets us understand the structure and tissue types. Traditional segmentation methods usually struggle with variability in imaging and pathology cases and often result in errors. This paper introduces new interactive methods that do a better job at handling variation and require less user input. We combine traditional segmentation algorithms with interactive features so that users have only minimal input needed to refine results. Results show improvements over previous best methods regarding accuracy and robustness. This research offers promising solutions for segmentation challenges in medical imaging and may have practical uses like diagnosis support and clinical decision making.,1,AI
"The goal of this paper is to establish which practical routing schemes for wireless networks are most suitable for wideband systems in the power-limited regime, which is, for example, a practically relevant mode of operation for the analysis of ultrawideband (UWB) mesh networks. For this purpose, we study the tradeoff between energy efficiency and spectral efficiency (known as the power-bandwidth tradeoff) in a wideband linear multihop network in which transmissions employ orthogonal frequency-division multiplexing (OFDM) modulation and are affected by quasi-static, frequency-selective fading. Considering open-loop (fixed-rate) and closed-loop (rate-adaptive) multihop relaying techniques, we characterize the impact of routing with spatial reuse on the statistical properties of the end-to-end conditional mutual information (conditioned on the specific values of the channel fading parameters and therefore treated as a random variable) and on the energy and spectral efficiency measures of the wideband regime. Our analysis particularly deals with the convergence of these end-to-end performance measures in the case of large number of hops, i.e., the phenomenon first observed in \cite{Oyman06b} and named as ``multihop diversity''. Our results demonstrate the realizability of the multihop diversity advantages in the case of routing with spatial reuse for wideband OFDM systems under wireless channel effects such as path-loss and quasi-static frequency-selective multipath fading.",0,Human
This paper introduces a new approach called Panoptic Fusion for semantic volumetric mapping online. It considers both 'stuff' and 'things'. Panoptic Fusion merges visual information from a 3D LiDAR sensor and semantic information from RGB images into one dense environment representation. A new fusion method using probability theory fuses different data types. Results of this method are both accurate and rich semantically and they facilitate efficient and effective decisions for robotics. Results are evaluated thoroughly on diverse indoor and outdoor scenes and show Panoptic Fusion outperforms leading methods today. Results indicate segmentation of semantic classes and reconstruction of 3D geometry is very high quality. Results point toward great potential for improving perception in real world robotics.,1,AI
"Automatic segmentation methods are an important advancement in medical image analysis. Machine learning techniques, and deep neural networks in particular, are the state-of-the-art for most medical image segmentation tasks. Issues with class imbalance pose a significant challenge in medical datasets, with lesions often occupying a considerably smaller volume relative to the background. Loss functions used in the training of deep learning algorithms differ in their robustness to class imbalance, with direct consequences for model convergence. The most commonly used loss functions for segmentation are based on either the cross entropy loss, Dice loss or a combination of the two. We propose the Unified Focal loss, a new hierarchical framework that generalises Dice and cross entropy-based losses for handling class imbalance. We evaluate our proposed loss function on five publicly available, class imbalanced medical imaging datasets: CVC-ClinicDB, Digital Retinal Images for Vessel Extraction (DRIVE), Breast Ultrasound 2017 (BUS2017), Brain Tumour Segmentation 2020 (BraTS20) and Kidney Tumour Segmentation 2019 (KiTS19). We compare our loss function performance against six Dice or cross entropy-based loss functions, across 2D binary, 3D binary and 3D multiclass segmentation tasks, demonstrating that our proposed loss function is robust to class imbalance and consistently outperforms the other loss functions. Source code is available at: https://github.com/mlyg/unified-focal-loss",0,Human
This paper studies the issue of uniformity within variability in relation to crowd counting focusing specifically on count intervals. The aim is to study deeply this subject and conduct a comprehensive analysis of different approaches that are used for count intervals. The paper looks at what strengths and weaknesses these approaches have. It also investigates the impact of different methods for partitioning count intervals on accuracy of counting people. Insights are sought as to how to balance uniformity and variability better. Results of this investigation have implications for further development of higher accuracy systems and reveal important aspects about this problem.,1,AI
"This paper introduces an innovative method for learning predictive models that integrate both theoretical knowledge and data science. This new approach, called HCP stands for Theory Guided Hard Constraint Projection. It learns an approximation based on data and then projects this result into a feasible solution space via physical constraint knowledge. There are two steps involved in training: learning an initial data driven approximation followed by projecting the resulting solution onto the feasible solution space according to physical constraints. Results of theoretical analysis of HCP compared to other ML techniques on various numerical experiments show that HCP excels at learning consistent models and performs well with new data. Experiments also showcase that HCP has potential to solve problems such as interpretability and transferability in scientific ML. In summary, the research advances methods that can integrate domain specific knowledge and ensure consistency in predictive models through theoretical guidance.",1,AI
"This study looks at how neural networks can contribute to understanding the detection, prediction, and influence of the coronavirus (COVID-19) pandemic through the use of large data sets. Using these data sets a neural network model is trained to examine the spread of the virus across various regions and weather conditions. Results show the model accurately predicts case numbers, fatalities and hospital admissions with high precision. Also, the model identifies important factors which influence the spread of the virus such as humidity, temperature and pollution. Results show that high humidity and low temperature accelerate spread of the virus. Furthermore, patterns and trends are detected by the model that can help policymakers make better decisions about dealing with the pandemic. Results showed that lockdowns, social distancing and wearing masks work to reduce spread of the virus. Overall results suggest that neural networks can offer useful insight into detection, prediction and weather effects related to the pandemic. Insights from this research can guide policymakers on effective actions to control spread of virus and lessen impact of pandemic.",1,AI
"We introduce a flexible, scalable Bayesian inference framework for nonlinear dynamical systems characterised by distinct and hierarchical variability at the individual, group, and population levels. Our model class is a generalisation of nonlinear mixed-effects (NLME) dynamical systems, the statistical workhorse for many experimental sciences. We cast parameter inference as stochastic optimisation of an end-to-end differentiable, block-conditional variational autoencoder. We specify the dynamics of the data-generating process as an ordinary differential equation (ODE) such that both the ODE and its solver are fully differentiable. This model class is highly flexible: the ODE right-hand sides can be a mixture of user-prescribed or ""white-box"" sub-components and neural network or ""black-box"" sub-components. Using stochastic optimisation, our amortised inference algorithm could seamlessly scale up to massive data collection pipelines (common in labs with robotic automation). Finally, our framework supports interpretability with respect to the underlying dynamics, as well as predictive generalization to unseen combinations of group components (also called ""zero-shot"" learning). We empirically validate our method by predicting the dynamic behaviour of bacteria that were genetically engineered to function as biosensors. Our implementation of the framework, the dataset, and all code to reproduce the experimental results is available at https://www.github.com/Microsoft/vi-hds .",0,Human
"Human pose estimation is a fundamental yet challenging task in computer vision, which aims at localizing human anatomical keypoints. However, unlike human vision that is robust to various data corruptions such as blur and pixelation, current pose estimators are easily confused by these corruptions. This work comprehensively studies and addresses this problem by building rigorous robust benchmarks, termed COCO-C, MPII-C, and OCHuman-C, to evaluate the weaknesses of current advanced pose estimators, and a new algorithm termed AdvMix is proposed to improve their robustness in different corruptions. Our work has several unique benefits. (1) AdvMix is model-agnostic and capable in a wide-spectrum of pose estimation models. (2) AdvMix consists of adversarial augmentation and knowledge distillation. Adversarial augmentation contains two neural network modules that are trained jointly and competitively in an adversarial manner, where a generator network mixes different corrupted images to confuse a pose estimator, improving the robustness of the pose estimator by learning from harder samples. To compensate for the noise patterns by adversarial augmentation, knowledge distillation is applied to transfer clean pose structure knowledge to the target pose estimator. (3) Extensive experiments show that AdvMix significantly increases the robustness of pose estimations across a wide range of corruptions, while maintaining accuracy on clean data in various challenging benchmark datasets.",0,Human
"This paper introduces a parallel algorithm for weighted random sampling of big data sets. Sampling proportional to weights is very important for statistics, machine learning, and data mining as this process draws samples from a set according to weight proportions. Proposed is an algorithm that makes use of parallelism of current multicore processors and distributed systems for high performance and scalability. This algorithm relies on reservoir sampling techniques that keep a reservoir of fixed size and replace reservoir items randomly with respect to weights. Parallelization is achieved by dividing data into smaller subsets and applying reservoir sampling independently to each subset. Further optimization of parallelism is done using dynamic load balancing which adjusts subset sizes to reduce communication costs and balance workload. Results on both simulated and real data sets show that the algorithm performs very well in terms of efficiency and accuracy. Performance evaluation shows that speedups are significant and scalability increases with bigger data and computing nodes. Comparison against other parallel weighted sampling methods indicates that this new algorithm excels and has broader flexibility. In summary, this work proposes a parallel algorithm that uses modern parallel systems power. This algorithm provides effective and scalable solutions for large scale statistical and mining tasks that need weighted random sampling. Future work could extend this algorithm to adapt to different sampling schemes and weightings.",1,AI
This paper introduces a new way of estimating distance using efferent copies and maneuvers of optical flow. Proposed technique uses stability as important factor to increase accuracy when estimating distances in dynamic situations. Study uses efferent copies which are brain-generated command copies and optical flow data to perform an analysis based on stability of visual scenes. Results from experimental work demonstrate proposed strategy performs better than current methods and has promise for practical use such as robotics and autonomous systems.,1,AI
"Manipulating facial expressions is a challenging task due to fine-grained shape changes produced by facial muscles and the lack of input-output pairs for supervised learning. Unlike previous methods using Generative Adversarial Networks (GAN), which rely on cycle-consistency loss or sparse geometry (landmarks) loss for expression synthesis, we propose a novel GAN framework to exploit 3D dense (depth and surface normals) information for expression manipulation. However, a large-scale dataset containing RGB images with expression annotations and their corresponding depth maps is not available. To this end, we propose to use an off-the-shelf state-of-the-art 3D reconstruction model to estimate the depth and create a large-scale RGB-Depth dataset after a manual data clean-up process. We utilise this dataset to minimise the novel depth consistency loss via adversarial learning (note we do not have ground truth depth maps for generated face images) and the depth categorical loss of synthetic data on the discriminator. In addition, to improve the generalisation and lower the bias of the depth parameters, we propose to use a novel confidence regulariser on the discriminator side of the framework. We extensively performed both quantitative and qualitative evaluations on two publicly available challenging facial expression benchmarks: AffectNet and RaFD. Our experiments demonstrate that the proposed method outperforms the competitive baseline and existing arts by a large margin.",0,Human
"This paper looks at what artificial intelligence (AI) is currently like and how we are working toward developing responsible AI and deploying it properly. We start with defining responsible AI along with some important principles like transparency, accountability, fairness and ethics. The authors next look at where AI stands today and discuss obstacles to responsible AI like unclear guidelines and regulations and the need for diverse viewpoints and engagement from different groups. There's also looking at roles of different actors including government, companies and academia on advancing responsible AI. Authors also review current initiatives and good practices such as development of ethical frameworks, creation of AI ethics committees and embedding ethics into AI curriculum. In conclusion this paper emphasizes that we must continue collaboration and action from all involved and stresses importance of clear standards and embedding ethics into the process of AI development and deployment so that we can develop AI responsibly and sustainably. Authors urge for further development of clear and enforceable standards and embedding ethics into processes of AI development and deployment.",1,AI
"In this work, we initiate the study of \emph{smoothed analysis} of population protocols. We consider a population protocol model where an adaptive adversary dictates the interactions between agents, but with probability $p$ every such interaction may change into an interaction between two agents chosen uniformly at random. That is, $p$-fraction of the interactions are random, while $(1-p)$-fraction are adversarial. The aim of our model is to bridge the gap between a uniformly random scheduler (which is too idealistic) and an adversarial scheduler (which is too strict).  We focus on the fundamental problem of leader election in population protocols. We show that, for a population of size $n$, the leader election problem can be solved in $O(p^{-2}n \log^3 n)$ steps with high probability, using $O((\log^2 n) \cdot (\log (n/p)))$ states per agent, for \emph{all} values of $p\leq 1$. Although our result does not match the best known running time of $O(n \log n)$ for the uniformly random scheduler ($p=1$), we are able to present a \emph{smooth transition} between a running time of $O(n \cdot \mathrm{polylog} n)$ for $p=1$ and an infinite running time for the adversarial scheduler ($p=0$), where the problem cannot be solved. The key technical contribution of our work is a novel \emph{phase clock} algorithm for our model. This is a key primitive for much-studied fundamental population protocol algorithms (leader election, majority), and we believe it is of independent interest.",0,Human
This paper introduces a new loss function named Unified Focal Loss (UFL). UFL unifies two popular losses: Dice loss and cross entropy loss to avoid their drawbacks. UFL assigns greater weights to minority classes and reduces influence from simple samples. Results on diverse medical imaging data sets indicate that UFL outperforms traditional Dice loss and cross entropy loss; thus it excels at dealing with imbalance and improves segmentation accuracy. Results also show UFL is promising for segmentation and might serve as a valuable tool for both researchers and practitioners.,1,AI
"This paper introduces Bee$^+$. It is a new insect-sized flyer weighing 95 milligrams and powered by paired unimorph actuators. Designed to mimic bee flight, this robot aims at being highly agile and flexible for tasks like environmental monitoring, rescue missions and exploration. Capable of rapid hover, turns and acceleration, Bee$^+$ excels because of its small size and low weight for moving through complex spaces. Design and control systems are detailed along with onboard cameras and inertial sensors. Results show stable flight and successful navigation through messy areas. Overall, Bee$^+ $ is a major advance in micro aerial robotics and useful for various uses.",1,AI
"Ramsey's theorem, in the version of Erd\H{o}s and Szekeres, states that every 2-coloring of the edges of the complete graph on {1, 2,...,n} contains a monochromatic clique of order 1/2\log n. In this paper, we consider two well-studied extensions of Ramsey's theorem.  Improving a result of R\""odl, we show that there is a constant $c>0$ such that every 2-coloring of the edges of the complete graph on \{2, 3,...,n\} contains a monochromatic clique S for which the sum of 1/\log i over all vertices i \in S is at least c\log\log\log n. This is tight up to the constant factor c and answers a question of Erd\H{o}s from 1981.  Motivated by a problem in model theory, V\""a\""an\""anen asked whether for every k there is an n such that the following holds. For every permutation \pi of 1,...,k-1, every 2-coloring of the edges of the complete graph on {1, 2, ..., n} contains a monochromatic clique a_1<...<a_k with a_{\pi(1)+1}-a_{\pi(1)}>a_{\pi(2)+1}-a_{\pi(2)}>...>a_{\pi(k-1)+1}-a_{\pi(k-1)}. That is, not only do we want a monochromatic clique, but the differences between consecutive vertices must satisfy a prescribed order. Alon and, independently, Erd\H{o}s, Hajnal and Pach answered this question affirmatively. Alon further conjectured that the true growth rate should be exponential in k. We make progress towards this conjecture, obtaining an upper bound on n which is exponential in a power of k. This improves a result of Shelah, who showed that n is at most double-exponential in k.",0,Human
"Software cost estimation is one of the prerequisite managerial activities carried out at the software development initiation stages and also repeated throughout the whole software life-cycle so that amendments to the total cost are made. In software cost estimation typically, a selection of project attributes is employed to produce effort estimations of the expected human resources to deliver a software product. However, choosing the appropriate project cost drivers in each case requires a lot of experience and knowledge on behalf of the project manager which can only be obtained through years of software engineering practice. A number of studies indicate that popular methods applied in the literature for software cost estimation, such as linear regression, are not robust enough and do not yield accurate predictions. Recently the dual variables Ridge Regression (RR) technique has been used for effort estimation yielding promising results. In this work we show that results may be further improved if an AI method is used to automatically select appropriate project cost drivers (inputs) for the technique. We propose a hybrid approach combining RR with a Genetic Algorithm, the latter evolving the subset of attributes for approximating effort more accurately. The proposed hybrid cost model has been applied on a widely known high-dimensional dataset of software project samples and the results obtained show that accuracy may be increased if redundant attributes are eliminated.",0,Human
"In the last two years, more than 200 papers have been written on how machine learning (ML) systems can fail because of adversarial attacks on the algorithms and data; this number balloons if we were to incorporate papers covering non-adversarial failure modes. The spate of papers has made it difficult for ML practitioners, let alone engineers, lawyers, and policymakers, to keep up with the attacks against and defenses of ML systems. However, as these systems become more pervasive, the need to understand how they fail, whether by the hand of an adversary or due to the inherent design of a system, will only become more pressing. In order to equip software developers, security incident responders, lawyers, and policy makers with a common vernacular to talk about this problem, we developed a framework to classify failures into ""Intentional failures"" where the failure is caused by an active adversary attempting to subvert the system to attain her goals; and ""Unintentional failures"" where the failure is because an ML system produces an inherently unsafe outcome. After developing the initial version of the taxonomy last year, we worked with security and ML teams across Microsoft, 23 external partners, standards organization, and governments to understand how stakeholders would use our framework. Throughout the paper, we attempt to highlight how machine learning failure modes are meaningfully different from traditional software failures from a technology and policy perspective.",0,Human
"This paper looks at Nash dynamics of equilibrium in markets where buyers and sellers must be matched before transactions take place. Using game theory and mathematical modeling, we study conditions for reaching stable equilibrium and what causes instability. We also consider practical implications for actual markets and discuss possible policy interventions to enhance market performance. Research stresses significance of understanding matching market dynamics so that efficient and fair policies can be developed for these important economic systems.",1,AI
"The visual cue of optical flow plays a major role in the navigation of flying insects, and is increasingly studied for use by small flying robots as well. A major problem is that successful optical flow control seems to require distance estimates, while optical flow is known to provide only the ratio of velocity to distance. In this article, a novel, stability-based strategy is proposed to estimate distances with monocular optical flow and knowledge of the control inputs (efference copies). It is shown analytically that given a fixed control gain, the stability of a constant divergence control loop only depends on the distance to the approached surface. At close distances, the control loop first starts to exhibit self-induced oscillations, eventually leading to instability. The proposed stability-based strategy for estimating distances has two major attractive characteristics. First, self-induced oscillations are easy for the robot to detect and are hardly influenced by wind. Second, the distance can be estimated during a zero divergence maneuver, i.e., around hover. The stability-based strategy is implemented and tested both in simulation and with a Parrot AR drone 2.0. It is shown that it can be used to: (1) trigger a final approach response during a constant divergence landing with fixed gain, (2) estimate the distance in hover, and (3) estimate distances during an entire landing if the robot uses adaptive gain control to continuously stay on the 'edge of oscillation'.",0,Human
"This paper introduces a hybrid network for learning shared representations between different types of data including text, images and sound. The hybrid network uses both unsupervised and supervised learning to map diverse data types into a unified space and preserve key features from each type. Unsupervised learning part learns this common representation using a cross modality auto encoder while supervised learning employs a classifier to improve the discriminative ability of the model. Evaluation results show strong performance compared to leading methods on benchmarks. Results suggest that this hybrid network can effectively integrate information across different data types and advance downstream tasks like recommendation and cross modal search.",1,AI
"In this paper, we study the Nash dynamics of strategic interplays of n buyers in a matching market setup by a seller, the market maker. Taking the standard market equilibrium approach, upon receiving submitted bid vectors from the buyers, the market maker will decide on a price vector to clear the market in such a way that each buyer is allocated an item for which he desires the most (a.k.a., a market equilibrium solution). While such equilibrium outcomes are not unique, the market maker chooses one (maxeq) that optimizes its own objective --- revenue maximization. The buyers in turn change bids to their best interests in order to obtain higher utilities in the next round's market equilibrium solution.  This is an (n+1)-person game where buyers place strategic bids to gain the most from the market maker's equilibrium mechanism. The incentives of buyers in deciding their bids and the market maker's choice of using the maxeq mechanism create a wave of Nash dynamics involved in the market. We characterize Nash equilibria in the dynamics in terms of the relationship between maxeq and mineq (i.e., minimum revenue equilibrium), and develop convergence results for Nash dynamics from the maxeq policy to a mineq solution, resulting an outcome equivalent to the truthful VCG mechanism.  Our results imply revenue equivalence between maxeq and mineq, and address the question that why short-term revenue maximization is a poor long run strategy, in a deterministic and dynamic setting.",0,Human
"Learning disentangled representation of data without supervision is an important step towards improving the interpretability of generative models. Despite recent advances in disentangled representation learning, existing approaches often suffer from the trade-off between representation learning and generation performance i.e. improving generation quality sacrifices disentanglement performance). We propose an Information-Distillation Generative Adversarial Network (ID-GAN), a simple yet generic framework that easily incorporates the existing state-of-the-art models for both disentanglement learning and high-fidelity synthesis. Our method learns disentangled representation using VAE-based models, and distills the learned representation with an additional nuisance variable to the separate GAN-based generator for high-fidelity synthesis. To ensure that both generative models are aligned to render the same generative factors, we further constrain the GAN generator to maximize the mutual information between the learned latent code and the output. Despite the simplicity, we show that the proposed method is highly effective, achieving comparable image generation quality to the state-of-the-art methods using the disentangled representation. We also show that the proposed decomposition leads to an efficient and stable model design, and we demonstrate photo-realistic high-resolution image synthesis results (1024x1024 pixels) for the first time using the disentangled representations.",0,Human
"The proven efficacy of learning-based control schemes strongly motivates their application to robotic systems operating in the physical world. However, guaranteeing correct operation during the learning process is currently an unresolved issue, which is of vital importance in safety-critical systems. We propose a general safety framework based on Hamilton-Jacobi reachability methods that can work in conjunction with an arbitrary learning algorithm. The method exploits approximate knowledge of the system dynamics to guarantee constraint satisfaction while minimally interfering with the learning process. We further introduce a Bayesian mechanism that refines the safety analysis as the system acquires new evidence, reducing initial conservativeness when appropriate while strengthening guarantees through real-time validation. The result is a least-restrictive, safety-preserving control law that intervenes only when (a) the computed safety guarantees require it, or (b) confidence in the computed guarantees decays in light of new observations. We prove theoretical safety guarantees combining probabilistic and worst-case analysis and demonstrate the proposed framework experimentally on a quadrotor vehicle. Even though safety analysis is based on a simple point-mass model, the quadrotor successfully arrives at a suitable controller by policy-gradient reinforcement learning without ever crashing, and safely retracts away from a strong external disturbance introduced during flight.",0,Human
"This paper introduces a new method of language modeling by integrating neural trans dimensional random fields. This integration allows diverse sources of information to be incorporated flexibly and efficiently. In particular, neural networks are used to extract features from the input data and these features are then included in the random field model. As a result, the resulting model can capture intricate relationships among words and sentences and can perform tasks such as language generation and sentiment analysis. Results of experiments conducted on various benchmark datasets demonstrate effectiveness of the proposed approach. Results indicate that this model outperforms leading models including recurrent neural networks and transformers in both accuracy and efficiency. Additionally, this model shows strong generalization abilities; it works well on unseen data and noisy data too. Overall, this paper provides new insights into modeling language and highlights the advantages of combining neural nets with random fields. Implications for natural language processing are significant and point towards more accurate and efficient models.",1,AI
This paper applies ordinary differential equations to Markov Decision Processes (MDPs) to optimize the KL cost. A detailed evaluation of different ODE techniques for solving MDPs is presented. Results show that using ODEs is effective compared to traditional methods such as dynamic programming. Numerical experiments are conducted to support findings. Results show that ODEs can produce both efficient and accurate solutions especially when considering KL cost as a performance metric. Concluding remarks highlight future research directions for control and decision making.,1,AI
"This paper introduces a new method for unsupervised matching of data and text; this method seeks to automatically associate pertinent data records with text descriptions without using labeled training data. Proposed approach uses powerful unsupervised learning techniques such as clustering and topic modeling to generate data and text representations capturing underlying semantic structure. Method consists of two stages where first data and texts are transformed into vector representation by combining feature extraction and dimensionality reduction techniques. Matching function is then defined based on similarity of those vectors via cosine similarity which allows identification of data records that share similar semantics to a specific description. Performance is evaluated on two real data sets and compared against leading baselines. Results show that this method performs better than previous unsupervised approaches both in terms of matching accuracy and speed, and also performs comparably to supervised methods but at much lower cost in labeling. Overall we highlight promise of unsupervised matching for diverse application areas including information retrieval, recommender systems and data mining.",1,AI
"This research introduces a new method for evaluating professors based on neural networks using particle swarm optimization. The study considers different factors including student assessments, teaching resources and attendance. This allows for more accurate and comprehensive assessment of professor performance. Neural nets with many hidden layers are employed to learn complicated relationships among different inputs and performance. Particle swarm optimization adjusts weights and biases to optimize performance and reduce prediction errors. Results show this method surpasses traditional approaches; it predicts performance better. Conclusions state this method objectively and accurately assesses performance and therefore should be adopted in universities and other educational institutions to enhance teaching effectiveness and learning quality.",1,AI
"Writing accurate numerical software is hard because of many sources of unavoidable uncertainties, including finite numerical precision of implementations. We present a programming model where the user writes a program in a real-valued implementation and specification language that explicitly includes different types of uncertainties. We then present a compilation algorithm that generates a conventional implementation that is guaranteed to meet the desired precision with respect to real numbers. Our verification step generates verification conditions that treat different uncertainties in a unified way and encode reasoning about floating-point roundoff errors into reasoning about real numbers. Such verification conditions can be used as a standardized format for verifying the precision and the correctness of numerical programs. Due to their often non-linear nature, precise reasoning about such verification conditions remains difficult. We show that current state-of-the art SMT solvers do not scale well to solving such verification conditions. We propose a new procedure that combines exact SMT solving over reals with approximate and sound affine and interval arithmetic. We show that this approach overcomes scalability limitations of SMT solvers while providing improved precision over affine and interval arithmetic. Using our initial implementation we show the usefullness and effectiveness of our approach on several examples, including those containing non-linear computation.",0,Human
"This paper introduces an approach for calculating safe paths for a robot moving through a complicated space where there are dynamic obstacles. The method uses probability occupancy functions and sets along with forward stochastic reachability analysis. The method considers uncertainties in obstacle trajectories and guarantees that the robot avoids collisions. First, probabilistic occupancy functions representing the probability of obstacles being present at any point in the space are constructed. Using sensor data these functions are refined and they define a set of possible obstacle configurations. Next, stochastic reachability analysis is conducted forward to calculate states reachable by the robot avoiding collisions with dynamic obstacles. This is done within a bounded time horizon and taking into account uncertainties about obstacle motions. Results from simulations of a rigid body robot moving through a complicated environment show that this method performs well at producing collision free paths that take uncertainty into account. Main contribution here is the use of probability occupancy functions and sets along with forward stochastic reachability analysis to generate safe paths for robots moving through spaces with dynamic obstacles. The method works well in high uncertainty situations and is likely to have broad applicability across different kinds of robotics tasks.",1,AI
"This paper introduces a new method of learning graph representations which uses hierarchical adaptive pooling to learn high order dependencies within graphs. It contains two main parts: a hierarchical pooling layer and an adaptive one. Hierarchical pooling gathers information at different levels of granularity to learn higher order dependencies; adaptive pooling picks the most important nodes based on downstream task relevance. Experiments on benchmark datasets show the new method excels previous ones in terms of performance and efficiency. Analysis also shows that this new approach learns both local and global structure and handles diverse sizes and densities of graphs well. In sum, this paper makes contributions to graph representation learning by introducing a new method effective at capturing high order dependencies.",1,AI
"This research studies how to use receiver feedback to adaptively allocate radio resources such as power and subcarriers to different users based on their channel conditions and video needs. In heterogeneous networks where conditions vary widely and devices differ, this aims at improving video quality and reducing delay. Results from simulations show that this approach works better than previous methods; performance metrics include video quality and latency. Results also indicate that this technique distributes resources fairly and supports many users who have different preferences regarding video quality. Results suggest that this method of using receivers to multicast videos using NOMA systems performs well for diverse network environments.",1,AI
"We introduce Bee$^+$, a 95-mg four-winged microrobot with improved controllability and open-loop-response characteristics with respect to those exhibited by state-of-the-art two-winged microrobots with the same size and similar weight (i.e., the 75-mg Harvard RoboBee). The key innovation that made possible the development of Bee$^+$ is the introduction of an extremely light (28-mg) pair of twinned unimorph actuators, which enabled the design of a new microrobotic mechanism that flaps four wings independently. A first main advantage of the proposed design, compared to those of two-winged flyers, is that by increasing the number of actuators from two to four, the number of direct control inputs increases from three to four when simple sinusoidal excitations are employed. A second advantage of Bee$^+$ is that its four-wing configuration and flapping mode naturally damp the rotational disturbances that commonly affect the yaw degree of freedom of two-winged microrobots. In addition, the proposed design greatly reduces the complexity of the associated fabrication process compared to those of other microrobots, as the unimorph actuators are fairly easy to build. Lastly, we hypothesize that given the relatively low wing-loading affecting their flapping mechanisms, the life expectancy of Bee$^+$s must be considerably higher than those of the two-winged counterparts. The functionality and basic capabilities of the robot are demonstrated through a set of simple control experiments.",0,Human
"In this paper we investigate the problem of allocating spectrum among radio nodes under SINR requirements. This problem is of special interest in dynamic spectrum access networks where topology and spectral resources differ with time and location. The problem is to determine the number of radio nodes that can transmit simultaneously while still achieving their SINR requirements and then decide which channels these nodes should transmit on. Previous work have shown how this can be done for a large spectrum pool where nodes allocate multiple channels from that pool which renders a linear programming approach feasible when the pool is large enough. In this paper we extend their work by considering arbitrary individual pool sizes and allow nodes to only transmit on one channel. Due to the accumulative nature of interference this problem is a non-convex integer problem which is NP-hard. However, we introduce a constraint transformation that transforms the problem to a binary quadratic constraint problem. Although this problem is still NP-hard, well known heuristic algorithms for solving this problem are known in the literature. We implement a heuristic algorithm based on Lagrange relaxation which bounds the solution value of the heuristic to the optimal value of the constraint transformed problem. Simulation results show that this approach provides solutions within an average gap of 10% of solutions obtained by a genetic algorithm for the original non-convex integer problem.",0,Human
"This paper introduces a new method for building trees that approximate shortest paths in graphs which may have faulty edges. The method aims at fault tolerance so that it can reliably return good results even if some edges fail or disconnect. Built on a mix of classical graph algorithms and approximation techniques, it was thoroughly tested using both artificial and actual data sets. Results indicate that compared to other methods, this approach excels in accuracy as well as fault tolerance and scalability. In sum, this work advances development of robust and efficient algorithms for solving problems related to short path trees in big and rapidly changing networks.",1,AI
"OdoViz is a reactive web-based tool for 3D visualization and processing of autonomous vehicle datasets designed to support common tasks in visual place recognition research. The system includes functionality for loading, inspecting, visualizing, and processing GPS/INS poses, point clouds and camera images. It supports a number of commonly used driving datasets and can be adapted to load custom datasets with minimal effort. OdoViz's design consists of a slim server to serve the datasets coupled with a rich client frontend. This design supports multiple deployment configurations including single user stand-alone installations, research group installations serving datasets internally across a lab, or publicly accessible web-frontends for providing online interfaces for exploring and interacting with datasets. The tool allows viewing complete vehicle trajectories traversed at multiple different time periods simultaneously, facilitating tasks such as sub-sampling, comparing and finding pose correspondences both across and within sequences. This significantly reduces the effort required in creating subsets of data from existing datasets for machine learning tasks. Further to the above, the system also supports adding custom extensions and plugins to extend the capabilities of the software for other potential data management, visualization and processing tasks. The platform has been open-sourced to promote its use and encourage further contributions from the research community.",0,Human
"Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the `Stoch'. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then analyze the resulting walking by using principal component analysis. We observe that the kMPs extracted from PCA followed a similar pattern irrespective of the type of gaits generated. Leveraging on this underlying structure, we then realize walking in Stoch by a straightforward reconstruction of joint trajectories from kMPs. This type of methodology improves the transferability of these gaits to real hardware, lowers the computational overhead on-board, and also avoids multiple training iterations by generating a set of derived behaviors from a single learned gait.",0,Human
"Depth coding in 3D-HEVC for the multiview video plus depth (MVD) architecture (i) deforms object shapes due to block-level edge-approximation; (ii) misses an opportunity for high compressibility at near-lossless quality by failing to exploit strong homogeneity (clustering tendency) in depth syntax, motion vector components, and residuals at frame-level; and (iii) restricts interactivity and limits responsiveness of independent use of depth information for ""non-viewing"" applications due to texture-depth coding dependency. This paper presents a standalone depth sequence coder, which operates in the lossless to near-lossless quality range while compressing depth data superior to lossy 3D-HEVC. It preserves edges implicitly by limiting quantisation to the spatial-domain and exploits clustering tendency efficiently at frame-level with a novel binary tree based decomposition (BTBD) technique. For mono-view coding of standard MVD test sequences, on average, (i) lossless BTBD achieved $\times 42.2$ compression-ratio and $-60.0\%$ coding gain against the pseudo-lossless 3D-HEVC, using the lowest quantisation parameter $QP = 1$, and (ii) near-lossless BTBD achieved $-79.4\%$ and $6.98$ dB Bj{\o}ntegaard delta bitrate (BD-BR) and distortion (BD-PSNR), respectively, against 3D-HEVC. In view-synthesis applications, decoded depth maps from BTBD rendered superior quality synthetic-views, compared to 3D-HEVC, with $-18.9\%$ depth BD-BR and $0.43$ dB synthetic-texture BD-PSNR on average.",0,Human
"Auto scaling becomes important for cloud services as they need to handle fluctuating user demand. Traditional auto scaling relies on predefined rules that do not perform well because of variability in cloud environments. This paper studies two new methods for auto scaling: one called self aware and another called adaptive auto scaling. Self aware uses machine learning to forecast future resource needs based on past performance and current system status. Adaptive auto scaling uses control theory to change scaling rules according to real time system feedback. To test performance we ran an experiment with a cloud service and compared self aware and adaptive scaling against traditional scaling. Results indicate both new methods perform better than previous ones with reduced response times and higher use of resources. Adaptive performs better when demand suddenly increases whereas self aware works better at predicting long term usage trends. Overall, this study shows benefits of these approaches and highlights their strengths and weaknesses; we think this will help cloud providers manage resources well and improve user service quality while lowering provisioning cost. We believe that these methods will help cloud providers manage resources well and improve service quality.",1,AI
"Entity resolution is a widely studied problem with several proposals to match records across relations. Matching textual content is a widespread task in many applications, such as question answering and search. While recent methods achieve promising results for these two tasks, there is no clear solution for the more general problem of matching textual content and structured data. We introduce a framework that supports this new task in an unsupervised setting for any pair of corpora, being relational tables or text documents. Our method builds a fine-grained graph over the content of the corpora and derives word embeddings to represent the objects to match in a low dimensional space. The learned representation enables effective and efficient matching at different granularity, from relational tuples to text sentences and paragraphs. Our flexible framework can exploit pre-trained resources, but it does not depends on their existence and achieves better quality performance in matching content when the vocabulary is domain specific. We also introduce optimizations in the graph creation process with an ""expand and compress"" approach that first identifies new valid relationships across elements, to improve matching, and then prunes nodes and edges, to reduce the graph size. Experiments on real use cases and public datasets show that our framework produces embeddings that outperform word embeddings and fine-tuned language models both in results' quality and in execution times.",0,Human
Quantization bias is a known problem in machine learning that can lead to reduced performance. This paper tackles this using a new approach by including a bias term during quantization. This improves performance by reducing quantization errors. Results from various tests show that this new method is effective at reducing bias and improving accuracy compared to previous quantization techniques. We also find information about the tradeoff between quantization errors and bias and stress that both should be considered in quantization processing. Results of this research are significant for deploying ML models in environments with limited resources.,1,AI
"This paper investigates the use of Panda, a platform focusing on user centered development, to develop usable AI systems. Using a case study involving development of a conversational AI assistant for a health care organization, this paper shows that usability features in Panda allowed for iterative collaboration and development focused on user needs and preferences. The paper asserts that through design thinking methods and other features of user centered design that include user testing and creation of personas, developers can produce better systems. Results from the case study show that the development team successfully created an assistant that met the intended audience well and elicited good feedback and high adoption rates. Concluding remarks highlight the importance of design practice that focuses on users when developing AI systems. Results point out that usability features of Panda help developers create better and friendlier systems that could result in higher adoption and better performance across different fields.",1,AI
"This study looks into effectiveness of three different ways of distributing information - elitism, egalitarianism and welfareism - and how they affect performance in task oriented teams. Using experiments with human participants, we find that both elitism and egalitarianism perform better than welfareism. Groups using elitism showed highest performance because information goes to high performers. Groups using egalitarianism also performed better compared to welfareism which allocates information to those in greatest need. Results indicate that focusing on individual performance rather than need works best for teams working on tasks. Practical implications for organizations and policymakers include enhancing team performance through allocation policies designed for groups. Results may guide design of allocation policies in group settings.",1,AI
This paper looks at how to estimate mixing times using just one sample path for reversible Markov chains. Authors introduce a new approach for estimating mixing times which doesn't need many sample paths nor knowledge about stationary distribution. Their method relies on statistical analysis of convergence towards stationary distribution. Results are presented on various examples and compared against other approaches. Results show that this new approach gives reliable mixing time estimates and performs better than others. Conclusion states this approach is an important tool for studying mixing times in reversible Markov chains.,1,AI
"This paper introduces a novel dense nested attention network for detecting small targets using infrared images. Small target detection is hard because infrared images have low contrast and much noise. To solve this problem, the proposed network employs multiscale feature extraction and a dense nested attention mechanism that selectively enhances relevant information and suppresses noise. Specifically, the network comprises a feature extraction module, dense nested attention module, and detection module. Feature extraction module extracts features at different scales from the input images; attention module then generates maps to emphasize informative features at those scales. Detection module uses these attention maps to predict target positions. Performance is evaluated on various benchmark datasets; results show that performance metrics surpass many leading methods in terms of accuracy and robustness. Proposed network may find application in diverse real world scenarios such as military reconnaissance, industrial inspections and environmental monitoring.",1,AI
"This paper introduces a new method for improving efficiency of multi objective algorithms through the use of a hyper heuristic that mimics mutation inspired by biology. Such algorithms are typically used to optimize complex tasks with many goals but perform poorly if used on problems with varied traits or changing landscapes. Proposed here is an approach which uses a mutation operator that modifies search space by generating new solutions through combination of previously known solutions. This modification enhances diversity and prevents premature convergence to local optima leading to better performance on complex and ever changing problems. To test this new approach, this study evaluates it against a set of benchmark problems and compares performance against current top methods. Results show this approach performs better in runtime and produces high quality results. Findings indicate that using mutation inspired hyper heuristics improves performance for such algorithms on complex and dynamic problems. Conclusions discuss implications of results, note limitations and outline future work directions.",1,AI
"This paper focuses on addressing challenges of large scale classification using deep neural networks with complicated label mappings. It proposes a new approach of hierarchical label mapping that transforms original labels into a smaller set of more general classes. This hierarchy helps the network to learn better discriminative features for the original labels and improves overall generalization ability. Results are compared on diverse datasets like ImageNet, CIFAR 100, and MS COCO; they show superior performance both in terms of accuracy and efficiency compared to current best methods. Also this paper details analysis of the proposed method including studies of removal of components and visualization of learned hierarchical mapping. Overall, this proposed method offers a promising solution for classification using deep learning networks with complicated label mappings applicable across different fields such as computer vision, NLP and speech recognition.",1,AI
"This paper looks at using serverless protocols for inventory and tracking with unmanned aircraft systems (UAS). It proposes a framework for an inventory and tracking system that uses UAS to autonomously gather data in real time and transmit it to a remote server. This system includes an aircraft equipped with sensors, local storage modules, and wireless communications. Data collection occurs along predetermined routes and is subsequently sent to a remote server using serverless protocol. Advantages and drawbacks of this new system are discussed such as better data security, lower latency and scalability. Results from simulations and experiments show that this system is feasible and effective. Overall this research indicates that serverless protocols provide viable solutions for inventory and tracking with UAS and result in enhanced security, efficiency and scalability.",1,AI
"This paper investigates reward function assessment for reinforcement learning in traffic control for cities taking into account real world constraints. Authors propose a deep reinforcement learning method for optimizing flow in a complicated urban setting. Performance of system is analyzed using different reward measures such as travel time, delays and emissions. Experiments are run in a simulation environment and results show effectiveness of proposed approach. Results show that choice of reward function strongly affects system performance and recommend future research concentrate on developing better capturing interaction in urban traffic control. In general, this research advances the field of intelligent transportation and provides guidance about implementing reinforcement learning practically in real urban traffic control situations.",1,AI
"We present a strategy grounded in the element removal idea of Bruns and Tortorelli [1] and aimed at reducing computational cost and circumventing potential numerical instabilities of density-based topology optimization. The design variables and the relative densities are both represented on a fixed, uniform finite element grid, and linked through filtering and Heaviside projection. The regions in the analysis domain where the relative density is below a specified threshold are removed from the forward analysis and replaced by fictitious nodal boundary conditions. This brings a progressive cut of the computational cost as the optimization proceeds and helps to mitigate numerical instabilities associated with low-density regions. Removed regions can be readily reintroduced since all the design variables remain active and are modeled in the formal sensitivity analysis. A key feature of the proposed approach is that the Heaviside functions promote material reintroduction along the structural boundaries by amplifying the magnitude of the sensitivities inside the filter reach. Several 2D and 3D structural topology optimization examples are presented, including linear and nonlinear compliance minimization, the design of a force inverter, and frequency and buckling load maximization. The approach is shown to be effective at producing optimized designs equivalent or nearly equivalent to those obtained without the element removal, while providing remarkable computational savings.",0,Human
"Machine learning techniques have enabled robots to learn narrow, yet complex tasks and also perform broad, yet simple skills with a wide variety of objects. However, learning a model that can both perform complex tasks and generalize to previously unseen objects and goals remains a significant challenge. We study this challenge in the context of ""improvisational"" tool use: a robot is presented with novel objects and a user-specified goal (e.g., sweep some clutter into the dustpan), and must figure out, using only raw image observations, how to accomplish the goal using the available objects as tools. We approach this problem by training a model with both a visual and physical understanding of multi-object interactions, and develop a sampling-based optimizer that can leverage these interactions to accomplish tasks. We do so by combining diverse demonstration data with self-supervised interaction data, aiming to leverage the interaction data to build generalizable models and the demonstration data to guide the model-based RL planner to solve complex tasks. Our experiments show that our approach can solve a variety of complex tool use tasks from raw pixel inputs, outperforming both imitation learning and self-supervised learning individually. Furthermore, we show that the robot can perceive and use novel objects as tools, including objects that are not conventional tools, while also choosing dynamically to use or not use tools depending on whether or not they are required.",0,Human
"This paper studies the problem of predicting missing relationships between entities in knowledge graphs through learning their representations. Currently, the majority of existing link prediction models employ simple but intuitive scoring functions and relatively small embedding size so that they could be applied to large-scale knowledge graphs. However, these properties also restrict the ability to learn more expressive and robust features. Therefore, diverging from most of the prior works which focus on designing new objective functions, we propose, DeCom, a simple but effective mechanism to boost the performance of existing link predictors such as DistMult, ComplEx, etc, through extracting more expressive features while preventing overfitting by adding just a few extra parameters. Specifically, embeddings of entities and relationships are first decompressed to a more expressive and robust space by decompressing functions, then knowledge graph embedding models are trained in this new feature space. Experimental results on several benchmark knowledge graphs and advanced link prediction systems demonstrate the generalization and effectiveness of our method. Especially, RESCAL + DeCom achieves state-of-the-art performance on the FB15k-237 benchmark across all evaluation metrics. In addition, we also show that compared with DeCom, explicitly increasing the embedding size significantly increase the number of parameters but could not achieve promising performance improvement.",0,Human
"Trans-dimensional random field language models (TRF LMs) have recently been introduced, where sentences are modeled as a collection of random fields. The TRF approach has been shown to have the advantages of being computationally more efficient in inference than LSTM LMs with close performance and being able to flexibly integrating rich features. In this paper we propose neural TRFs, beyond of the previous discrete TRFs that only use linear potentials with discrete features. The idea is to use nonlinear potentials with continuous features, implemented by neural networks (NNs), in the TRF framework. Neural TRFs combine the advantages of both NNs and TRFs. The benefits of word embedding, nonlinear feature learning and larger context modeling are inherited from the use of NNs. At the same time, the strength of efficient inference by avoiding expensive softmax is preserved. A number of technical contributions, including employing deep convolutional neural networks (CNNs) to define the potentials and incorporating the joint stochastic approximation (JSA) strategy in the training algorithm, are developed in this work, which enable us to successfully train neural TRF LMs. Various LMs are evaluated in terms of speech recognition WERs by rescoring the 1000-best lists of WSJ'92 test data. The results show that neural TRF LMs not only improve over discrete TRF LMs, but also perform slightly better than LSTM LMs with only one fifth of parameters and 16x faster inference efficiency.",0,Human
"The field of analyzing performance is very important and sensitive in particular when it is related to the performance of lecturers in academic institutions. Locating the weak points of lecturers through a system that provides an early warning to notify or reward the lecturers with warned or punished notices will help them to improve their weaknesses, leads to a better quality in the institutions. The current system has major issues in the higher education at Salahaddin University-Erbil (SUE) in Kurdistan-Iraq. These issues are: first, the assessment of lecturers' activities is conducted traditionally via the Quality Assurance Teams at different departments and colleges at the university, second, the outcomes in some cases of lecturers' performance provoke a low level of acceptance among lectures, as these cases are reflected and viewed by some academic communities as unfair cases, and finally, the current system is not accurate and vigorous. In this paper, Particle Swarm Optimization Neural Network is used to assess performance of lecturers in more fruitful way and also to enhance the accuracy of recognition system. Different real and novel data sets are collected from SUE. The prepared datasets preprocessed and important features are then fed as input source to the training and testing phases. Particle Swarm Optimization is used to find the best weights and biases in the training phase of the neural network. The best accuracy rate obtained in the test phase is 98.28 %.",0,Human
"Unless special conditions apply, the attempt to solve ill-conditioned systems of linear equations with standard numerical methods leads to uncontrollably high numerical error. Often, such systems arise from the discretization of operator equations with a large number of discrete variables. In this paper we show that the accuracy can be improved significantly if the equation is transformed before discretization, a process we call full operator preconditioning (FOP). It bears many similarities with traditional preconditioning for iterative methods but, crucially, transformations are applied at the operator level. We show that while condition-number improvements from traditional preconditioning generally do not improve the accuracy of the solution, FOP can. A number of topics in numerical analysis can be interpreted as implicitly employing FOP; we highlight (i) Chebyshev interpolation in polynomial approximation, and (ii) Olver-Townsend's spectral method, both of which produce solutions of dramatically improved accuracy over a naive problem formulation. In addition, we propose a FOP preconditioner based on integration for the solution of fourth-order differential equations with the finite-element method, showing the resulting linear system is well-conditioned regardless of the discretization size, and demonstrate its error-reduction capabilities on several examples. This work shows that FOP can improve accuracy beyond the standard limit for both direct and iterative methods.",0,Human
"MIMO processing plays a central part towards the recent increase in spectral and energy efficiencies of wireless networks. MIMO has grown beyond the original point-to-point channel and nowadays refers to a diverse range of centralized and distributed deployments. The fundamental bottleneck towards enormous spectral and energy efficiency benefits in multiuser MIMO networks lies in a huge demand for accurate channel state information at the transmitter (CSIT). This has become increasingly difficult to satisfy due to the increasing number of antennas and access points in next generation wireless networks relying on dense heterogeneous networks and transmitters equipped with a large number of antennas. CSIT inaccuracy results in a multi-user interference problem that is the primary bottleneck of MIMO wireless networks. Looking backward, the problem has been to strive to apply techniques designed for perfect CSIT to scenarios with imperfect CSIT. In this paper, we depart from this conventional approach and introduce the readers to a promising strategy based on rate-splitting. Rate-splitting relies on the transmission of common and private messages and is shown to provide significant benefits in terms of spectral and energy efficiencies, reliability and CSI feedback overhead reduction over conventional strategies used in LTE-A and exclusively relying on private message transmissions. Open problems, impact on standard specifications and operational challenges are also discussed.",0,Human
"Quantum computation promises significant computational advantages over classical computation for some problems. However, quantum hardware suffers from much higher error rates than in classical hardware. As a result, extensive quantum error correction is required to execute a useful quantum algorithm. The decoder is a key component of the error correction scheme whose role is to identify errors faster than they accumulate in the quantum computer and that must be implemented with minimum hardware resources in order to scale to the regime of practical applications. In this work, we consider surface code error correction, which is the most popular family of error correcting codes for quantum computing, and we design a decoder micro-architecture for the Union-Find decoding algorithm. We propose a three-stage fully pipelined hardware implementation of the decoder that significantly speeds up the decoder. Then, we optimize the amount of decoding hardware required to perform error correction simultaneously over all the logical qubits of the quantum computer. By sharing resources between logical qubits, we obtain a 67% reduction of the number of hardware units and the memory capacity is reduced by 70%. Moreover, we reduce the bandwidth required for the decoding process by a factor at least 30x using low-overhead compression algorithms. Finally, we provide numerical evidence that our optimized micro-architecture can be executed fast enough to correct errors in a quantum computer.",0,Human
"When 5G began its commercialisation journey around 2020, the discussion on the vision of 6G also surfaced. Researchers expect 6G to have higher bandwidth, coverage, reliability, energy efficiency, lower latency, and, more importantly, an integrated ""human-centric"" network system powered by artificial intelligence (AI). Such a 6G network will lead to an excessive number of automated decisions made every second. These decisions can range widely, from network resource allocation to collision avoidance for self-driving cars. However, the risk of losing control over decision-making may increase due to high-speed data-intensive AI decision-making beyond designers and users' comprehension. The promising explainable AI (XAI) methods can mitigate such risks by enhancing the transparency of the black box AI decision-making process. This survey paper highlights the need for XAI towards the upcoming 6G age in every aspect, including 6G technologies (e.g., intelligent radio, zero-touch network management) and 6G use cases (e.g., industry 5.0). Moreover, we summarised the lessons learned from the recent attempts and outlined important research challenges in applying XAI for building 6G systems. This research aligns with goals 9, 11, 16, and 17 of the United Nations Sustainable Development Goals (UN-SDG), promoting innovation and building infrastructure, sustainable and inclusive human settlement, advancing justice and strong institutions, and fostering partnership at the global level.",0,Human
"Smart cities solutions are often monolithically implemented, from sensors data handling through to the provided services. The same challenges are regularly faced by different developers, for every new solution in a new city. Expertise and know-how can be re-used and the effort shared. In this article we present the methodologies to minimize the efforts of implementing new smart city solutions and maximizing the sharing of components. The final target is to have a live technical community of smart city application developers. The results of this activity comes from the implementation of 35 city services in 27 cities between Europe and South Korea. To share efforts, we encourage developers to devise applications using a modular approach. Single-function components that are re-usable by other city services are packaged and published as standalone components, named Atomic Services. We identify 15 atomic services addressing smart city challenges in data analytics, data evaluation, data integration, data validation, and visualization. 38 instances of the atomic services are already operational in several smart city services. We detail in this article, as atomic service examples, some data predictor components. Furthermore, we describe real-world atomic services usage in the scenarios of Santander and three Danish cities. The resulting atomic services also generate a side market for smart city solutions, allowing expertise and know-how to be re-used by different stakeholders.",0,Human
"We present Stable View Synthesis (SVS). Given a set of source images depicting a scene from freely distributed viewpoints, SVS synthesizes new views of the scene. The method operates on a geometric scaffold computed via structure-from-motion and multi-view stereo. Each point on this 3D scaffold is associated with view rays and corresponding feature vectors that encode the appearance of this point in the input images. The core of SVS is view-dependent on-surface feature aggregation, in which directional feature vectors at each 3D point are processed to produce a new feature vector for a ray that maps this point into the new target view. The target view is then rendered by a convolutional network from a tensor of features synthesized in this way for all pixels. The method is composed of differentiable modules and is trained end-to-end. It supports spatially-varying view-dependent importance weighting and feature transformation of source images at each point; spatial and temporal stability due to the smooth dependence of on-surface feature aggregation on the target view; and synthesis of view-dependent effects such as specular reflection. Experimental results demonstrate that SVS outperforms state-of-the-art view synthesis methods both quantitatively and qualitatively on three diverse real-world datasets, achieving unprecedented levels of realism in free-viewpoint video of challenging large-scale scenes. Code is available at https://github.com/intel-isl/StableViewSynthesis",0,Human
"Processing of symbolic sequences represented by mapping of symbolic data into numerical signals is commonly used in various applications. It is a particularly popular approach in genomic and proteomic sequence analysis. Numerous mappings of symbolic sequences have been proposed for various applications. It is unclear however whether the processing of symbolic data provides an artifact of the numerical mapping or is an inherent property of the symbolic data. This issue has been long ignored in the engineering and scientific literature. It is possible that many of the results obtained in symbolic signal processing could be a byproduct of the mapping and might not shed any light on the underlying properties embedded in the data. Moreover, in many applications, conflicting conclusions may arise due to the choice of the mapping used for numerical representation of symbolic data. In this paper, we present a novel framework for the analysis of the equivalence of the mappings used for numerical representation of symbolic data. We present strong and weak equivalence properties and rely on signal correlation to characterize equivalent mappings. We derive theoretical results which establish conditions for consistency among numerical mappings of symbolic data. Furthermore, we introduce an abstract mapping model for symbolic sequences and extend the notion of equivalence to an algebraic framework. Finally, we illustrate our theoretical results by application to DNA sequence analysis.",0,Human
"Vehicular Ad-hoc NETworks (VANETs) are developing at a very fast pace to enable smart transportation in urban cities, by designing some mechanisms for decreasing travel time for commuters by reducing congestion. Inefficient Traffic signals and routing mechanisms are the major factors that contribute to the increase of road congestion. For smoother traffic movement and reducing congestion on the roads, the waiting time at intersections must be reduced and an optimal path should be chosen simultaneously. In this paper, A GPU assisted Preemptive MACO (GMACO-P) algorithm has been proposed to minimize the total travel time of the commuters. GMACO-P is an improvement of MACO-P algorithm that uses the harnessing the power of the GPU to provide faster computations for further minimizing the travel time. The MACO-P algorithm is based on an existing MACO algorithm that avoid the path with the congestion. The MACO-P algorithm reduces the average queue length at intersections by incorporating preemption that ensures less waiting time. In this paper, GMACO-P algorithm is proposed harnessing the power of GPU to improve MACO-P to further reduce the travel time. The GMACO-P algorithm is executed with CUDA toolkit 7.5 using C language and the obtained results were compared with existing Dijkstra, ACO, MACO, MACO-P, parallel implementation of the Dijkstra, ACO and MACO algorithms. Obtained results show the significant reduction in the travel time after using the proposed GMACO-P algorithm.",0,Human
This paper studies incidence coloring of graphs with high maximum average degree. Maximum average degree (MAD) is an indicator of graph connectivity; incidence coloring means assigning colors to both vertices and edges of a graph such that no incident vertex or edge shares the same color. Studies of incidence coloring are useful in fields like graph theory and computer science too. We look at upper limits for incidence chromatic numbers of graphs with high MAD. We use different tools such as graph decomposition and algebra to understand the connection between MAD and chromatic number. Results improve our understanding of coloring behavior for high MAD graphs and advance the design of effective algorithms for incidence coloring.,1,AI
"This paper proposes a principle for operationalizing accountability in computing systems. Called outlining traceability, the paper introduces the current status of accountability and stresses that there is a pressing need for practical and concrete approaches to ensure accountability. Authors suggest using outlining traceability as a way to achieve accountability by emphasizing preservation and recording of relationships among system elements, processes, and data. Benefits of this principle are also considered, such as enhanced auditability, transparency and trustworthiness in computing systems alongside implementation challenges. Finally, implications of this for future research and designing accountable systems along with broader applicability in other fields is discussed.",1,AI
"The human visual perception system has very strong robustness and contextual awareness in a variety of image processing tasks. This robustness and the perception ability of contextual awareness is closely related to the characteristics of multi-task auxiliary learning and subjective attention of the human visual perception system. In order to improve the robustness and contextual awareness of image fusion tasks, we proposed a multi-task auxiliary learning image fusion theory guided by subjective attention. The image fusion theory effectively unifies the subjective task intention and prior knowledge of human brain. In order to achieve our proposed image fusion theory, we first analyze the mechanism of multi-task auxiliary learning, build a multi-task auxiliary learning network. Secondly, based on the human visual attention perception mechanism, we introduce the human visual attention network guided by subjective tasks on the basis of the multi-task auxiliary learning network. The subjective intention is introduced by the subjective attention task model, so that the network can fuse images according to the subjective intention. Finally, in order to verify the superiority of our image fusion theory, we carried out experiments on the combined vision system image data set, and the infrared and visible image data set for experimental verification. The experimental results demonstrate the superiority of our fusion theory over state-of-arts in contextual awareness and robustness.",0,Human
This paper suggests a new method for dealing with Gaussian multiple access channels (GMACs) using feedback. This method improves performance by better aligning codewords sent by users with received channel outputs through use of posterior matching and refinement via feedback. There is also a quantization step to reduce the amount of feedback used. Results from theory show that this new approach performs better than previous decoding methods; simulations confirm that this new scheme works well in practice. Proposed posterior matching scheme with feedback is promising for better performance of communication systems.,1,AI
"A color image contains luminance and chrominance components representing the intensity and color information respectively. The objective of the work presented in this paper is to show the significance of incorporating the chrominance information for the task of scene classification. An improved color-to-grayscale image conversion algorithm by effectively incorporating the chrominance information is proposed using color-to-gay structure similarity index (C2G-SSIM) and singular value decomposition (SVD) to improve the perceptual quality of the converted grayscale images. The experimental result analysis based on the image quality assessment for image decolorization called C2G-SSIM and success rate (Cadik and COLOR250 datasets) shows that the proposed image decolorization technique performs better than 8 existing benchmark algorithms for image decolorization. In the second part of the paper, the effectiveness of incorporating the chrominance component in scene classification task is demonstrated using the deep belief network (DBN) based image classification system developed using dense scale invariant feature transform (SIFT) as features. The levels of chrominance information incorporated by the proposed image decolorization technique is confirmed by the improvement in the overall scene classification accuracy . Also, the overall scene classification performance is improved by the combination of models obtained using the proposed and the conventional decolorization methods.",0,Human
"This paper studies economic factors that lead to vulnerability, trade, and exploitation in current society. Using a broad approach that mixes economic, sociological, and political perspectives, the paper looks into how power relations, globalization and neoliberal policies shape patterns of vulnerability and exploitation. The paper starts by defining vulnerability and considering how things like poverty and insecure jobs impact both individuals and groups. Then it looks at mechanisms of trade and exploitation focusing on how globalization and transnational corporations exploit vulnerable people in the Global South. After that, the study analyzes how neoliberal policies increase vulnerability and exploitation. The paper contends that deregulation, privatization, and austerity weaken labor protection and social safety nets and leave people more exposed to exploitation. In conclusion, the paper considers means to address economic factors contributing to vulnerability, trade and exploitation. It stresses that policies that support social protections and labor rights are important along with international efforts towards equitable development and reducing income disparity. Overall, this paper illuminates complex economic dynamics behind vulnerability, trade and exploitation among modern societies and stresses the urgency of policy interventions for these pressing issues.",1,AI
"This paper studies in depth some interpolation methods that apply to $\mathcal{H}_\infty$ model reduction for systems with multiple inputs and outputs. It focuses on addressing the problem of preserving stability and performance while reducing complexity of the reduced order models. Methods considered are based on balanced truncation, singular perturbation theory, and matching moments. Results are evaluated using numerical experiments on benchmark problems and compared against results from other model reduction techniques. The paper also considers advantages and disadvantages of each method and suggests practical uses. Results should advance this field and offer new insights into designing high efficiency and effectiveness model reduction methods for systems with many inputs and outputs.",1,AI
"This paper introduces a novel method for smart transportation by using a GPU accelerated Preemptive MACO algorithm named GMACO-P. Smart transportation seeks to improve traffic flow efficiency, reduce congestion and offer better comfort and safety for commuters. Traditional traffic control methods have failed to keep up with the growing traffic volume. This study presents a new control algorithm, GMACO P, designed to overcome shortcomings of existing methods. Based on Ant Colony Optimization (ACO), GMACO P optimizes traffic flow in real time. Acceleration via GPUs enables faster and more efficient decision making compared to traditional algorithms using CPUs. Additionally, GMACO P includes preemptive mechanisms allowing dynamic adjustment of traffic lights based on current traffic conditions. Performance is evaluated through simulations using real traffic data; results indicate that GMACO P excels at reducing average travel times, increasing reliability of travel time and reducing congestion. Results also show significant improvement in performance thanks to GPU acceleration. Overall GMACO P stands out as promising approach to smart transportation and far surpasses traditional methods. Results of this research are important contributions to researchers and practitioners in smart transportation. This new algorithm can greatly enhance traffic flow and improve commuting quality.",1,AI
"This paper introduces a new method for generating personalized recommendations by using explicit ratings of users on knowledge graph entities. The proposed system called MindReader addresses challenges of producing high quality and effective recommendations when users have varied preferences and interests. MindReader uses a graph representation of user ratings augmented with information extracted semantically from knowledge graphs. It also employs a matrix factorization technique to personalize recommendations for users. A novel regularization term is included which considers semantic relatedness among entities and improves recommendation accuracy. Results show that MindReader performs better compared to leading algorithms in terms of accuracy, diversity and novelty. Analysis of regularization term shows that incorporating semantic information strongly benefits recommendation performance. This work suggests ways to design recommendation systems that use explicit user ratings along with semantic information from knowledge graphs. Results suggest Mind Reader can improve recommendation quality and enhance user experience in different domains including e-commerce, social media and advertising.",1,AI
"This paper introduces a new way to estimate parameters of Separable Markov Random Fields (SMURF) using binary data. SMURFs are a kind of probabilistic graphical model important in spatial statistics and machine learning; they have broad uses such as image analysis, disease mapping, and network analysis. The new approach combines Maximum Likelihood Estimation (MLE) and Expectation Maximization (EM) algorithms and performs better than current methods regarding both accuracy and computational speed. Results show effectiveness of this new approach via extensive simulation work and real data analysis. Implications for the wider field of spatial statistics and machine learning are also considered.",1,AI
"An accountable algorithmic transparency report (ATR) should ideally investigate the (a) transparency of the underlying algorithm, and (b) fairness of the algorithmic decisions, and at the same time preserve data subjects' privacy. However, a provably formal study of the impact to data subjects' privacy caused by the utility of releasing an ATR (that investigates transparency and fairness), is yet to be addressed in the literature. The far-fetched benefit of such a study lies in the methodical characterization of privacy-utility trade-offs for release of ATRs in public, and their consequential application-specific impact on the dimensions of society, politics, and economics. In this paper, we first investigate and demonstrate potential privacy hazards brought on by the deployment of transparency and fairness measures in released ATRs. To preserve data subjects' privacy, we then propose a linear-time optimal-privacy scheme, built upon standard linear fractional programming (LFP) theory, for announcing ATRs, subject to constraints controlling the tolerance of privacy perturbation on the utility of transparency schemes. Subsequently, we quantify the privacy-utility trade-offs induced by our scheme, and analyze the impact of privacy perturbation on fairness measures in ATRs. To the best of our knowledge, this is the first analytical work that simultaneously addresses trade-offs between the triad of privacy, utility, and fairness, applicable to algorithmic transparency reports.",0,Human
"This paper looks into using dynamic pricing to control the freshness of information at receivers' end, or Age of Information (AoI), in networks. AoI is an important measure that reflects how fresh information is. Pricing that varies according to supply and demand in real time has been widely used across many industries to maximize profits. This research proposes a pricing mechanism that motivates users to transmit information at times when AoI is lowest. In this scenario users differ in terms of sensitivity to delays. Results show that this new mechanism improves overall network performance by reducing average AoI and increasing revenue for providers. The paper also studies the impact of different pricing strategies on user behavior and resultant network performance. Simulation results indicate that pricing dynamically controls AoI and provides understanding for designing pricing mechanisms for communication networks.",1,AI
"Transmission over multiple frequency bands combined into one logical channel speeds up data transfer for wireless networks. On the other hand, the allocation of multiple channels to a single user decreases the probability of finding a free logical channel for new connections, which may result in a network-wide throughput loss. While this relationship has been studied experimentally, especially in the WLAN configuration, little is known on how to analytically model such phenomena. With the advent of Opportunistic Spectrum Access (OSA) networks, it is even more important to understand the circumstances in which it is beneficial to bond channels occupied by primary users with dynamic duty cycle patterns. In this paper we propose an analytical framework which allows the investigation of the average channel throughput at the medium access control layer for OSA networks with channel bonding enabled. We show that channel bonding is generally beneficial, though the extent of the benefits depend on the features of the OSA network, including OSA network size and the total number of channels available for bonding. In addition, we show that performance benefits can be realized by adaptively changing the number of bonded channels depending on network conditions. Finally, we evaluate channel bonding considering physical layer constraints, i.e. throughput reduction compared to the theoretical throughput of a single virtual channel due to a transmission power limit for any bonding size.",0,Human
"This paper examines smoothed analysis in the context of population protocols. These are distributed algorithms where simple agents interact within networks having limited memory and communication resources. Usually, protocol analysis uses worst case complexity bounds which do not reflect the network input structure. Smoothed analysis is a method that bridges worst and average case analysis by measuring performance across distributions of inputs near worst cases according to a metric. In this work we develop a smoothed analysis framework for protocols and study leader election and majority voting among others. Results show that many protocols with poor worst case bounds perform well under smoothed analysis and are thus robust against small variations in input networks. We also look at relationships between smoothed analysis and input network structure and find that protocols performing well under smoothed analysis tend to fit networks with low expansion and high connectivity. Results are important because they suggest worst case bounds may not fully indicate performance quality here; smoothed analysis provides a more refined and realistic means for assessing performance and might direct future protocol design towards both efficiency and resilience to variation in input network.",1,AI
This research paper addresses development and implementation of new methods for estimating sparse principal components and covariance matrices. A new method based on rephrasing the Procrustes problem is introduced here; this allows for estimation of sparse orthogonal principal components and covariance matrices. Sparse optimization problems are considered equivalent to the Procrustes problem and used to achieve this. Performance is evaluated using diverse synthetic and real datasets and results show better performance relative to other methods. Results indicate effectiveness for accurate estimation of sparse PCA and covariance matrices and suggest promising application domains such as high dimensional data analysis and signal processing.,1,AI
"In the last years, multi-objective evolutionary algorithms (MOEA) have been applied to different software engineering problems where many conflicting objectives have to be optimized simultaneously. In theory, evolutionary algorithms feature a nice property for runtime optimization as they can provide a solution in any execution time. In practice, based on a Darwinian inspired natural selection, these evolutionary algorithms produce many deadborn solutions whose computation results in a computational resources wastage: natural selection is naturally slow. In this paper, we reconsider this founding analogy to accelerate convergence of MOEA, by looking at modern biology studies: artificial selection has been used to achieve an anticipated specific purpose instead of only relying on crossover and natural selection (i.e., Muller et al [18] research on artificial mutation of fruits with X-Ray). Putting aside the analogy with natural selection , the present paper proposes an hyper-heuristic for MOEA algorithms named Sputnik 1 that uses artificial selective mutation to improve the convergence speed of MOEA. Sputnik leverages the past history of mutation efficiency to select the most relevant mutations to perform. We evaluate Sputnik on a cloud-reasoning engine, which drives on-demand provisioning while considering conflicting performance and cost objectives. We have conducted experiments to highlight the significant performance improvement of Sputnik in terms of resolution time.",0,Human
"Machine learning models have been successfully used in many scientific and engineering fields. However, it remains difficult for a model to simultaneously utilize domain knowledge and experimental observation data. The application of knowledge-based symbolic AI represented by an expert system is limited by the expressive ability of the model, and data-driven connectionism AI represented by neural networks is prone to produce predictions that violate physical mechanisms. In order to fully integrate domain knowledge with observations, and make full use of the prior information and the strong fitting ability of neural networks, this study proposes theory-guided hard constraint projection (HCP). This model converts physical constraints, such as governing equations, into a form that is easy to handle through discretization, and then implements hard constraint optimization through projection. Based on rigorous mathematical proofs, theory-guided HCP can ensure that model predictions strictly conform to physical mechanisms in the constraint patch. The performance of the theory-guided HCP is verified by experiments based on the heterogeneous subsurface flow problem. Due to the application of hard constraints, compared with fully connected neural networks and soft constraint models, such as theory-guided neural networks and physics-informed neural networks, theory-guided HCP requires fewer data, and achieves higher prediction accuracy and stronger robustness to noisy observations.",0,Human
"This paper introduces a general framework for safety in robots using learning control in unpredictable environments. Using learning control has become quite common; this has both advantages and risks. Uncertainty in environment and limitations of learning algorithms can result in unexpected behavior in robots, which might be dangerous at times. The authors propose a framework aimed at keeping robots safe as they operate in unpredictable situations and even when encountering scenarios not part of their training data. This framework comprises two major parts: a safety layer and a performance layer. Safety layer continuously monitors robot behavior and intervenes as needed to avoid unsafe actions; performance layer is responsible for maximizing performance. Results of simulation studies show effectiveness of this framework in protecting system safety. In sum, this work advances research on safe learning control for robots and presents promising methods to address safety issues in unpredictable environments.",1,AI
"This paper introduces a new way to improve resolution of depth images, which are important for many vision tasks. It leverages transfer learning across different tasks to learn scene structure guidance using high resolution RGB images; this improves inference of missing details from lower resolution depth images. Specifically, the proposed approach comprises a network for super resolution of depth data and another network for guiding. The guiding network transmits knowledge obtained from RGB images to the depth super resolution network. Results show that the proposed method excels compared to leading techniques both quantitatively and visually. Performance is also good on actual datasets and thus the method looks promising for practical use.",1,AI
"3D object detection based on point clouds has become more and more popular. Some methods propose localizing 3D objects directly from raw point clouds to avoid information loss. However, these methods come with complex structures and significant computational overhead, limiting its broader application in real-time scenarios. Some methods choose to transform the point cloud data into compact tensors first and leverage off-the-shelf 2D detectors to propose 3D objects, which is much faster and achieves state-of-the-art results. However, because of the inconsistency between 2D and 3D data, we argue that the performance of compact tensor-based 3D detectors is restricted if we use 2D detectors without corresponding modification. Specifically, the distribution of point clouds is uneven, with most points gather on the boundary of objects, while detectors for 2D data always extract features evenly. Motivated by this observation, we propose DENse Feature Indicator (DENFI), a universal module that helps 3D detectors focus on the densest region of the point clouds in a boundary-aware manner. Moreover, DENFI is lightweight and guarantees real-time speed when applied to 3D object detectors. Experiments on KITTI dataset show that DENFI improves the performance of the baseline single-stage detector remarkably, which achieves new state-of-the-art performance among previous 3D detectors, including both two-stage and multi-sensor fusion methods, in terms of mAP with a 34FPS detection speed.",0,Human
"Nonextensive statistical mechanics is an alternative approach to traditional thermodynamics to understand complex systems. This paper extends this idea to economics and looks at ways to apply these ideas to model economic systems. We use new principles of this theory to better handle differences among components of data and also long distance relationships within data. Results indicate that such models perform much better than standard ones at describing dynamics within economic systems and they can help policymakers make more thoughtful decisions. Overall, this research shows that it is important to incorporate nonextensive statistical mechanics into economics studies and it points out a path towards a deeper understanding of complex economies.",1,AI
"Semantic segmentation of aerial videos has been extensively used for decision making in monitoring environmental changes, urban planning, and disaster management. The reliability of these decision support systems is dependent on the accuracy of the video semantic segmentation algorithms. The existing CNN based video semantic segmentation methods have enhanced the image semantic segmentation methods by incorporating an additional module such as LSTM or optical flow for computing temporal dynamics of the video which is a computational overhead. The proposed research work modifies the CNN architecture by incorporating temporal information to improve the efficiency of video semantic segmentation.  In this work, an enhanced encoder-decoder based CNN architecture (UVid-Net) is proposed for UAV video semantic segmentation. The encoder of the proposed architecture embeds temporal information for temporally consistent labelling. The decoder is enhanced by introducing the feature-refiner module, which aids in accurate localization of the class labels. The proposed UVid-Net architecture for UAV video semantic segmentation is quantitatively evaluated on extended ManipalUAVid dataset. The performance metric mIoU of 0.79 has been observed which is significantly greater than the other state-of-the-art algorithms. Further, the proposed work produced promising results even for the pre-trained model of UVid-Net on urban street scene with fine tuning the final layer on UAV aerial videos.",0,Human
"This paper introduces a new approach to generating scalable and realistic recommendation datasets by means of fractal expansion. This method exploits the inherent fractal nature of interactions between users and items and utilizes similarity properties inherent to fractals to synthesize data that closely resembles actual recommendation scenarios. We compare performance of leading recommendation algorithms using both synthetic and real data sets to show effectiveness of this method. Results show that synthetic data from fractal expansion shares similar statistical properties with real data. It also allows for more scalability and efficiency in generating large scale recommendation data. We also study the influence of different parameters used for fractal expansion and give guidance for choosing suitable parameters according to different recommendation scenarios. We also touch upon some limitations and potential future developments like adding temporal dynamics and user feedback into the expansion process. In summary, this approach promises to be promising for generating realistic datasets both for research and practical use.",1,AI
"The development of positioning technologies has resulted in an increasing amount of mobility data being available. While bringing a lot of convenience to people's life, such availability also raises serious concerns about privacy. In this paper, we concentrate on one of the most sensitive information that can be inferred from mobility data, namely social relationships. We propose a novel social relation inference attack that relies on an advanced feature learning technique to automatically summarize users' mobility features. Compared to existing approaches, our attack is able to predict any two individuals' social relation, and it does not require the adversary to have any prior knowledge on existing social relations. These advantages significantly increase the applicability of our attack and the scope of the privacy assessment. Extensive experiments conducted on a large dataset demonstrate that our inference attack is effective, and achieves between 13% to 20% improvement over the best state-of-the-art scheme. We propose three defense mechanisms -- hiding, replacement and generalization -- and evaluate their effectiveness for mitigating the social link privacy risks stemming from mobility data sharing. Our experimental results show that both hiding and replacement mechanisms outperform generalization. Moreover, hiding and replacement achieve a comparable trade-off between utility and privacy, the former preserving better utility and the latter providing better privacy.",0,Human
"Communication or influence networks are probably the most controllable of all factors that are known to impact on the problem-solving capability of task-forces. In the case connections are costly, it is necessary to implement a policy to allocate them to the individuals. Here we use an agent-based model to study how distinct allocation policies affect the performance of a group of agents whose task is to find the global maxima of NK fitness landscapes. Agents cooperate by broadcasting messages informing on their fitness and use this information to imitate the fittest agent in their influence neighborhoods. The larger the influence neighborhood of an agent, the more links, and hence information, the agent receives. We find that the elitist policy in which agents with above-average fitness have their influence neighborhoods amplified, whereas agents with below-average fitness have theirs deflated, is optimal for smooth landscapes, provided the group size is not too small. For rugged landscapes, however, the elitist policy can perform very poorly for certain group sizes. In addition, we find that the egalitarian policy, in which the size of the influence neighborhood is the same for all agents, is optimal for both smooth and rugged landscapes in the case of small groups. The welfarist policy, in which the actions of the elitist policy are reversed, is always suboptimal, i.e., depending on the group size it is outperformed by either the elitist or the egalitarian policies.",0,Human
"Accountability is widely understood as a goal for well governed computer systems, and is a sought-after value in many governance contexts. But how can it be achieved? Recent work on standards for governable artificial intelligence systems offers a related principle: traceability. Traceability requires establishing not only how a system worked but how it was created and for what purpose, in a way that explains why a system has particular dynamics or behaviors. It connects records of how the system was constructed and what the system did mechanically to the broader goals of governance, in a way that highlights human understanding of that mechanical operation and the decision processes underlying it. We examine the various ways in which the principle of traceability has been articulated in AI principles and other policy documents from around the world, distill from these a set of requirements on software systems driven by the principle, and systematize the technologies available to meet those requirements. From our map of requirements to supporting tools, techniques, and procedures, we identify gaps and needs separating what traceability requires from the toolbox available for practitioners. This map reframes existing discussions around accountability and transparency, using the principle of traceability to show how, when, and why transparency can be deployed to serve accountability goals and thereby improve the normative fidelity of systems and their development processes.",0,Human
"This research looks into implementing a new way of pattern classification using circuits that mix digital and analog elements. Specifically, we study embedding 180 nanometer memory array cells into a mixed signal circuit. Our aim is to create a fast and low power system for tasks like image and speech recognition. Proposed is a system that integrates both digital and analog parts to reach high performance levels with low power usage. Results indicate that the system can classify quickly (<1 us) and use less than 20 nJ energy per classification. Findings are important because they could advance development of such systems for different purposes.",1,AI
"This paper introduces a new way to detect salient objects using RGB and depth data. By utilizing depth data from RGBD cameras, we can accurately detect and segment objects in a scene. This method uses low level features like color and texture together with high level semantic information related to objects and their relationship to the surroundings. Authors test this on various public datasets and show that overall it performs better than leading methods in terms of accuracy and robustness. The conclusion of the paper discusses implications for development of advanced computer vision systems that can understand and perceive the real world in a more comprehensive and sophisticated way.",1,AI
This paper introduces an innovative Adversarial Normalized Noisy Feature Auto Encoder (ANNAE) for text generation. ANNAE combines adversarial training with normalization techniques to improve quality of generated text. The proposed system uses auto encoder benefits and adds a noise layer to the encoding process to generate richer and more robust feature representations of input data. ANNAE also uses normalization techniques to stabilize and converge training. Empirically evaluating performance on several benchmark datasets shows that ANNAE excels in both quality and diversity of generated text relative to leading models.,1,AI
"This paper investigates relationships between logic and games to reason about concurrent systems; its goal is to develop a broad framework. The paper starts by defining true concurrency as simultaneous execution of multiple processes and reviews previous models that do so. It introduces a new logical framework for concurrent reasoning that integrates ideas from both logic and game theory. Specifically, a new logic is presented that bases itself on the concept of bisimulation, along with an explanation of how this logic helps to reason about system behavior. The paper also develops a new game theoretic model of concurrency that facilitates strategic interaction among agents in concurrent systems. Case studies involving distributed and multi agent systems are subsequently considered and results show effectiveness of proposed framework. In summary, this work offers novel and comprehensive reasoning for concurrency by integrating ideas from logic and game theory. Researchers and practitioners would benefit from this framework and it lays groundwork for future research.",1,AI
"As real-world images come in varying sizes, the machine learning model is part of a larger system that includes an upstream image scaling algorithm. In this system, the model and the scaling algorithm have become attractive targets for numerous attacks, such as adversarial examples and the recent image-scaling attack. In response to these attacks, researchers have developed defense approaches that are tailored to attacks at each processing stage. As these defenses are developed in isolation, their underlying assumptions may not hold when viewing them from the perspective of an end-to-end machine learning system. Thus, it is necessary to study these attacks and defenses in the context of machine learning systems. In this paper, we investigate the interplay between vulnerabilities of the image scaling procedure and machine learning models in the challenging hard-label black-box setting. We propose a series of novel techniques to make a black-box attack exploit vulnerabilities in scaling algorithms, scaling defenses, and the final machine learning model in an end-to-end manner. Based on this scaling-aware attack, we reveal that most existing scaling defenses are ineffective under threat from downstream models. Moreover, we empirically observe that standard black-box attacks can significantly improve their performance by exploiting the vulnerable scaling procedure. We further demonstrate this problem on a commercial Image Analysis API with transfer-based black-box attacks.",0,Human
"This paper introduces a new benchmark dataset and an advanced framework for QA specifically focused on electronic devices. The dataset includes diverse questions and answers about things like smartphones and laptops and other consumer electronics. The authors design and implement a framework using multi task learning, leveraging shared knowledge and representations across different tasks to improve performance. Results show this new approach performs much better compared to previous methods in terms of both accuracy and efficiency. Authors conduct a detailed analysis of results which reveals advantages and disadvantages of the new framework. Contributions include development of a new benchmark dataset for electronic device QA and a novel framework that could be widely useful.",1,AI
This research introduces a method for studying the timing and distribution of traces of partially synchronous systems in real time. Researchers study system behavior in terms of exchanges of messages and execution of processes and they present a technique for capturing and displaying data traces. Results from this study offer insight into dynamic behavior of systems and are useful for debugging and performance evaluation. Evaluations using actual systems show effectiveness in gaining clear and comprehensive understanding of system behavior. Findings from this work advance distributed systems research and suggest directions for new tools for monitoring and analyzing such systems.,1,AI
"This paper introduces a new approach to interactive data exploration that uses information theory and subjective user feedback. The study merges standard data visualization techniques with feedback to produce a more dynamic experience. By integrating feedback, this method can adjust to users' preferences and goals resulting in personalized exploration. Information theory provides a mathematical basis for this process allowing the system to make informed decisions based on feedback information. Results from testing real data sets show effectiveness of the proposed methods and indicate potential utility across diverse fields such as BI, scientific discovery and education. Overall, this research advances data visualization by offering a fresh and effective approach to interactive exploration using subjective feedback.",1,AI
"This paper introduces a new method of nonlinear regression that both picks out important parameters and estimates them at the same time. This method uses a penalized likelihood approach that joins together a nonlinear model with a penalty function that prefers sparser solutions. Penalty function combines L1 and L2 regularizations which allow for simultaneous parameter selection and estimation. The resulting optimization problem is solved by an algorithm based on iterative weighted least squares. Performance of this method is assessed via simulated and real datasets and compared against other popular regression methods. Results indicate this regularized nonlinear regression method performs accurately at selecting and estimating important parameters while avoiding overfitting and improving predictive performance. Overall, this new method is a promising tool for diverse fields such as medicine research, engineering and finance.",1,AI
"Purpose: Development of a fast and fully automated deep learning pipeline (FatSegNet) to accurately identify, segment, and quantify abdominal adipose tissue on Dixon MRI from the Rhineland Study - a large prospective population-based study. Method: FatSegNet is composed of three stages: (i) consistent localization of the abdominal region using two 2D-Competitive Dense Fully Convolutional Networks (CDFNet), (ii) segmentation of adipose tissue on three views by independent CDFNets, and (iii) view aggregation. FatSegNet is trained with 33 manually annotated subjects, and validated by: 1) comparison of segmentation accuracy against a testingset covering a wide range of body mass index (BMI), 2) test-retest reliability, and 3) robustness in a large cohort study. Results: The CDFNet demonstrates increased robustness compared to traditional deep learning networks. FatSegNet dice score outperforms manual raters on the abdominal visceral adipose tissue (VAT, 0.828 vs. 0.788), and produces comparable results on subcutaneous adipose tissue (SAT, 0.973 vs. 0.982). The pipeline has very small test-retest absolute percentage difference and excellent agreement between scan sessions (VAT: APD = 2.957%, ICC=0.998 and SAT: APD= 3.254%, ICC=0.996). Conclusion: FatSegNet can reliably analyze a 3D Dixon MRI in1 min. It generalizes well to different body shapes, sensitively replicates known VAT and SAT volume effects in a large cohort study, and permits localized analysis of fat compartments.",0,Human
"The problem of estimating sparse eigenvectors of a symmetric matrix attracts a lot of attention in many applications, especially those with high dimensional data set. While classical eigenvectors can be obtained as the solution of a maximization problem, existing approaches formulate this problem by adding a penalty term into the objective function that encourages a sparse solution. However, the resulting methods achieve sparsity at the expense of sacrificing the orthogonality property. In this paper, we develop a new method to estimate dominant sparse eigenvectors without trading off their orthogonality. The problem is highly non-convex and hard to handle. We apply the MM framework where we iteratively maximize a tight lower bound (surrogate function) of the objective function over the Stiefel manifold. The inner maximization problem turns out to be a rectangular Procrustes problem, which has a closed form solution. In addition, we propose a method to improve the covariance estimation problem when its underlying eigenvectors are known to be sparse. We use the eigenvalue decomposition of the covariance matrix to formulate an optimization problem where we impose sparsity on the corresponding eigenvectors. Numerical experiments show that the proposed eigenvector extraction algorithm matches or outperforms existing algorithms in terms of support recovery and explained variance, while the covariance estimation algorithms improve significantly the sample covariance estimator.",0,Human
This paper investigates the use of Broadface technology for large scale surveillance. Researchers conduct experiments using a dataset of tens of thousands of faces and test both accuracy and efficiency of their system. Results show Broadface can recognize faces live and with high accuracy. Authors also consider privacy and security implications and emphasize need for further study. Final conclusion is that Broadface may change how we think about big face recognition and could impact many different fields and uses.,1,AI
"Current evaluation functions for heuristic planning are expensive to compute. In numerous planning problems these functions provide good guidance to the solution, so they are worth the expense. However, when evaluation functions are misguiding or when planning problems are large enough, lots of node evaluations must be computed, which severely limits the scalability of heuristic planners. In this paper, we present a novel solution for reducing node evaluations in heuristic planning based on machine learning. Particularly, we define the task of learning search control for heuristic planning as a relational classification task, and we use an off-the-shelf relational classification tool to address this learning task. Our relational classification task captures the preferred action to select in the different planning contexts of a specific planning domain. These planning contexts are defined by the set of helpful actions of the current state, the goals remaining to be achieved, and the static predicates of the planning task. This paper shows two methods for guiding the search of a heuristic planner with the learned classifiers. The first one consists of using the resulting classifier as an action policy. The second one consists of applying the classifier to generate lookahead states within a Best First Search algorithm. Experiments over a variety of domains reveal that our heuristic planner using the learned classifiers solves larger problems than state-of-the-art planners.",0,Human
"This paper looks at controlling an $m/m/n + m$ queue system that has high loads in a Halfin-Whitt regime. Performance of this system is examined over a long time period. The goal is to devise a control strategy to minimize long run average costs while keeping the system stable. Using a framework based on Markov Decision Processes (MDPs) and applying Dynamic Programming principles, the paper derives the optimal control policy. A heuristic policy is also introduced which is simple to implement and uses low resource requirements. Performance metrics of these proposed policies are evaluated through numerical simulation against the optimal policy. Simulation results show that the heuristic policy performs nearly as well as the best one and excels over many other common control strategies. Finally the paper talks about the consequences of the findings and suggests ideas for future work regarding design of control strategies for such systems. Conclusion highlights contribution of this study and points out avenues for further research.",1,AI
"E-commerce platforms usually display a mixed list of ads and organic items in feed. One key problem is to allocate the limited slots in the feed to maximize the overall revenue as well as improve user experience, which requires a good model for user preference. Instead of modeling the influence of individual items on user behaviors, the arrangement signal models the influence of the arrangement of items and may lead to a better allocation strategy. However, most of previous strategies fail to model such a signal and therefore result in suboptimal performance. In addition, the percentage of ads exposed (PAE) is an important indicator in ads allocation. Excessive PAE hurts user experience while too low PAE reduces platform revenue. Therefore, how to constrain the PAE within a certain range while keeping personalized recommendation under the PAE constraint is a challenge.  In this paper, we propose Cross Deep Q Network (Cross DQN) to extract the crucial arrangement signal by crossing the embeddings of different items and modeling the crossed sequence by multi-channel attention. Besides, we propose an auxiliary loss for batch-level constraint on PAE to tackle the above-mentioned challenge. Our model results in higher revenue and better user experience than state-of-the-art baselines in offline experiments. Moreover, our model demonstrates a significant improvement in the online A/B test and has been fully deployed on Meituan feed to serve more than 300 millions of customers.",0,Human
"This paper looks at whether Tree Memory Networks (TMNs) work well for learning long dependencies over time from sequences of data. Traditional neural nets have trouble doing this because they lack sufficient memory. TMNs use recursion to explicitly model dependencies hierarchically. We show through comparison to other nets that TMNs excel at handling long term dependencies. Performance is demonstrated using various tasks like processing natural language and generating music. Results show TMNs surpass traditional nets by a large margin when it comes to learning long dependencies. We also look at interpretability by visualizing learned hierarchies; these reveal clear alignment with human understanding of linguistic and musical features. Finally, we consider practical uses like understanding natural language and speech and time series analysis. Results indicate TMNs are promising tools for modeling dependencies and suggest deeper insights into how brains store long term memory.",1,AI
"Recent advances in deep convolutional neural networks (DCNNs) have shown impressive performance improvements on thermal to visible face synthesis and matching problems. However, current DCNN-based synthesis models do not perform well on thermal faces with large pose variations. In order to deal with this problem, heterogeneous face frontalization methods are needed in which a model takes a thermal profile face image and generates a frontal visible face. This is an extremely difficult problem due to the large domain as well as large pose discrepancies between the two modalities. Despite its applications in biometrics and surveillance, this problem is relatively unexplored in the literature. We propose a domain agnostic learning-based generative adversarial network (DAL-GAN) which can synthesize frontal views in the visible domain from thermal faces with pose variations. DAL-GAN consists of a generator with an auxiliary classifier and two discriminators which capture both local and global texture discriminations for better synthesis. A contrastive constraint is enforced in the latent space of the generator with the help of a dual-path training strategy, which improves the feature vector discrimination. Finally, a multi-purpose loss function is utilized to guide the network in synthesizing identity preserving cross-domain frontalization. Extensive experimental results demonstrate that DAL-GAN can generate better quality frontal views compared to the other baseline methods.",0,Human
"Recent results by Alagic and Russell have given some evidence that the Even-Mansour cipher may be secure against quantum adversaries with quantum queries, if considered over other groups than $(\mathbb{Z}/2)^n$. This prompts the question as to whether or not other classical schemes may be generalized to arbitrary groups and whether classical results still apply to those generalized schemes. In this thesis, we generalize the Even-Mansour cipher and the Feistel cipher. We show that Even and Mansour's original notions of secrecy are obtained on a one-key, group variant of the Even-Mansour cipher. We generalize the result by Kilian and Rogaway, that the Even-Mansour cipher is pseudorandom, to super pseudorandomness, also in the one-key, group case. Using a Slide Attack we match the bound found above. After generalizing the Feistel cipher to arbitrary groups we resolve an open problem of Patel, Ramzan, and Sundaram by showing that the 3-round Feistel cipher over an arbitrary group is not super pseudorandom. We generalize a result by Gentry and Ramzan showing that the Even-Mansour cipher can be implemented using the Feistel cipher as the public permutation. In this result, we also consider the one-key case over a group and generalize their bound. Finally, we consider Zhandry's result on quantum pseudorandom permutations, showing that his result may be generalized to hold for arbitrary groups. In this regard, we consider whether certain card shuffles may be generalized as well.",0,Human
"Evolution strategies (ES) are a family of black-box optimization algorithms able to train deep neural networks roughly as well as Q-learning and policy gradient methods on challenging deep reinforcement learning (RL) problems, but are much faster (e.g. hours vs. days) because they parallelize better. However, many RL problems require directed exploration because they have reward functions that are sparse or deceptive (i.e. contain local optima), and it is unknown how to encourage such exploration with ES. Here we show that algorithms that have been invented to promote directed exploration in small-scale evolved neural networks via populations of exploring agents, specifically novelty search (NS) and quality diversity (QD) algorithms, can be hybridized with ES to improve its performance on sparse or deceptive deep RL tasks, while retaining scalability. Our experiments confirm that the resultant new algorithms, NS-ES and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES to achieve higher performance on Atari and simulated robots learning to walk around a deceptive trap. This paper thus introduces a family of fast, scalable algorithms for reinforcement learning that are capable of directed exploration. It also adds this new family of exploration algorithms to the RL toolbox and raises the interesting possibility that analogous algorithms with multiple simultaneous paths of exploration might also combine well with existing RL algorithms outside ES.",0,Human
"This study looks into segmentation of objects within videos by separating them accurately from a sequence of frames. We introduce a new method that couples objects with transformers which are networks typically used for processing natural language. Using a two step process, we first apply a traditional detector to find objects in video frames. We then connect each detected object to a transformer network that learns appearance and motion information through time. This transformer generates embeddings for every object which serve as inputs to a fully convolutional network which outputs pixel level segmentation masks. We test this method using different benchmark datasets and compare it with leading methods. Results indicate that coupling objects with transformers yields better performance and we outperform current top performers on various datasets. Overall, we present an encouraging approach to video object segmentation that mixes benefits of classical vision techniques and contemporary neural nets.",1,AI
"This paper evaluates comprehensively the security of mail delivery systems. It looks at many different kinds of systems including both traditional physical mail and newer digital systems. Evaluation includes looking at risks like unauthorized access, theft of data and tampering. There is also a detailed look into current security methods such as encryption, authentication and access controls. Results show that although current security methods mitigate certain risks, there is still opportunity for improvement. Authors suggest good practices for improving system security and suggest new research topics. Results give important information to people who depend on secure and reliable mail delivery systems.",1,AI
"This paper studies invisible data handling practices within the context of facility management and focuses on a big company that does that work. Usually people think about data handling as a technical matter but this research stresses the significance of understanding social and organizational aspects of such handling. Through interviews and observation, this paper lists many examples of unobvious practices like using informal communication channels, making ad hoc tools and processes and embedding data into decisions. The paper asserts that those invisible practices are important to managing facilities well but they usually get neglected or not highly valued. At the end, the paper suggests some recommendations on how to better support and value these invisible practices.",1,AI
"This paper introduces a new method for estimating software development effort based on ridge regression and evolutionary attribute selection. Precise estimation of effort is important for project planning, budgeting and resource allocation but currently there are problems of either too low or high estimates leading to delays and cost overrun. We propose a dual step approach that couples ridge regression modeling and use of evolutionary attribute selection. Ridge regression relates software project attributes to effort estimation; evolutionary selection picks significant attributes for estimation. Results using four public datasets show performance exceeding other methods including linear regression, decision trees and support vector regression. Performance improvements are around 10%. Selection also highlights key attributes for estimation and produces simpler models. This method shows promise for more accurate planning and resource allocation. Future work will look into applying this approach to other areas and explore potential for further advanced ML techniques.",1,AI
"This paper introduces Pifthon, a tool for statically analyzing control and data flow at compile time in imperative languages. It detects security flaws which may arise when a program runs. Written in Python, Pifthon analyzes code at bytecode level. The authors describe the design and implementation of Pifthon and detail its various analyses and algorithms. Evaluation results show that Pifthon finds different kinds of security leaks and achieves good accuracy along with acceptable performance. At the end, this paper also talks about the limitations of Pifthon and points towards future research directions.",1,AI
"The security evaluation for Mail Distribution Systems focuses on certification and reliability of sensitive data between mail servers. The need to certify the information conveyed is a result of known weaknesses in the simple mail transfer protocol (SMTP). The most important consequence of these weaknesses is the possibility to mislead the recipient, which is achieved via spam (especially email spoofing). Email spoofing refers to alterations in the headers and/or the content of the message. Therefore, the authenticity of the message is compromised. Unfortunately, the broken link between certification and reliability of the information is unsolicited email (spam).  Unlike the current practice of estimating the cost of spam, which prompts organizations to purchase and maintain appropriate anti-spam software, our approach offers an alternative perspective of the economic and moral consequences of unsolicited mail. The financial data provided in this paper show that spam is a major contributor to the financial and production cost of an organization, necessitating further attention. Additionally, this paper highlights the importance and severity of the weaknesses of the SMTP protocol, which can be exploited even with the use of simple applications incorporated within most commonly used Operating Systems (e.g. Telnet).  As a consequence of these drawbacks Mail Distribution Systems need to be appropriate configured so as to provide the necessary security services to the users.",0,Human
"In recent years, deep neural network is widely used in machine learning. The multi-class classification problem is a class of important problem in machine learning. However, in order to solve those types of multi-class classification problems effectively, the required network size should have hyper-linear growth with respect to the number of classes. Therefore, it is infeasible to solve the multi-class classification problem using deep neural network when the number of classes are huge. This paper presents a method, so called Label Mapping (LM), to solve this problem by decomposing the original classification problem to several smaller sub-problems which are solvable theoretically. Our method is an ensemble method like error-correcting output codes (ECOC), but it allows base learners to be multi-class classifiers with different number of class labels. We propose two design principles for LM, one is to maximize the number of base classifier which can separate two different classes, and the other is to keep all base learners to be independent as possible in order to reduce the redundant information. Based on these principles, two different LM algorithms are derived using number theory and information theory. Since each base learner can be trained independently, it is easy to scale our method into a large scale training system. Experiments show that our proposed method outperforms the standard one-hot encoding and ECOC significantly in terms of accuracy and model complexity.",0,Human
This paper conducts a critical review of current methods for using randomized machine learning to predict renewable energy production. It surveys recent high quality methods along with their shortcomings and potential ways of enhancing them. Results and fresh viewpoints about randomized learning applications are also reported and analyzed. Authors give insights into advantages and disadvantages of different randomized approaches and suggest new avenues for future research. Conclusions summarize important implications of these findings for designing better and more efficient systems for renewable energy forecasting.,1,AI
"This paper investigates how to realize better and more efficient embedding learning to tackle the semi-supervised video object segmentation under challenging multi-object scenarios. The state-of-the-art methods learn to decode features with a single positive object and thus have to match and segment each target separately under multi-object scenarios, consuming multiple times computing resources. To solve the problem, we propose an Associating Objects with Transformers (AOT) approach to match and decode multiple objects uniformly. In detail, AOT employs an identification mechanism to associate multiple targets into the same high-dimensional embedding space. Thus, we can simultaneously process multiple objects' matching and segmentation decoding as efficiently as processing a single object. For sufficiently modeling multi-object association, a Long Short-Term Transformer is designed for constructing hierarchical matching and propagation. We conduct extensive experiments on both multi-object and single-object benchmarks to examine AOT variant networks with different complexities. Particularly, our R50-AOT-L outperforms all the state-of-the-art competitors on three popular benchmarks, i.e., YouTube-VOS (84.1% J&F), DAVIS 2017 (84.9%), and DAVIS 2016 (91.1%), while keeping more than $3\times$ faster multi-object run-time. Meanwhile, our AOT-T can maintain real-time multi-object speed on the above benchmarks. Based on AOT, we ranked 1st in the 3rd Large-scale VOS Challenge.",0,Human
"NormalGAN introduces a new way of generating 3D human models from a single RGB depth image. Leveraging GANs, it creates detailed models that accurately depict human anatomy and finer features like skin texture and clothes. Results indicate that NormalGAN produces high quality models that surpass previous best methods in terms of precision and detail. Applications for this work are broad and include virtual and augmented reality, animation and human interaction with computers.",1,AI
"This paper introduces a new approach to train automatic view planners for cardiac MRI using supervision from the spatial relationships between different views. We address the issues of obtaining large amounts of labeled data for supervised learning and the limitations of unsupervised methods relying on preset criteria for selecting views. This approach includes three main components: a view selection module that generates candidate views based on spatial relations; a synthesis module that creates synthetic images for selected candidates via a generative model; and an evaluation module that uses a discriminator to assess synthetic quality and select high quality views. Experiments on a public dataset of cardiac MR images show that this new approach surpasses previous unsupervised methods both in image quality and selection accuracy. Results also indicate that performance compares favorably with supervised methods requiring many labeled examples. In summary, this new approach offers a promising solution for automatic view selection in cardiac MRI through leveraging spatial relationships and using unsupervised learning. This new approach could reduce annotation burdens and enhance efficiency and accuracy of cardiac MRI.",1,AI
"This paper reviews robust video watermarking methods aimed at protecting content from illegal access and piracy. Starting with an overview of challenges and requirements, including robustness, imperceptibility and capacity, this paper then details a broad range of current top level methods. They include spatial and frequency domains and hybrid techniques. Performance evaluation considers robustness to common operations like compression, filtering and cropping. Comparison of computational complexity, capacity and imperceptibility is included. Results highlight strengths and weaknesses of different techniques and provide suggestions for future research. Results show high robustness and imperceptibility along with reasonable computation complexity and capacity but also indicate there is still room for improvement against strong attacks and better capacity. Concluding remarks point out major challenges and promising areas for future research in video watermarking.",1,AI
"This paper introduces an innovative way of inferring social connections based on individual mobility profiles called Walk2Friends. Using GPS data, we identify and predict relationships among people. We use a large dataset containing both mobility traces and social network connections collected at a university campus to evaluate effectiveness. This study describes details of Walk2Friends including pre-processing GPS data, construction of mobility profiles and use of a machine learning algorithm for link prediction. Results compare performance of Walk2Friends against other methods and show higher accuracy and efficiency. This paper also conducts a careful analysis of factors affecting accuracy of predicting social links using mobility data such as time and space resolution, importance of proximity and interaction frequency, and influence of individual mobility patterns. Results of this research are important and indicate that Walk2Friends offers promising prospects for deriving social relationships across various applications. These outcomes might be useful for targeted marketing and advertisement, identifying new social connections and understanding network dynamics.",1,AI
"Several recent studies in privacy-preserving learning have considered the trade-off between utility or risk and the level of differential privacy guaranteed by mechanisms for statistical query processing. In this paper we study this trade-off in private Support Vector Machine (SVM) learning. We present two efficient mechanisms, one for the case of finite-dimensional feature mappings and one for potentially infinite-dimensional feature mappings with translation-invariant kernels. For the case of translation-invariant kernels, the proposed mechanism minimizes regularized empirical risk in a random Reproducing Kernel Hilbert Space whose kernel uniformly approximates the desired kernel with high probability. This technique, borrowed from large-scale learning, allows the mechanism to respond with a finite encoding of the classifier, even when the function class is of infinite VC dimension. Differential privacy is established using a proof technique from algorithmic stability. Utility--the mechanism's response function is pointwise epsilon-close to non-private SVM with probability 1-delta--is proven by appealing to the smoothness of regularized empirical risk minimization with respect to small perturbations to the feature mapping. We conclude with a lower bound on the optimal differential privacy of the SVM. This negative result states that for any delta, no mechanism can be simultaneously (epsilon,delta)-useful and beta-differentially private for small epsilon and small beta.",0,Human
"Background: The learning of genotype-phenotype associations and history of human disease by doing detailed and precise analysis of phenotypic abnormalities can be defined as deep phenotyping. To understand and detect this interaction between phenotype and genotype is a fundamental step when translating precision medicine to clinical practice. The recent advances in the field of machine learning is efficient to predict these interactions between abnormal human phenotypes and genes.  Methods: In this study, we developed a framework to predict links between human phenotype ontology (HPO) and genes. The annotation data from the heterogeneous knowledge resources i.e., orphanet, is used to parse human phenotype-gene associations. To generate the embeddings for the nodes (HPO & genes), an algorithm called node2vec was used. It performs node sampling on this graph based on random walks, then learns features over these sampled nodes to generate embeddings. These embeddings were used to perform the downstream task to predict the presence of the link between these nodes using 5 different supervised machine learning algorithms.  Results: The downstream link prediction task shows that the Gradient Boosting Decision Tree based model (LightGBM) achieved an optimal AUROC 0.904 and AUCPR 0.784. In addition, LightGBM achieved an optimal weighted F1 score of 0.87. Compared to the other 4 methods LightGBM is able to find more accurate interaction/link between human phenotype & gene pairs.",0,Human
"This paper introduces a new way to store and quickly search for small pieces of large graphs called Compact Neighborhood Index (CNI). CNI reduces storage space needed compared to other approaches at the same time as performing fast searches. It does this by storing efficiently a neighbor set of each node using hashing and bit manipulation methods. Performance testing on real data sets shows that CNI saves much storage space but also processes queries similarly to other current systems. Results also indicate that CNI performs better than others when dealing with graphs that cluster tightly together. Overall, this research points towards promising development of efficient and scalable indexes for large graphs. Such indexes have broad practical uses including social networks, biological networks and transport networks among others.",1,AI
